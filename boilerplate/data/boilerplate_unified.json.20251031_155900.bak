{
  "appendix": {
    "additional_tables": "This appendix contains additional tables that could not be included in the main manuscript due to space constraints.",
    "alternative_specifications": "We tested alternative model specifications to ensure that our results are not sensitive to specific modeling choices.",
    "assumptions": {
      "assumptions_grf_text": "\n## S{{appendix_assumptions_grf}}: How Statistical Models Influence Detecting Treatment Effect Differences\n\nThis explanation draws on @bulbulia2024swigstime.\n\nImagine a treatment or exposure ($A$) that might affect an outcome ($Y$). Sometimes, the effect of $A$ on $Y$ isn't the same for everyone; it might be stronger or weaker depending on other characteristics. This is called 'effect modification'. For effect modification to even be possible, the treatment must have some effect on at least some individuals [@bulbulia2024wierd].\n\nWe cannot simply look at average differences within our sample to understand how effects vary. Instead, we need to use statistical models to investigate this potential heterogeneity [@grf2024; @vansteelandt2022a]. Alternatively, we might want to compare if the treatment effect differs between specific groups in the population, such as different cultural groups or genders.\n\n::: {#tbl-terminologyeffectmodification}\n```{=latex}\n\\terminologyeffectmodification\nGraphical conventions used to represent effect modification.\n:::\n\n@tbl-terminologyeffectmodification shows the symbols we use in diagrams to discuss effect modification clearly. To focus purely on effect modification, we assume the treatment ($A$) was assigned randomly (like flipping a coin, $\\mathcal{R} \\rightarrow A$). This means we assume the basic relationship is $A$ causes $Y$ ($A \\to Y$), without other factors confusing this link.\n\nTherefore, we don't need complex causal diagrams to adjust for confounding of the treatment effect itself. We also won't draw a causal arrow from the variable that modifies the effect ($F$) directly to the outcome ($Y$). This choice helps us focus solely on how $F$ changes the $A \to Y$ relationship. (For discussion on different arrow types, see @hernan2024WHATIF, pp. 126-127).\n\n::: {#tbl-terminologyeffectmodificationtypes}\n\\terminologyeffectmodificationtypes\nExamples of Effect Modification Scenarios\n:::\n\nThe diagrams in @tbl-terminologyeffectmodificationtypes illustrate the central point: whether we find effect modification depends on which variables we include in our statistical analysis.\n\nIn $\\mathcal{G}_1$, the variable $F$ directly influences how $A$ affects $Y$. The open arrow towards the $A \\to Y$ path indicates that $F$ is associated with differences in the effect, without necessarily claiming $F$ causes this difference.\n\nIn $\\mathcal{G}_2$, $F$ is an unobserved factor that modifies the $A \to Y$ effect. If the distribution of $F$ differs between populations (e.g., a study population vs. a target population), the average treatment effect found in the study might not apply elsewhere. Generalising findings requires careful consideration [@hernan2024WHATIF; @bulbulia2024wierd]. Estimates can be misleading if the target population differs from the study population regarding effect-modifying characteristics [@greenland2009commentary; @lash2020; @bulbulia2024wierd].\n\nNow, consider the diagrams $\\mathcal{G}_3$ to $\\mathcal{G}_6$, which use the same underlying causal structure but different analysis choices. Let's use an example: $F$ is childhood deprivation, $G$ is educational achievement (influenced by $F$), $A$ is a government educational initiative, and $Y$ is recycling behaviour.\n\nIn $\\mathcal{G}_3$, $F$ (deprivation) directly modifies the effect of the initiative ($A$) on recycling ($Y$). $G$ (education) is influenced by $F$. If our statistical analysis accounts for $F$, we essentially block the connection from $G$ to $Y$ that goes through $F$. In this analysis, we would not find that the initiative's effectiveness varies by education level ($G$).\n\nIn $\\mathcal{G}_4$, we use the same scenario but analyse the data without accounting for $F$ (deprivation), only including $G$ (education). Because the link between education ($G$), deprivation ($F$), and recycling ($Y$) ($G \\leftarrow F \\rightarrow Y$) is not blocked in this analysis, we would find that the initiative's effect ($A \\to Y$) varies by education level ($G$). Here, $G$ appears to be an effect modifier simply because of our analysis choice.\n\nIn $\\mathcal{G}_5$, let's add another variable: $B$, representing depression (measured before $G$). Suppose $B$ also influences education ($G$). If we analyse the data including education ($G$) and depression ($B$), but not deprivation ($F$), something interesting happens. Because $G$ is influenced by both $F$ and $B$, including $G$ in the model creates an artificial statistical link between $B$ and $F$ (via $G$). This makes it look like the initiative's effect ($A \\to Y$) varies by depression level ($B$), even though $B$ has no actual causal link to $Y$ in this structure. The apparent effect modification by $B$ is an artefact of the analysis, not a reflection of causation.\n\nIn $\\mathcal{G}_6$, if we include the direct modifier $F$ (deprivation) in our analysis, it blocks the artificial pathways seen in $\\mathcal{G}_4$ and $\\mathcal{G}_5$. We would not find effect modification by education ($G$) or depression ($B$) in this case. This strongly highlights that our findings about effect modification depend on (1) the true underlying causal relationships and (2) which variables we choose to include in our statistical model.\n\nUsing principles from causal diagrams [@vanderweele2012], it becomes clear that analysing effect modification requires thinking about the assumed causal structure and explicitly stating which variables are included in the statistical model. Policymakers and researchers might reach wrong conclusions if they misinterpret effect modification findings without considering how the analysis was done [@bulbulia2024swigstime]. Remember, when we assess effect modification, we are asking if the treatment effect differs across groups, not whether the characteristics defining those groups themselves cause the outcome. For further reading on effect modification, see [@vanderweele2012; @vanderweele2007; @suzuki2013counterfactual;bulbulia2024swigstime].\n"
    },
    "baseline": "\n## S2: Measures and Demographic Statistics {#appendix-baseline}\n\n### Measures\n\n```{r, results='asis'}\ncat(appendix_text_all_measures) # make this with boilerplate_measures_text\n```\n\n### Sample Demographic Statistics\n\n@tbl-appendix-baseline presents sample demographic statistics.\n\n::: {#tbl-appendix-baseline}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\ncat(latex_table_baseline)\n\n```\nDemographic statistics for New Zealand Attitudes and Values Cohort {{baseline_wave}}.\n:::\n",
    "confounding": {
      "lmtp_dag": "\n## S{{appendix_confounding}}: Confouding Control {#appendix-confounding}\n\n::: {#tbl-C}\n```{=latex}\n\\feedbackB\n```\n@tbl-C Common cause of Treatment 1 and downstream confounder of Treatment 2 is a collider. To handle time-varying confounding we include time-fixed confounders in the baseline wave. Time-varying confounders are included in each of the successive treatment waves. When there is more than one exposure wave, identifying causal effects requires adjustment for time-varying confounders [@robins2008estimation; @bulbulia2024swigstime; @richardson2013].\n:::\n\nFor confounding control, we employ a modified disjunctive cause criterion [@vanderweele2019], which involves:\n\n\n1.\tIdentifying all common causes of both the treatment and outcomes.\n2.\tExcluding instrumental variables that affect the exposure but not the outcome.\n3.\tIncluding proxies for unmeasured confounders affecting both exposure and outcome.\n4.\tControlling for baseline exposure and baseline outcome, serving as proxies for unmeasured common causes [@vanderweele2020].\n\nAdditionally, we control for time-varying confounders at each exposure wave [@robins2008estimation; @bulbulia2024swigstime; @richardson2013].\n\nThe covariates included for confounding control are described in @pedro_2024effects.",
      "lmtp_swig": "\n## Appendix {{appendix_confounding}}: Confouding Control {#appendix-confounding}\n\n::: {#tbl-C}\n```{=latex}\n\tvtable\n```\n@tbl-C presents single-world intervention graphs showing time-fixed and time-varying sources of bias in our six waves (baseline, four exposure waves, followed by the outcome wave.) Time-fixed confounders are included in the baseline wave. Time-varying confounders are included in each of the four treatment waves (abbreviated here by '$\\dots$' to declutter the graph). When there is more than one exposure wave, identifying causal effects requires adjustment for time-varying confounders [@robins2008estimation; @bulbulia2024swigstime; @richardson2013].\n:::\n\nFor confounding control, we employ a modified disjunctive cause criterion [@vanderweele2019], which involves:\n\n\n1.\tIdentifying all common causes of both the treatment and outcomes.\n2.\tExcluding instrumental variables that affect the exposure but not the outcome.\n3.\tIncluding proxies for unmeasured confounders affecting both exposure and outcome.\n4.\tControlling for baseline exposure and baseline outcome, serving as proxies for unmeasured common causes [@vanderweele2020].\n\nAdditionally, we control for time-varying confounders at each exposure wave [@robins2008estimation; @bulbulia2024swigstime; @richardson2013].\n\nThe covariates included for confounding control are described in @pedro_2024effects.\n\nWhere there are multiple exposures, causal inference may be threatened by time-varying confounding [@bulbulia2024swigstime].",
      "threewave_l": "\n## S{{appendix_confounding}}: Confouding Control {#appendix-confounding}\n\n::: {#tbl-confounding}\n```{=latex}\n\\threewavepanel\n```\nThe Causal Directed Acyclic Graphs (DAGS) report the causal identification problems in our three-wave studyand and or methods for addressing them solution.\n:::\n\n@tbl-confounding describes our strategy for confounding control, in which we employ a modified disjunctive cause criterion [@vanderweele2019], which involves:\n\n\n1.\tIdentifying all common causes of both the treatment and outcomes.\n2.\tExcluding instrumental variables that affect the exposure but not the outcome.\n3.\tIncluding proxies for unmeasured confounders affecting both exposure and outcome.\n4.\tControlling for baseline exposure and baseline outcome (@tbl-confounding) addresses the strongest confounders, given any residual confounding would need to be orthogonal to these measures [@vanderweele2020].\n\nNevertheless, confounding and selection biases owing to attrition remain a problem. Missing responses at baseline are estimated within our causal forests. To handle attrition from the baseline wave to the exposure wave, and from the exposure wave to the outcome wave, we employ inverse probability of censoring weighting. Because confounding may still remain a problem a problem we employ sensitivity analysis, as described in the main text.",
      "threewave_x": "\n## S{{appendix_confounding}}: Confouding Control {#appendix-confounding}\n\n::: {#tbl-confounding}\n```{=latex}\n\\threewavepanelX\n```\nThe Causal Directed Acyclic Graphs (DAGS) report the causal identification problems in our three-wave studyand and or methods for addressing them solution.\n:::\n\n@tbl-confounding describes our strategy for confounding control, in which we employ a modified disjunctive cause criterion [@vanderweele2019], which involves:\n\n\n1.\tIdentifying all common causes of both the treatment and outcomes.\n2.\tExcluding instrumental variables that affect the exposure but not the outcome.\n3.\tIncluding proxies for unmeasured confounders affecting both exposure and outcome.\n4.\tControlling for baseline exposure and baseline outcome (@tbl-confounding) addresses the strongest confounders, given any residual confounding would need to be orthogonal to these measures [@vanderweele2020].\n\nNevertheless, confounding and selection biases owing to attrition remain a problem. Missing responses at baseline are estimated within our causal forests. To handle attrition from the baseline wave to the exposure wave, and from the exposure wave to the outcome wave, we employ inverse probability of censoring weighting. Because confounding may still remain a problem a problem we employ sensitivity analysis, as described in the main text."
    },
    "confusions": {
      "cross_lagged_model_deficiencies": "\n## S{{appendix_confusions_cross_lagged_model_deficiencies}}: Inadequacy of Cross Lagged Models\n\nAiken's regression textbook to assert that three conditions must generally be met to establish causality.\n\n\nWhere $X$ represents the exposure or treatment and $Y$ the outcome, Aiken asserts:\n\n1. $X$ and $Y$ must be correlated.\n2. The correlation must not be spurious or due to a confounding factor.\n3. $X$ must precede $Y$ in time.\n\n\nThe modern causal inference literature, which has advanced considerably over the past two decades in fields such as epidemiology, computer science, economics, and policy research, has shown that these assumptions are inadequate. Consider the following limitations of the traditional veiw.\n\n\n### Condition 1: It is not true that causation implies correlation\n\n\nUsing Pearl’s graphical models, causality can be defined as $X \rightarrow Y$, where conditioning on a mediator is denoted by $\boxed{M}$. Pearl has shown that in the scenario $X \rightarrow \boxed{M} \rightarrow Y$, causality can exist without a direct association between $X$ and $Y$. This is crucial because, with only two waves of data, any variable measured at Wave 1 could act as a mediator, potentially obscuring the true association between $X$ at time 1 and $Y$ at time 2. To address mediator bias effectively, at least three waves of data are required to disentangle these causal pathways [@vanderweele2020].\n\n### Condition 2: The confounding criterion is insufficient to evaluate causality\n\n\nThis condition essentially restates the idea that an association must be causal to be valid, which, although trivially true, adds no meaningful insight.\n\nThe confounding criterion typically applies when treatment $X$ and outcome $Y$ share a common cause, $L$. By adjusting for $L$, we aim to remove the confounding effect. However, consider a scenario where $X$ precedes $Y$ and both $X$ and $Y$ cause $L$, without a direct relationship between $X$ and $Y$. In Pearl's graphical terms, this would be represented as $X \\rightarrow \boxed{L} \\leftarrow Y$. Conditioning on $L$ would induce a spurious association between $X$ and $Y$ that would not exist without conditioning. This demonstrates even when we account for confounding by commong cause, the association between $X$ and $Y$ may be biased.\n\nMore fundamental, when including multiple varaibles in our models, we do not automatically obtain consistent causal effect estimates Take the simple case where $L \\rightarrow X \\rightarrow Y$, and suppose that $L \\rightarrow Y$.  To consistently estimate the a causal effect of $X \\rightarrow Y$ we must adjust for $\boxed{L}$.  If the causal relationships we have just described are correct, we may obtain valid causal inference for $X \\rightarrow Y$ by adjusting for $\\boxed{L}$. However the coefficient we obtain for $L$ in our stastical model will not consistently estimate the causal effect of $L \\to Y$ because $X$ is a mediator, such that  $L \\to \boxed{X} \to  Y$.\n\nInference become even more delicate when we add variables to our model because spurious correlations may be induced. For example, suppose that $L$ is no casually related to $Y$, but causally related to $X$. Suppose further that and unmesaured variable $U$ is related to both $X$ and $Y$ as a common cause.  In this case, there is unmeasured confounding for $X \\to Y$. However, conditioning on $X$ introduces bias for the path for $L$ to $Y$ because $\boxed{X}$ is a collider of $U$ and $L$. In a model that includes $\boxed{X}$ and to will appear that $L$ is associated with $Y$, however were we to simply focus on the unconditional realtionship between $L$ and $Y$ no correlation would be observed. Pearl's proved these points in @pearl1995, yet the remain under-appreciated in many social sciences, including psychological science. However, a consensus in causal inference holds that we should first clarify the causal effect of interest, then assess its identification conditions, then develop an appropriate estimator before we attempt a statistical model.  Practically this means investigators typically require separate models for each causal effect estimate of interest [@mcelreath2020; @westreich2013].\n\n\n### Condition 3: Temporal precedence is necessary but does not clarify identification\n\n\nIt is true that for $X$ to cause $Y$, $X$ must precede $Y$ in time. However in observational seetings, we must typically collect information on prior states of $Y$ and prior states of $X$ to ensure valid inferences for the causal effects of later states of $X$ on (still) later states of $Y$ . Consider a feedback loop such as $X_0 \rightarrow Y_1 \rightarrow X_2 \rightarrow Y_3$. Here, we imagine that $X$ and $Y$ affect each other over time, (as might occur when threat perceptions affect authoritarian attitudes, which then reshape future threat perceptions...). To correctly estimate the causal effect of $X_t$ on $Y_{t+1}$, we would need to control for both $Y_{t-1}$ and $X_{t-1}$. In regression form, this would appear as:\n\n\n$$ {\\tt model <- lm(Y_{t+1} \\sim A_t + Y_{t-1} + A_{t-1} + L_{t-1}, ...) }$$\n\nControl for prior exposure and prior outcome is necessary wherever there are unmeasured common causes of both[@vanderweele2020]. Importantly, this model cannot be estimated with only two waves of data; three waves are the minimum required to capture these dynamics. Therefore, the temporal precedence condition, while necessary, is insufficient for drawing reliable causal inferences when data are limited.\n\n\n### Time series data collected at a four month interval raise in a small student sample are unlikely to yield sufficiently many observations to obtain causal effect estimates\n\n\nBeyond these conceptual issues, there are practical limitations to causal modelling. For a causal model to be credible, sufficient variation in $X$ over time is necessary. For instance, if we are estimating the causal effect of threat perceptions ($X$) on authoritarianism ($Y$) over a four-month period, we need enough individuals whose threat perceptions have changed to observe any real effects. This variation must also occur across all levels of covariates (e.g., $L$). Without sufficient change, we would not expect to observed causal effects [@vanderweele2020]. However, we cannot rule out causality over longer intervals, which may be required to obtain valid instances of threat triggering.\n\nNotably, experiments are the gold standard for causal inference, and should be preferred when feasible and ethical. We are not given an explanation of why experiments were not used in this thesis. As indicated above, the decision to avoid experiments should be explained.\n\n\n### Cross-Lagged panel models typically do not afford valid causal effect estimates\n\n\nLastly, Cross-Lagged Panel Models (CLPMs), such as those used in Study 4, do not typically offer valid causal contrasts needed to estimate causal effects. The probem is that Cross-Lagged Panel Models lack explicit counterfactual comparisons, which are essential for determining what $Y_{t+1}$ would have been if $X_t$ had taken a different value. Instead, Cross-Lagged Panel Models  only observe $Y_{t+1}$ given the actual value of $X_t$, making it impossible to model hypothetical scenarios. Furthermore, these models typically do not adequately adjust for confounding. As a result, the findings in Study 4 do not provide credible causal inferences.  Gerard notes these problems, but this reader is left in doubt about the scholarly value of the study if the coeffecients reported, because if Gerard's critical observations are right the coefficients are uninterpretable.\n"
    },
    "explain": {
      "grf": "\nHere, we explain how the `grf` R package (Generalized Random Forests) can be used to estimate causal effects with causal forests.\n\n#### Menu of HTE diagnostics\n\nInvestigators may run one, several, or all of the following, depending on the scientific or operational question:\n* **RATE AUTOC / RATE Qini (global evidence)** – 'Should we abandon a uniform policy?'\n* **Qini curves (budget lens)** – 'If we treat at most $p\\%$, what uplift should we expect?'\n* **Policy trees (decision rule)** – 'Which simple, transparent allocation maximises welfare under constraints?'\n\nThe tools are complementary, not sequential.  A study may stop after RATE, skip RATE and go straight to a policy tree, or report the full trio; the choice should reflect whether the aim is evidence, optimisation, or communication.\n\n### Step 1: Estimating the Average Treatment Effect (ATE)\n\nThe Average Treatment Effect (ATE) is the overall effect of the treatment in the population. It answers the question: on average, how much does the treatment change the outcome compared to not treating? In a randomised trial, the ATE can be estimated simply by the difference in mean outcomes between the treated and control groups. For example, if a randomised intervention is designed to improve a psychological outcome such as well-being, the ATE would be the difference in the average outcome for those who received the intervention versus those who did not.\n\nFormally, we can define the ATE as $E[Y(1) - Y(0)]$, where $Y(1)$ is the outcome if an individual receives the treatment and $Y(0)$ is the outcome if they receive the control. In practice, the `grf` package provides functions like `average_treatment_effect()` that can compute the ATE (often using techniques like doubly robust estimation to improve precision). This initial step gives us a baseline: for instance, we might find that a new therapy improves an outcome by, say, .25 points (1-7 scale) on average.\n\nWhy start with the ATE? The ATE tells us if the treatment works on average if everyone were randomised to treatment as compared with everyone not receiving the treatment. Note however that even if the ATE is essentially zero (or unreliable), there may nevertheless be value in pursuing heterogeneity if some portion of the population is benefited or — equally important — if some portion is harmed.\n\nMoreover, even if the ATE is non-zero (e.g. the treatment has a positive overall effect), the next question is whether this effect is homogeneous (similar for everyone) or heterogeneous (different for different individuals). Thus, whether or not we detect reliable Average Treatment Effects we are led to investigate heterogeneous treatment effects.\n\n+Because multiple outcomes were evaluated, we corrected ATE results using {{ate_adjustment}} at α = {{ate_alpha}}.  For all heterogeneity (CATE) tests allow for controlled the false-discovery rate with {{cate_adjustment}} at q = {{cate_alpha}} [@benjamini1995controlling].\n\n\n\n### Step 2: Assessing Heterogeneous Treatment Effects (HTE)\n\nRealistically, treatment effects are often heterogeneous, meaning the treatment's magnitude (and direction) of effect can differ across individuals and subgroups. For example, a therapy might work better for participants with a certain personality trait, or an educational intervention might benefit students with lower initial skills more than those with higher skills. Heterogeneous Treatment Effect (HTE) analysis seeks to estimate how the treatment effect varies as a function of individual characteristics. We denote the Conditional Average Treatment Effect (CATE) for an individual with features $x$ as:\n\n$$\\tau(x) = E[Y(1) - Y(0)\\mid X = x]$$\n\nwhere $X$ represents the covariates (individual characteristics). In plain language, $\\tau(x)$ is the expected treatment effect for an individual with attributes $x$. If $\\tau(x)$ is the same for all $x$, the treatment effect is homogeneous (everyone benefits the same amount). If $\\tau(x)$ varies — for instance, $\\tau(x)$ is higher for some people and lower or even negative for others — then we have treatment effect heterogeneity.\n\n**Standard parametric approaches vs. HTE**: Traditionally, researchers might use regression models with interaction terms to examine heterogeneity. For example, one might include terms like Treatment $\times$ Covariate in a linear regression to see if the effect differs by that covariate. However, standard parametric models impose strong assumptions. Often a simple model assumes a homogeneous effect (one treatment coefficient for all) unless specific interactions are added. Even when interactions are included, the model usually assumes a particular functional form (e.g. linear or additive effects of covariates). This can be very restrictive – real heterogeneity might involve complex, non-linear combinations of attributes that are hard to pre-specify. If we try to include many interaction terms or non-linear effects (such as polynomials or splines), we risk model misspecification (choosing the wrong form) and overfitting in small samples [@Sadique2022]. In short, classical regression approaches require us to guess the right pattern of heterogeneity in advance, and they treat everything outside that guess as noise.\n\n**Example:** imagine a study on a new depression therapy. A simple model might assume the therapy has the same effect on all patients (homogeneous effect). If we suspect younger patients respond differently than older patients, we could add an age interaction. But what if the effect actually depends on a combination of age and baseline symptom severity in a non-linear way? Capturing that with a parametric model would require carefully specifying complex interactions (e.g. Age $\times$ Severity, perhaps non-linearly) and would quickly become impractical with many covariates.\n\nBecause of these challenges, we turn to a more flexible, data-driven approach: causal forests. These allow the data to reveal heterogeneity without us having to specify a particular form.\n\n### Step 3: Estimating Individualised Effects with Causal Forests\n\nA causal forest (as implemented in grf) is a machine learning method that extends the idea of random forests to estimate $\\tau(x)$ (the CATE) for each individual. A causal forest is an ensemble of many decision trees that are grown specifically to capture differences in treatment effect across individuals [@grf2024]. In essence, each tree in a causal forest partitions the data based on covariates, aiming to group together individuals with similar treatment responses. By averaging over many such trees (each built on a random subset of data and covariates), the forest produces a robust estimate of the individual treatment effect for each person’s feature profile.\n\n**How causal forests avoid strong assumptions**: Unlike a parametric model, a causal forest model does not assume the treatment effect is constant or linear in the covariates. It can discover non-linear relationships and interactions automatically. For example, a causal forest might find that for younger participants the therapy is very effective, whereas for older participants with high baseline depression the effect is smaller – even if we didn't explicitly program an 'age $\times$ baseline' interaction. The forest algorithm will try splitting the data on different covariates to maximize differences in outcomes between treated and control within each split, effectively letting the data determine where the treatment effect differs. This means we are not forcing a single form of heterogeneity; the model can capture complex patterns (such as a treatment working only at certain combinations of characteristics) that a linear model might miss.\n\n**Causal forest mechanics:** Each tree in a causal forest is constructed in a way that is similar to a standard random forest, but the splitting criterion is tailored to treatment effect estimation. At each split, the algorithm looks for a covariate and a cut-point that best separate the data into two groups with different treatment effects. In other words, it tries to maximize the contrast in outcomes between treated and control in the two child nodes [@grf2024]. This is different from a standard regression tree that would split based on differences in outcome levels; the causal tree splits based on differences in **treatment effects. Once the tree is grown, the treatment effect within each final leaf can be estimated by comparing the average outcomes of treated vs. control units in that leaf. To get a prediction for a new individual with features $x$, we drop that individual down each tree (finding which leaf they land in), and take the leaf's estimated treatment effect. The causal forest averages those estimates across many trees, yielding $\\hat{\tau}(x)$, an estimate of that individual's treatment effect.\n\nImportantly, grf uses an approach called 'orthogonalisation' (or 'Robinson’s transformation') to handle confounding in observational data: it first estimates the outcome without treatment and the propensity of treatment, then focuses the forest on the residuals [@wager2018]. This ensures that the forest primarily learns the difference attributable to treatment, not just baseline outcome differences or propensities. (In a randomised experiment, this step is less critical since treatment assignment is independent of $X$, but it is very useful in observational studies.)\n\nBy using a causal forest, we obtain an estimate $\\hat{\\tau}(x_i)$ for each individual $i$ in our sample (often called individual treatment effect or ITE estimates). These estimates tell us who benefits more or less from the treatment according to the model.\n\n### Step 4: Honest Estimation and Out-of-Bag Validation\n\nOne concern with flexible models (like forests) is overfitting – they might pick up random noise as if it were a real pattern, especially when trying to estimate many individual effects. The `grf` package addresses this through a technique called honest estimation and by using out-of-bag (OOB) validation.\n\n**Honest trees:** an honest causal tree is built so that the data used to decide where to split the tree is separate from the data used to estimate the treatment effect in each leaf [@wager2018]. In practice, this can be done by randomly splitting the sample into two halves: one half is used to grow the structure of the tree (find the splits based on covariates), and the other half is used to compute the treatment effect estimates within the leaves. Because an observation is either used for splitting or for estimation (but not both) in any given tree, the estimates in each leaf are unbiased by the selection of that leaf. This honest approach guards against a tree that carves the data too finely to chase noisy differences that will not hold up in new data [@wager2018]. Causal forests in `grf` implement honesty by default, meaning each tree in the forest is grown in a way that ensures the treatment effect estimate at the end is an 'out-of-sample' estimate relative to the splits that created the leaf [@grf2024].\n\nOut-of-bag predictions: in a random forest, each tree is typically built on a bootstrap sample (random sampling with replacement) of the data. This means about one-third of the observations are left out (not used) in that tree – these are called 'out-of-bag' observations for that tree. Since they were not used to train that tree, we can use them to get an unbiased prediction for those observations. `grf` uses this idea to produce OOB estimates of $\\tau(x)$ for every training point: each observation’s OOB estimate is the average of predictions from all trees where that observation was not in the training sample. This is like a built-in cross-validation. The OOB estimates are honest in the sense that for each individual, we're predicting their treatment effect using only trees that did not observe that individual's outcome during training [@grf2024]. These OOB estimates can be used to assess model fit and to perform certain tests (with caution, as we discuss later).\n\nBy combining honesty and OOB estimation, causal forests avoid the worst of overfitting while still using all the data. In fact, these measures enable the forest to provide valid confidence intervals and variance estimates for the treatment effects. For example, grf can calculate standard errors for $\\hat{\\tau}(x)$ using the variability across trees (with a method that groups trees and compares their predictions) [@grf2024]. The bottom line is that the forest's individual effect estimates are 'honest' (out-of-sample) estimates, increasing our trust that these effects are not just reflecting noise.\n\n### Step 5 Handling Missing Data and Basic Validation\n\nEmpirical data often have missing values in some covariates. Unlike many traditional methods that might require dropping observations or imputing values, `grf` can handle missing covariate values directly. `grf` uses a strategy called the Missing Incorporated in Attributes (MIA) splitting rule [@grf2024]. In simple terms, when considering a split on a variable that has some missing values, the algorithm treats 'missing' as its own category: it finds splits that can send missing values one way and non-missing another way. For example, suppose we have a covariate like income where some values are missing. A causal tree could have a split that says 'if Income > 50K go left, if Income <= 50K go right, and if Income is missing, also go right (or go left)' -- essentially handling the missingness within the tree structure. This way, we do not have to drop people with missing income; the forest can still use partial information from other covariates and also possibly learn if 'missingness' itself is informative (perhaps not reporting income correlates with some outcome). By using MIA, the causal forest implicitly handles missing data without a separate imputation step, preserving information and avoiding bias that might come from improper imputation [@grf2024].\n\nBeyond missing data, another core aspect of model validation is ensuring our findings are not artifacts of particular sample splits or tuning choices. Although random forests typically have a few hyperparameters (number of trees, depth, etc.), the defaults in `grf` are often reasonable, and we employ them here. Users can use cross-validation to fine-tune parameters such as minimum leaf size or complexity if needed. For example, one might try different minimum leaf sizes and check which yields the best out-of-sample predictive performance for treatment effects. However, because causal forests average over many trees and use honesty, they are relatively robust and often do not require extensive tuning.\n\n\n### Step 6 Global evidence with RATE (AUTOC & Qini)\n\nAfter fitting a causal forest and obtaining individualised effect estimates $\\hat{\tau}(x)$, a crucial question is: do these estimates provide evidence that treatment effects truly vary, or could the apparent heterogeneity be just noise? In other words, we want to test the hypothesis that the treatment effect is actually the same for everyone.\n\nWe begin with an approach implemented in the `grf` framework that uses the Rank-Weighted Average Treatment Effect (RATE) metrics as a basis for a hypothesis test [@grf2024]. The idea is to ask: if we were to use our estimated $\\hat{\\tau}(x)$ to prioritise who gets treated, would outcomes improve compared to treating people at random? If there were no heterogeneity, then any rule based on $X$ (including our $\\hat{\\tau}(x)$ estimates) should do no better than random assignment. If there is heterogeneity and we have identified it correctly, then targeting those with higher $\\hat{\\tau}(x)$ should yield better outcomes on average.\n\nConcretely, we can sort individuals by their estimated benefit $\\hat{\tau}(x)$ (from highest to lowest). Suppose we progressively treat people in that order – first the top 10% most likely to benefit, then 20%, and so on. If heterogeneity is meaningful, the people with higher $\\hat{\\tau}(x)$ should indeed have larger actual treatment effects on average, so treating them first gives us a bigger gain than treating a random 10% or 20%. We can summarise this with a Targeting Operator Characteristic (TOC) curve – analogous to an ROC curve in classification – which for each fraction $q$ of the population treated (x-axis) shows the excess treatment effect achieved by targeting based on $\\hat{\tau}$ (y-axis) compared to random treatment [@grf2024]. If there were no heterogeneity, this curve would be flat (no gain from targeting). If there were heterogeneity, the curve would rise – especially at low $q$, where we are focusing on the top predicted responders [refer to @yadlowsky2021evaluating].\n\nThe test for heterogeneity can then be based on the area under this TOC curve or other summaries of it. Specifically, grf defines:\n\n- **AUTOC:** the Area Under the TOC Curve. This essentially integrates the benefit of targeting across all possible fractions treated [@grf2024]. If there's no heterogeneity, AUTOC should be zero (no area under the curve, since the curve is flat at zero gain).\n\n- **Qini:** a related metric (named after a concept by Radcliffe, 2007) which is a weighted area under the TOC [@radcliffe2007using]. The Qini index weights larger fractions more heavily (technically, Qini = $\\int_0^1 q \\cdot \\mathrm{TOC}(q),dq$) [@radcliffe2007using]. Intuitively, AUTOC tends to emphasise the extremes (are there a small group of people with very large effects?) whereas Qini gives more weight to broader improvements (moderate effects spread across more people) [@yadlowsky2021evaluating].\n\nBoth metrics aggregate the **whole** targeting curve.  A single negative stretch can drag the average below zero, so a reliably negative RATE warns that *no blanket ranking policy should be adopted*, no matter how attractive the extreme tail looks.\n\nTo test for heterogeneity, we can check whether these metrics are significantly greater than zero. Under $H_0$ (no heterogeneity), we expect no gain from targeting, so, for example, AUTOC = 0. We can compute an estimate of AUTOC or Qini from the data (using held-out samples to avoid bias) and compute a standard error. Thanks to theoretical results, these metrics satisfy a central limit theorem, so we can do a simple $t$-test. Essentially, we test:\n\n- $H_0$: RATE (e.g., AUTOC or Qini) = 0 (no heterogeneity detectable)\n- $H_A$: RATE $> 0$\n\nIf the test rejects $H_0$, we have evidence that some individuals benefit more than others, beyond what we would expect by chance [@grf2024]. This is strong evidence of treatment effect heterogeneity. If we fail to reject, it suggests that any differences our forest found might not be statistically reliable – in other words, we cannot be sure the treatment effect isn't basically uniform.\n\nTo summarise this step: we use the forest's output to construct a test for heterogeneity. This moves us from simply eyeballing $\\hat{\\tau}(x)$ values (which can be noisy) to a rigorous statistical test of whether tailoring treatment based on $X$ has potential value.\n\n### Step 7 Quantifying policy value with RATE metrics\n\nBeyond hypothesis testing, the RATE framework is valuable for quantifying how much improvement we might gain by individualised treatment policies. RATE stands for Rank-Weighted Average Treatment Effect, which as described, comes from considering a treatment prioritisation rule $S(X)$ that ranks individuals by some score (in our case, the score is the predicted benefit $\\hat{\\tau}(X)$) [@grf2024]. We want to evaluate how good this rule is at targeting treatment to those who benefit the most.\n\nTwo key RATE metrics have already been mentioned: AUTOC and Qini. Both summarise the TOC curve (the performance of our targeting rule across the range of possible treated fractions). To interpret them in plain terms:\n\n- AUTOC (Area Under the Targeting Curve): This is the integral of the improvement achieved by targeting, across all possible proportions treated. An equivalent interpretation is that AUTOC is a weighted average of treatment effects where higher weight is placed on the highest-score individuals (since at very low fractions $q$, we’re only treating the top-scoring people). A larger AUTOC means our rule does a very good job at ranking people – the top-ranked have much bigger effects than the average. We refer to this as one type of RATE metric.\n\n- Qini: this is another summary of the targeting curve, but uses a different weighting (in fact, linearly increasing weight by fraction treated) In practice, that means Qini cares more about how well we do when treating larger portions of the population, not just the very top slice. If treatment benefits are spread out, the Qini will capture that better. We can think of Qini as measuring the aggregate gain from using the rule as we expand treatment – it places equal emphasis on high-benefit individuals and those with more modest benefit (because as you increase $q$, the weight $q$ in the integral increases) [@yadlowsky2021evaluating].\n\nBoth AUTOC and Qini are numbers (scalars) that we can compute for a given prioritisation rule (like the causal forest's ranking). They can be compared to baseline strategies. For instance, one baseline is a policy that does not use any covariates – e.g. treat a random fraction $q$ of people. That baseline would by definition have a TOC curve of zero (no preferential gain) and thus AUTOC = Qini = 0. Another baseline could be treating everyone (which yields the ATE as the outcome gain, but of course no targeting because everyone is treated.  This latter baseline is the rule that we use here. We are interested in incremental improvements over the ATE by targeting  $\\hat{\\tau}(X)$).\n\nIn a policy-setting context, these metrics help answer the question: 'Could we improve outcomes by targeting the treatment to specific individuals instead of a one-size-fits-all approach?' and 'If yes, how large might that improvement be?' For example, suppose the ATE of a job training program is an earnings increase of USD 500 on average. A statistically reliable Qini or AUTOC might reveal that if we only gave the program to the half of people who benefit the most (according to some characteristics), the average impact for those treated could be much higher, say $1000, and essentially zero for those not treated – implying resources can be better allocated. On the other hand, if no heterogeneity were found, we cannot be certain that targeting would change the payoff. Additionally, we might find reliable evidence that **targeting** performs worse than random assignment, and advise caution if the aim is to maximise benefits across the population.\n\n\nTo make this concrete, `grf` provides a function rank_average_treatment_effect() that computes these metrics and even performs statistical tests. An analyst might use it in an applied study to report, for example: 'Using the causal forest’s predicted CATEs as a prioritisation rule, we find a rank-weighted treatment effect (AUTOC) of 0.15 (SE = 0.05), indicating a substantial improvement from targeted treatment over a non-targeted policy [@grf2024]. The Qini coefficient is 0.10 (SE = 0.03). Both are reliably greater than zero, reinforcing the presence of actionable heterogeneity. These numbers would be in the units of the outcome (or outcome difference), and they tell policymakers the potential gain from personalised treatment assignment.\n\nIn summary, RATE metrics such as AUTOC and Qini serve a dual purpose: (1) they statistically test for any heterogeneity (as discussed in Step 6) and (2) they quantify how effective our estimated heterogeneity is for improving outcomes through targeting. They help translate complex heterogeneity estimates into a single measure of 'policy value.' If these metrics are small or insignificant, it means even if effects vary, it may not be useful for targeting (perhaps the variation is too minor or too uncertain). If they are large, it suggests real potential to increase impact by focusing the treatment where it works best.\n\n### Step 8 Budget-constrained gains via Qini curves\n\nWhile single-number metrics (AUTOC, Qini indices) are useful, it is often enlightening to look at the Qini curve or the underlying targeting curve visually. The Qini curve plots the cumulative gain in outcome as we allocate treatment to a larger fraction of the population, ranking by predicted treatment effect [@grf2024]. The x-axis typically is the fraction (or percentage) of the population treated (sorted from highest predicted benefit downwards), and the y-axis is the net gain achieved by that policy compared to treating that fraction at random.\n\nFor example, @fig-example-qini presents a Qini curve result in a causal forest analysis investigating the effects of religious service attendance on personality (here 'Agreeableness'). The straight, solid (orange) line indicates the expected gains from treating indiscriminately according to the ATE. The dashed (blue) curve indicates the expected gains from treating using  $\\hat{\\tau}(X)$). The x-axis ('spend') represents the fraction of individuals treated (scaled to a budget), and the y-axis ('gain') represents the improvement in outcome (e.g., additional treatment effect) from targeting those individuals versus random assignment. A steeper, higher dashed curve indicates that the model-based targeting yields much better outcomes for the treated fraction than random selection (solid line). This curve stops (or 'plateaus') after treating approximately 50% of population, because at that point we have assigned treatment to the units predicted to benefit, $\\hat{\\tau_i}(X)> 0)$.\n\nIn our analysis, we report budget-constrained thresholds for treating the top 20% or 50% of recipients. Policymakers often have limits on how many people can be treated (due to cost or other constraints). The Qini curve allows us to zoom in on specific treatment fractions. For instance, if we can only treat 20% of the population, we look at $q = 0.2$ on the x-axis. The y-value of the Qini curve at $0.2$ tells us the expected gain from treating the top 20% (as ranked by the model) compared to treating 20% randomly.\n\nThe Qini curve allows us to visualise and explain how the effectiveness of the treatment allocation changes as we expand who gets treated. For an applied researcher, this is very useful. We do more than not that 'heterogeneity exists.'  We are able to advise whether, 'if we have a budget to treat X% of people, here's what outcome we can expect.' For example, suppose an education intervention has an average effect of 5 test score points. The Qini analysis might show that focusing on the top 50% of the population (maybe those with certain demographic profiles) could yield an average effect of .15 SD units for those expected to benefit, meaning we would save resources on those unlikely to gain. At 100% (treating everyone), we're back to average treatment effect, which in this example is about half this amount (0.07 SD units). So the policy insight is: if only 50% can be afforded, target that group to maximise impact.\n\nTo summarise, Qini curves allow us to identify and communicate the value of targeted policies at specific coverage levels. They show whether the benefit of the treatment is concentrated in a small segment of the population or more widely distributed. When making policy recommendations, one could use the Qini curve to decide, for instance, 'we should implement the program for the top 50% most likely to benefit; beyond 50%, the returns diminish to roughly the average effect, so including more people isn’t cost-effective.' This level of analysis goes beyond saying 'there is heterogeneity'; instead, we quantifies *how much improvement* is possible and for what percentage of a target population.\n\n**Practical note:** because the Qini curve is derived from the **same validation split** used for RATE, both views sit on equal footing and over-optimism is checked.\n\n\n+### Step 9 Avoiding over-fitting in policy evaluation (sample splitting for RATE/Qini)\n\nAn important statistical caution: when we use the same data to both train a model (such the causal forest) and evaluate its performance (like computing how well targeting does), we can get overly optimistic results. Even though the causal forest provides OOB estimates that are ostensibly out-of-sample for each individual, there is still a subtle form of overfitting possible if we are not careful. The forest was constructed to maximise heterogeneity in the training data, so using those same estimates to evaluate the policy can bias the evaluation upward (we might overstate the value of targeting because we are implicitly reusing the data).\n\nTo ensure valid inference, the best practice is to use explicit sample splitting or cross-fitting for the evaluation stage. This means, for example, after training the causal forest on the whole dataset (or a portion of it), we assess the RATE or Qini metrics on a fresh hold-out set that was not used in training. Here we use a separate hold-out set in which we train {{training_proportion}} of the data and use the unseen remainder as the validation set.\n\n\nWhy do we do this? Even though the forest’s OOB predictions are not directly from a model that saw that observation's outcome, there remains correlation – each observation’s prediction is an average from many trees, and while any given tree didn't see that observation, it saw many others including some that are also used in evaluating the policy. There is also the fact that OOB predictions are a form of cross-validation but not a true independent test, especially since the forest structure was influenced by all data. To be rigorous, researchers often do a double sample split: one split to train the forest, and a second split (completely independent) to compute the policy metrics like Qini or evaluate a specific targeting rule. This double-splitting ensures that when we say 'targeting the top 20% yields X improvement,' that claim is verified on data that played no part in determining who was top 20%. Thus, our inference (confidence intervals, p-values for heterogeneity) remains valid and not overly optimistic.\n\nIn plain terms, our workflow is as follows:\n\n1. Split the data into two parts: A and B.\n2. Use part A to train the causal forest and get $\\hat{\tau}(x)$.\n3. Use part B to evaluate heterogeneity: apply the targeting rule in B, compute observed gains, and estimate RATE/Qini metrics on that held-out data.\n\n\nBy doing this, when we report 'p = 0.01 for heterogeneity' or 'Qini = 0.10 at 20% spending', we know these numbers are honest assessments of how the model would perform on new data, not just the data we fit it to.\n\nIn short, even with OOB estimates, further sample splitting is used for final evaluation to ensure our conclusions about heterogeneous effects and the benefits of targeting are reliable. This extra step is crucial for rigour: it prevents us from convincing ourselves that a complicated model is useful when in fact it might be explaining noise.\n\n### Step 10 Transparent targeting rules with policy trees\n\nFinally, once we have evidence of heterogeneity and an effective way to target treatment, we might want to translate the complex model into a simple decision rule. Causal forests, while powerful, are 'black box' in nature – they may involve hundreds of trees and intricate splits that are not easy to interpret. For practical decision-making (especially in policy contexts), stakeholders often prefer a simple rule (for example, a checklist or a flowchart) that determines treatment eligibility. This is where policy trees come in.\n\nA policy tree is essentially a simple decision tree that assigns treatment or control based on a few covariates splits, optimised to yield good outcomes. The idea is to summarise the individual treatment effects $\\hat{\\tau}(x)$ (or directly use the data) into a set of if-then rules that approximate the optimal targeting. For instance, a policy tree might look like: 'If age < 25 and baseline severity is high, give treatment; if age ≥ 25 and baseline severity is low, do not treat,' etc. These rules are much easier to communicate than a black-box forest.\n\n`grf` integrates with the `policytree` package to derive an optimal decision tree given the causal forest's estimates [@policytree_package_2024]. Our procedure is as follows: use the forest's estimates or doubly robust scores as input to a decision tree algorithm that maximises the expected outcome (welfare) under that tree policy. In other words, we finds splits that best separate who should be treated vs not to improve the overall result. The result is a shallow tree (often depth 1, 2, or 3) that is much easier to interpret than the full forest. Here we use a decision tree of depth = 2.\n\n**Why use policy trees?** Apart from interpretability, policy trees can enforce fairness or simplicity constraints and avoid overfitting by limiting complexity. A shallow tree might capture the broad strokes of heterogeneity (e.g., young vs old, or high risk vs low risk) in a way that practitioners can double-check with domain knowledge. As an example from `grf` documentation: 'Deciding who to assign the program based on a complicated black-box CATE function may be undesirable if policymakers want transparent criteria. Likewise, it may be problematic for participants to learn they were denied a beneficial program solely because a black-box algorithm predicted low benefit. In such settings, we want an interpretable policy, for example, a shallow decision tree that says ‘Alice is assigned treatment because she is under 25 and lives in a disadvantaged neighborhood' see: [https://grf-labs.github.io/grf/articles/policy_learning.html](https://grf-labs.github.io/grf/articles/policy_learning.html). This nicely illustrates how a policy tree can provide a rationale in human terms.\n\n+**Training and validation for policy trees:** As when **constructing** causal forests and evaluating heterogeneity with RATE/Qini, we must be careful to avoid over-fitting.\nIt is tempting to use the same data that suggested heterogeneity to also choose the best splits for the policy tree, but that can lead to optimistic results. The optimal tree is chosen to fit the training data well – if we do not validate it, we might pick a tree that works by chance quirks of the data. Therefore, we use cross-validation to select the tree's depth and sample splitting to evaluate its performance, using {{train_proportion_decision_tree}} to train the tree and the remainder to **validate** it.\n\nPolicy tree analysis holds both theoretical and practical interest. Rather than picking out a familiar category grouping such as gender or ethnicity, policy trees reveal that effect vary by resource availability.\n\nOverall, policy trees condense the insights from causal forests into actionable guidelines. We emphasise that deriving these guidelines includes rigorous validation: we use one part of the data to learn the policy and another to test it. This ensures that the simple rules we recommend (e.g. 'treat those with lower time demands; do not treat incomes at a certain level') are supported by evidence rather than being artifacts of noise.\n\nAlthough estimating heterogeneous treatment effects and deriving actionable policy rules can be both theoretically and practically important, two considerations should temper our enthusiasm.\n\nFirst, the factors highlighted in policy trees are predictors of treatment-effect variability, but these predictors do not themselves have a causal interpretation. Returning to the example above, we should not infer that intervening to set someone’s travel and housework times to different values would change the variability in response. To understand the causal effects of joint interventions, we would need a different analysis. Decision trees are important because they highlight segments likely to benefit, but they do not clarify the effects of changing a population’s structure.\n\nSecond, decisions about prioritising treatment rules are often ethical and political. Even if we set aside uncertainties in the modelling process, few would argue that fairness and justice should be determined by optimisation rules alone. Such questions are typically resolved through democratic processes that involve stakeholder consultations, reflection on social values, a reckoning with historical inequities, and considerations beyond the scope of statistical analyses.\n",
      "grf_long": "\nIn this appendix we show how to estimate causal effects with the `grf` R package (Generalised Random Forests).\n\n#### Menu of HTE diagnostics\n\nInvestigators can choose one, some, or all of the following tools, depending on the scientific or operational question:\n\n* **RATE AUTOC / RATE Qini (global evidence)** – 'Should we abandon a uniform policy at all?'  Tests the null of no actionable heterogeneity on a validation split.\n* **Qini curves (budget lens)** – 'If we can treat only up to $p\\%$, what uplift do we expect?'  Reads the targeting curve at specific spend levels.\n* **Policy trees (decision rule)** – 'Which simple, transparent allocation rule maximises expected welfare under constraints?'  Optimises welfare directly, agnostic to hypothesis-testing conventions.\n\nThese tools are complementary rather than sequential.  A study may stop after RATE, skip RATE and go straight to a decision rule, or report the full trio; the choice should reflect the primary inferential aim — evidence, optimisation, or communication.\n\nBelow we **illustrate** all three analyses in turn.  In practice an investigator may run only the subset that addresses their question.\n\n\nHowever, we begin with the overall average treatment effect (ATE), investigate whether effects vary (heterogeneity), and --where useful -- estimate individualised effects and derive simple, actionable treatment rules.\n\n### Step 1 Estimating the Average Treatment Effect (ATE)\n\nThe ATE answers a simple question: on average, how much does treatment change the outcome? In a well‑randomised trial (or an observational study with adequate control), we estimate it with the difference in mean outcomes between treated and control units. Formally,\n\n$${\\rm ATE}=E\\,[Y(1)-Y(0)],$$\n\nwhere $Y(1)$ and $Y(0)$ denote potential outcomes under treatment and control.\n`grf::average_treatment_effect()` computes the ATE, using doubly‑robust estimation for precision. This step gives us a baseline—say, the new therapy lifts well‑being by 0.25 points (1–7 scale).\n\nWe start here because the ATE tells us whether the treatment works **on average** if everyone were treated versus no-one. Yet a zero (or noisy) ATE does not rule out helpful or harmful effects for sub-groups, and a non-zero ATE does not guarantee benefits for all.  We often want to examine heterogeneity.\n\n\n+### Step 2 Assessing Heterogeneous Treatment Effects (HTE)\n\nTreatments seldom work equally for everyone. We define the conditional average treatment effect (CATE) for covariate profile $x$ as\n$$\\tau(x)=E\\,[Y(1)-Y(0)\\mid X=x].$$\nIf $\\tau(x)$ is constant, effects are homogeneous; if it varies, we have heterogeneity.\n\nClassical regression tackles heterogeneity via interaction terms, but that approach demands strong functional‐form assumptions. Real‑world heterogeneity can be non‑linear and high‑dimensional; guessing the correct model risks misspecification or over‑fitting [@Sadique2022]. Thus we turn to causal forests, which let the data speak.\n\n\n+### Step 3 Estimating Individualised Effects with Causal Forests\n\nA causal forest is an ensemble of 'honest' causal trees grown to capture **differences** in treatment effects rather than outcome levels [@grf2024]. Each tree splits the data to maximise treated‑versus‑control contrasts within leaves, and the forest averages those leaf‑level estimates to give\n$$\\hat\\tau(x)$$\nfor every individual.\n\n Advantages:\n\n- **Flexibility** – no need to pre‑specify interactions or non‑linearities.\n- **Orthogonalisation** – residualising outcomes and treatment probabilities focuses the forest on causal signal [@wager2018].\n- **Per‑person estimates** – we obtain $\\hat\\tau(x_i)$ for every $i$.\n\n+### Step 4 Honest Estimation and Out-of-Bag Validation\n\nOver‑fitting lurks in flexible models. `grf` combats this with 'honest' trees: one half‑sample picks splits, the other half estimates effects, ensuring each leaf estimate is out‑of‑sample. Out‑of‑bag (OOB) predictions—averaging over trees that did **not** train on an observation—provide further unbiased validation and standard errors [@grf2024].\n\n+### Step 5 Handling Missing Data and Basic Validation\n\nMissing covariate values? No drama. `grf` uses the MIA (Missing Incorporated in Attributes) rule: it treats 'missing' as a legitimate split category, so we keep cases rather than impute or drop them [@grf2024]. Hyper‑parameters rarely need fine‑tuning, though cross‑validation can refine minimum leaf size, tree depth, and the like.\n\n+### Step 6 Global evidence with RATE (AUTOC & Qini)\n\nDo the estimated $\\hat\\tau(x)$ really differ, or is it just noise? The RATE framework answers this. We rank individuals by $\\hat\\tau$ and ask whether treating the top scorers improves outcomes relative to random assignment. The Targeting Operator Characteristic (TOC) curve plots this gain over treatment fractions $q$. Two scalar summaries are\n\n* **AUTOC** – area under the TOC; accentuates extreme responders.\n* **Qini** – a weighted area (weights grow with $q$); favours broader gains [@yadlowsky2021evaluating].\n\nUnder $H_0$ (no heterogeneity) both metrics equal zero; `grf::rank_average_treatment_effect()` supplies estimates, standard errors, and $t$‑tests. Rejecting $H_0$ signals actionable heterogeneity.\n\nBoth metrics aggregate the whole targeting curve, so a single negative stretch can drag the average below zero.  Thus a reliably negative RATE warns that *no blanket ranking policy should be adopted*, no matter what the tail behaviour looks like.\n\nRATE therefore answers a *global* question: if we were to use our estimated $\\hat{\\tau}(x)$ to prioritise who gets treated **across the entire population**, would outcomes improve compared with treating everyone (or no-one) identically?  If there were no heterogeneity, then any rule based on $X$ (including our $\\hat{\\tau}(x)$ estimates) should do no better than random assignment.\n\n+### Step 7 Quantifying policy value with RATE metrics\n\nBeyond significance, AUTOC and Qini quantify the **magnitude** of improvement from targeting. A large AUTOC means a prioritisation rule sharply distinguishes high‑benefit individuals; a large Qini means gains persist over wider coverage. Policymakers can weigh these gains against costs—because budgets rarely stretch to treating everyone (as any Kiwi running a lab grant knows too well).\n\n### Step 8 Budget-constrained gains via Qini curves\n\nRATE tells us whether heterogeneity exists in aggregate; the Qini curve drills down to **how much uplift we get at each spend level**.  A planner who can only afford to treat the top 20 % cares about the leftmost fifth of the curve, even if the global RATE is negative.\n\n*Practical note:* because the Qini curve is read off the **same validation split** used for RATE, comparisons are on equal footing and over-optimism is kept in check.\n\nIn our analysis, we report budget-constrained thresholds for treating the top 20% or 50% of recipients. Policymakers often have limits on how many people can be treated (due to cost or other constraints). The Qini curve allows us to zoom in on specific treatment fractions. For instance, if we can only treat 20% of the population, we look at $q = 0.2$ on the x-axis. The y-value of the Qini curve at $0.2$ tells us the expected gain from treating the top 20% (as ranked by the model) compared to treating 20% randomly.\n\nThe Qini curve allows us to visualise and explain how the effectiveness of the treatment allocation changes as we expand who gets treated. For an applied researcher, this is very useful. We do more than not that 'heterogeneity exists.'  We are able to advise whether, 'if we have a budget to treat X% of people, here's what outcome we can expect.' For example, suppose an education intervention has an average effect of 5 test score points. The Qini analysis might show that focusing on the top 50% of the population (maybe those with certain demographic profiles) could yield an average effect of .15 SD units for those expected to benefit, meaning we would save resources on those unlikely to gain. At 100% (treating everyone), we're back to average treatment effect, which in this example is about half this amount (0.07 SD units). So the policy insight is: if only 50% can be afforded, target that group to maximise impact.\n\nTo summarise, Qini curves allow us to identify and communicate the value of targeted policies at specific coverage levels. They show whether the benefit of the treatment is concentrated in a small segment of the population or more widely distributed. When making policy recommendations, one could use the Qini curve to decide, for instance, 'we should implement the program for the top 50% most likely to benefit; beyond 50%, the returns diminish to roughly the average effect, so including more people isn’t cost-effective.' This level of analysis goes beyond saying 'there is heterogeneity'; instead, we quantifies *how much improvement* is possible and for what percentage of a target population.\n\n### Step 9 Avoiding over-fitting in policy evaluation (sample splitting for RATE/Qini)\n\nAn important statistical caution: when we use the same data to both train a model (such the causal forest) and evaluate its performance (like computing how well targeting does), we can get overly optimistic results. Even though the causal forest provides OOB estimates that are ostensibly out-of-sample for each individual, there is still a subtle form of overfitting possible if we are not careful. The forest was constructed to maximise heterogeneity in the training data, so using those same estimates to evaluate the policy can bias the evaluation upward (we might overstate the value of targeting because we are implicitly reusing the data).\n\nTo ensure valid inference, the best practice is to use explicit sample splitting or cross-fitting for the evaluation stage. This means, for example, after training the causal forest on the whole dataset (or a portion of it), we assess the RATE or Qini metrics on a fresh hold-out set that was not used in training. Here we use a separate hold-out set in which we train {{traning_proportion}} of the data, and use the unseen remainder as the validation set.\n\nWhy do we do this? Even though the forest’s OOB predictions are not directly from a model that saw that observation's outcome, there remains correlation – each observation’s prediction is an average from many trees, and while any given tree didn't see that observation, it saw many others including some that are also used in evaluating the policy. There is also the fact that OOB predictions are a form of cross-validation but not a true independent test, especially since the forest structure was influenced by all data. To be rigorous, researchers often do a double sample split: one split to train the forest, and a second split (completely independent) to compute the policy metrics like Qini or evaluate a specific targeting rule. This double-splitting ensures that when we say 'targeting the top 20% yields X improvement,' that claim is verified on data that played no part in determining who was top 20%. Thus, our inference (confidence intervals, p-values for heterogeneity) remains valid and not overly optimistic.\n\nIn plain terms, our workflow is as follows:\n\n1. Split the data into two parts: A and B.\n2. Use part A to train the causal forest and get $\\hat{\\tau}(x)$.\n3. Use part B to evaluate heterogeneity: apply the targeting rule in B, compute observed gains, and estimate RATE/Qini metrics on that held-out data.\n\nBy doing this, when we report 'p = 0.01 for heterogeneity' or 'Qini = 0.10 at 20% spending', we know these numbers are honest assessments of how the model would perform on new data, not just the data we fit it to.\n\nEven with OOB estimates, further sample splitting guards against optimistic bias.  This extra step is crucial for rigour: it prevents us from convincing ourselves that a complicated model is useful when in fact it might be explaining noise.\n\n### Step 10: Translating Insights into a Policy Tree\n\nCausal forests, while powerful, are 'black box' in nature – they may involve hundreds of trees and intricate splits that are not easy to interpret. For practical decision-making (especially in policy contexts), stakeholders often prefer a simple rule (for example, a checklist or a flowchart) that determines treatment eligibility. This is where policy trees come in. We addresse the *operational* question: given a budget and evidence of heterogeneity, which covariate splits deliver the largest welfare gain in a form stakeholders can audit?  Rather than picking out a familiar category grouping such as gender or ethnicity, policy trees reveal how effect variation aligns with resource availability.\n\nA policy tree is essentially a simple decision tree that assigns treatment or control based on a few covariates splits, optimised to yield good outcomes. The idea is to summarise the individual treatment effects $\\hat{\\tau}(x)$ (or directly use the data) into a set of if-then rules that approximate the optimal targeting. For instance, a policy tree might look like: 'If age < 25 and baseline severity is high, give treatment; if age ≥ 25 and baseline severity is low, do not treat,' etc. These rules are much easier to communicate than a black-box forest.\n\n`grf` integrates with the `policytree` package to derive an optimal decision tree given the causal forest's estimates [@policytree_package_2024]. We feed either $\\hat\\tau(x)$ or doubly-robust scores into `policytree::policy_tree()`, which searches for splits that maximise expected welfare subject to a depth constraint.  The result is a shallow tree (often depth 1–2) that is far easier to communicate than the full forest.\n\n\n**Why use policy trees?** Apart from interpretability, policy trees can enforce fairness or simplicity constraints and avoid overfitting by limiting complexity. A shallow tree might capture the broad strokes of heterogeneity (e.g., young vs old, or high risk vs low risk) in a way that practitioners can double-check with domain knowledge. As an example from `grf` documentation:\n\n> Deciding who to assign the program based on a complicated black-box CATE function may be undesirable if policymakers want transparent criteria. Likewise, it may be problematic for participants to learn they were denied a beneficial program solely because a black-box algorithm predicted low benefit. In such settings, we want an interpretable policy, for example, a shallow decision tree that says ‘Alice is assigned treatment because she is under 25 and lives in a disadvantaged neighborhood' see: [https://grf-labs.github.io/grf/articles/policy_learning.html](https://grf-labs.github.io/grf/articles/policy_learning.html).\n\nThis nicely illustrates how a policy tree can provide a rationale in human terms.\n\n+**Training and validation for policy trees:** As when **constructing** causal forests and evaluating heterogeneity with RATE/Qini, we must avoid over-fitting. It is tempting to use the same data that suggested heterogeneity to also choose the best splits for the policy tree, but that can lead to optimistic results. The optimal tree is chosen to fit the training data well – if we do not validate it, we might pick a tree that works by chance quirks of the data. Therefore, we use cross-validation to select the tree's complexity (depth) and sample splitting to evaluate its performance, using {{train_proportion_decision_tree}} of the data to train the tree and the remainder to valid it.\n\nOverall, policy trees condense the insights from causal forests into actionable guidelines.+We emphasise that deriving these guidelines includes rigorous validation: one part of the data learns the policy, another tests it. This ensures that the simple rules we recommend (e.g. 'treat those with lower time demands; do not treat incomes at a certain level') are supported by evidence rather than being artifacts of noise.\n\nAlthough estimating heterogeneous treatment effects and deriving actionable policy rules can be both theoretically and practically important, two considerations should temper our enthusiasm.\n\nFirst, the factors highlighted in policy trees are predictors of treatment-effect variability, but these predictors do not themselves have a causal interpretation. Returning to the example above, we should not infer that intervening to set someone’s travel and housework times to different values would change the variability in response. To understand the causal effects of joint interventions, we would need a different analysis. Decision trees are important because they draw attention to segments of a population likely to benefit, but they do not clarify the effects of changing a population structure.\n\nSecond, decisions about prioritising treatment rules are often ethical and political. Even if we set aside uncertainties in the modelling process, few would argue that fairness and justice should be determined by optimisation rules alone.. Even if we set aside uncertainties in the modelling process, few would argue that fairness and justice should be determined by optimisation rules alone. Such questions are typically resolved through democratic processes that involve stakeholder consultations, reflection on social values, a reckoning with historical inequities, and considerations beyond the scope of statistical analyses.",
      "grf_short": "\n## S{{appendix_explain_grf}}. Estimating and Interpreting Heterogeneous Treatment Effects with GRF {#appendix-explain-grf}\n\nHere we explain a heterogeneous‐treatment‐effect (HTE) analysis using causal forests [@grf2024]. In our workflow, we move from the average treatment effect (ATE) to individualised effects, quantify the practical value of targeting, and finish with interpretable decision rules.\n\n\n### 1 Average Treatment Effect (ATE)\n\nThe ATE answers: *'What would happen, on average, if everyone received treatment versus no one?'*\n\n$$\n    \\text{ATE}=E[Y(1)-Y(0)].\n$$\n\nUsing the `grf` package, we estimate the ATE doubly-robustly.  Because we analyse several outcomes, we adjust ATE *p*-values with {{ate_adjustment}} ($\\alpha$ = {{ate_alpha}}) to control the family-wise error rate.\n\n\n\n\n### 2 Do Effects Vary?  Formal Test of Heterogeneity\n\nDefine the conditional average treatment effect (CATE)\n\n$$\n  \\tau(x)=E[Y(1)-Y(0)\\mid X=x].\n$$\n\nIf $\\tau(x)$ is constant, effects are homogeneous; otherwise they vary. Classical interaction models impose strong forms; **grf** uses *causal forests* to discover complex, nonlinear heterogeneity [@wager2018].  We assess heterogeneity with RATE *p*-values corrected via {{cate_adjustment}} (q = {{cate_alpha}}), controlling the false-discovery rate [@benjamini1995controlling].\n\n\n\n\n### 3 Causal Forests for Individualised Estimates\n\nA causal forest is an ensemble of 'honest' causal trees that split on covariates to maximise treated–control contrasts. For each unit $i$ we obtain\n\n$$\n  \\widehat{\\tau}(x_i)\n$$\n\nStrengths are flexibility, orthogonalisation, and per-person estimates.\n\n\n### 4 Built-in Protection Against Over-fitting\n\n  Honesty (split half/estimate half) plus out-of-bag (OOB) predictions yield unbiased $\\widehat{\\tau}(x)$ and standard errors without manual hyper-tuning.\n\n\n### 5 Missing Data Handling\n\n**grf** deploys 'Missing Incorporated in Attributes' (MIA): missingness is a valid split, so cases stay in the analysis -- no ad-hoc imputation required.\n\n\n### 6 Testing for **Actionable** Heterogeneity: the TOC & RATE Metrics\n\nRanking units by $\\widehat{\\tau}$ defines a **Targeting Operator Characteristic** (TOC) curve: the cumulative gain from treating the top fraction $q$ of predicted responders. Two scalar summaries:\n\n- **RATE AUTOC** – area under the entire TOC; emphasises the very highest responders.\n- **RATE Qini** – weighted area with weight $q$; rewards sustained gains across larger coverage [@yadlowsky2021evaluating].\n\nUnder $H_0{:}\\tau(x)$ constant, both equal 0.\n`grf::rank_average_treatment_effect()` supplies point estimates, standard errors, and $t$-tests.\n\n**Multiplicity control**: We adjust AUTOC and Qini *p*-values with {{cate_adjustment}} (q = {{cate_alpha}}) before declaring actionable heterogeneity.\n\nHere is an **interpretation tip**:\n\n* AUTOC answers *'How sharply can we prioritise?'*\n* Qini answers *'How valuable is targeting when budgets are modest but not tiny?'*\n\n### 7 Visualising Policy Value: the Qini Curve\n\nPlotting the Qini curve (cumulative gain vs $q$) reveals where returns plateau. Investigators (and policy audiences) can see at a glance whether benefits concentrate in, say, the top 20 % or persist up to 50 %.\n\n\n### 8 Valid Inference for RATE / Qini\n\nAlthough OOB predictions are out-of-sample per tree, they inherit forest-level dependence. We use an explicit **sample split**:\n\n1. **Train set**: fit the causal forest and compute $\\widehat{\\tau}(x)$.\n2. **Test set**: compute RATE AUTOC/Qini and run $H_0$ tests.\n\nThis second split yields honest policy evaluation and guards against optimistic bias [@grf2024].\n\n### 9 From Black Box to Simple Rules: Policy Trees\n\nStakeholders value transparent criteria. The **policytree** algorithm takes $\\widehat{\\tau}(x)$ or doubly-robust scores and learns a shallow decision tree that maximises expected welfare [@policytree_package_2024].\n\n*Advantages*: interpretability, the possibility of fairness constraints, and easy communication (e.g., *'treat if age < 25 and baseline severity high'*).\n\nTraining mirrors the split above: learn the tree on one fold, evaluate welfare on another.\n\n> **Caveat**  Splits identify predictors of *effect variation*, not causal levers. Changing a covariate in the tree does **not** guarantee an effect on $\\tau(x)$.\n\n\n### 10 Ethical and Practical Considerations\n\nStatistical optimisation rarely aligns perfectly with equity or political feasibility. Decisions about who *should* receive treatment belong to democratic processes that weigh fairness, cost, and broader social values.\n\n\n### Putting it together\n\nThe sequence—ATE, causal-forest CATEs, RATE/Qini diagnostics, Qini curve, and finally a shallow policy tree—delivers both rigorous evidence and a defensible targeting rule.  Researchers learn **how large** heterogeneity is, **where** targeting pays off under budget constraints, and **which** simple covariate splits capture most of the welfare gain, all while guarding against over-fitting and multiplicity.\n"
    },
    "exposure": "\n### Exposure Variable: {{name_exposure_variable}}  {#appendix-exposure}\n\n@tbl-sample-appendix-exposures presents sample statistics for the {{name_exposure_variable}} during the {{baseline_wave}} and {{exposure_waves}}.\n\n::: {#tbl-appendix-exposures}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\ncat(latex_table_exposures)\n\n```\nDemographic statistics for New Zealand Attitudes and Values Cohort {{baseline_wave}}.\n:::\n",
    "outcomes": {
      "flourishing_2025": "\n## Outcome Variables {#appendix-outcomes}\n\n@tbl-appendix-outcomes presents sample outcomes at baseline and the end of study.\n\n::: {#tbl-appendix-outcomes}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\n\nprint(markdown_table_outcomes_all)\n\n```\nOutcome variables measured at baseline and end of study.\n:::\n",
      "general": "\n## Outcome Variables {#appendix-outcomes}\n\n@tbl-appendix-outcomes presents sample outcomes at baseline and the end of study.\n\n::: {#tbl-appendix-outcomes}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\n\nprint(markdown_table_outcomes_all)\n\n```\nOutcome variables measured at baseline and end of study.\n:::\n"
    },
    "positivity": {
      "exposures_1": "\n## S{{appendix_positivity}}: Transition Matrix to Check The Positivity Assumption {#appendix-positivity}\n\n@tbl-transition-waveb-wave1 presents the transition matrix indicating change in the exposure variable between the baseline and exposure waves.\n\n```{r}\n#| eval: true\n#| include: false\n#| echo: false\ntransition_tables$quarto_code()\n```\n\n```{r, results='asis'}\ncat(transition_tables$explanation)\n```\n\n```{r}\n#| label: tbl-transition-waveb-wave1\n#| tbl-cap: \"Transition Matrix From Baseline Wave to Exposure Wave\"\ntransition_tables$tables[[1]]\n```\n",
      "exposures_1_binary": "\n## S{{appendix_positivity}}: Transition Matrix to Check The Positivity Assumption {#appendix-positivity}\n\n\n```{r}\n#| eval: true\n#| include: false\n#| echo: false\ntransition_tables_binary$quarto_code()\n```\n\n```{r, results='asis'}\ncat(transition_tables_binary$explanation)\n```\n\n```{r}\n#| label: tbl-transition-waveb-wave1\n#| tbl-cap: \"Transition Matrix From Baseline Wave to Exposure Wave\"\ntransition_tables_binary$tables[[1]]\n```\n",
      "exposures_5": "\n## S{{appendix_positivity}}: Transition Matrix to Check The Positivity Assumption {#appendix-positivity}\n\n\n```{r}\n#| eval: true\n#| include: false\n#| echo: false\ntransition_tables$quarto_code()\n```\n\n```{r, results='asis'}\ncat(transition_tables$explanation)\n```\n\n```{r}\n#| label: tbl-transition-waveb-wave1\n#| tbl-cap: \"Transition Matrix From Baseline Wave to First Exposure Wave\"\ntransition_tables$tables[[1]]\n```\n\n```{r}\n#| label: tbl-transition-wave1-wave2\n#| tbl-cap: \"Transition Matrix From First Exposure Wave to Second Exposure Wave\"\ntransition_tables$tables[[2]]\n```\n\n```{r}\n#| label: tbl-transition-wave2-wave3\n#| tbl-cap: \"Transition Matrix From Second Exposure Wave to Third Exposure Wave\"\ntransition_tables$tables[[3]]\n```\n\n```{r}\n#| label: tbl-transition-wave3-wave4\n#| tbl-cap: \"Transition Matrix From Third Exposure Wave to Fourth Exposure Wave\"\ntransition_tables$tables[[4]]\n```\n\n```{r}\n#| label: tbl-transition-wave4-wave5\n#| tbl-cap: \"Transition Matrix From Fourth Exposure Wave to Fifth Exposure Wave\"\ntransition_tables$tables[[5]]\n```\n\n"
    },
    "references": "\n\n## References {.appendix-refs}\n\n",
    "sensitivity_analyses": "We conducted several sensitivity analyses to evaluate the robustness of our findings to different assumptions.",
    "supplementary_methods": "This appendix provides additional methodological details that supplement the main manuscript.",
    "technical": {
      "lmtp_time_vary": "\n## S{{appendix_explain_lmtp_time_vary}}: Causal Contrasts and Causal Assumptions {#appendix-assumptions}\n### Notation\n  - $A_k$: Observed {{name_exposure_variable}} at Wave $k$, for $k = 1, \\dots, {{n_final_exposure_wave}}$.\n  - $Y_\\tau$: Outcomes measured at the end of the study (Wave {{n_outcome_wave}}).\n  - $W_0$: Confounders measured at baseline (Wave 0) (including A_0, Y_0).\n  - $L_k$: Time-varying confounders measured at Wave $k$ (for $k = 1, \\dots, {{n_final_exposure_wave}}$).\n### Shift Functions\nLet $\\boldsymbol{\\text{d}}(a_k)^+$ represent the {{name_exposure_regime}} treatment sequence and $\\boldsymbol{\\text{d}}(a_k)^\\emptyset$ the **{{name_control_regime}}** treatment sequence, where the interventions occur at each wave $k = 1\\dots {{n_final_exposure_wave}}; k\\in \\{0\\dots n_outcome_wave\\}$.\nFormally:\n#### {{name_exposure_regime}} $\\bigl(\\boldsymbol{\\text{d}}(a_k^+)\\bigr)$\n$$\n\\boldsymbol{\\text{d}} (a_k^+)\n\\;=\\;\n\\begin{cases}\n{{value_exposure_set_low}}, & \\text{if } A_k < {{value_exposure_set_high}},\\\\[6pt]\nA_k, & \\text{otherwise.}\n\\end{cases}\n$$\n#### {{name_control_regime}} $\\bigl(\\boldsymbol{\\text{d}}(a_k^\\null)\\bigr)$\n$$\n\\boldsymbol{\\text{d}}(a_k^\\emptyset)\n\\;=\\;\n\\begin{cases}\n{{value_exposure_set_low}}, & \\text{if } A_k > {{value_exposure_set_low}},\\\\[6pt]\nA_k, & \\text{otherwise.}\n\\end{cases}\n$$\nHere, $A_k$ is the observed {{exposure_var}} at Wave $k$. The shift function $\\boldsymbol{\\text{d}}$ 'nudges' $A_k$ to a target level (four times per month or zero) only if the current value is below (for {{name_exposure_regime}}) or above (for  {{name_control_regime}}) that target. Across the 1-{{n_final_exposure_wave}} waves, these shifts form a sequence $\\boldsymbol{\\bar{\\boldsymbol{\\text{d}}}}$, which defines a complete intervention regime.\n### Causal Contrast\nWe compare the average well-being under the **{{name_exposure_regime}}** regime, $\\boldsymbol{\\bar{\\boldsymbol{\\text{d}}}}(a^+)$, to the average well-being under the **{{name_control_regime}}** regime, $\\boldsymbol{\\bar{\\boldsymbol{\\text{d}}}}(a^\\emptyset)$. Specifically, the average treatment effect (ATE) is given:\n$$\n\\text{ATE}^{\\text{outcomes}}\n\\;=\\;\n\\mathbb{E}\n\\Bigl[\n  Y_\\tau\\!\\bigl(\\boldsymbol{\\text{d}}(a^+)\\bigr)\n  \\;-\\;\n  Y_\\tau\\!\\bigl(\\boldsymbol{\\text{d}}(a^\\emptyset)\\bigr)\n\\Bigr].\n$$\n### Assumptions\nTo estimate this effect from observational data, we assume:\n1. **Conditional Exchangeability:** Once we condition on $W_0$ and each $L_k$, the interventions $\\boldsymbol{\\bar{\\boldsymbol{\\text{d}}}}(a^+)$ or $\\boldsymbol{\\bar{\\boldsymbol{\\text{d}}}}(a^\\emptyset)$ are effectively random with respect to potential outcomes.\n2. **Consistency:** The potential outcome under a given treatment regime matches the observed outcome when that regime is followed.\n3. **Positivity:** Everyone has a non-zero probability of receiving each level of {{name_exposure_variable}} (i.e., a chance to be 'shifted' up or down) given their covariates. The positivity assumption is the only causal assumption that can be evaluated with data. We evaluate this assumption in [Appendix {{appendix_positivity}}](#appendix-positivity)).\nMathematically, for conditional exchangeability, we write:\n$$\n\\Bigl\\{\n  Y\\bigl(\\boldsymbol{\\text{d}}(a^+)\\bigr),\n  \\;\n  Y\\bigl(\\boldsymbol{\\text{d}}(a^\\emptyset)\\bigr)\n\\Bigr\\}\n\\coprod\nA_k |\nW_0,\nL_k\n$$\nThat is, we assume the potential outcomes under each treatment regime are independent of each treatment at every time point, conditional on baseline confounders and time-varying confounders (here: {{time_varying_confounders}}).\nUnder these assumptions, our statistical models permit us to estimate $\\text{ATE}^{\\text{outcomes}}$ from observational data. That contrast is (1) *{{name_exposure_regime}}* versus (2) *{{name_control_regime}}* at least {{number_exposure_waves}} waves*.  We define the target population as {{name_target_population}}, the years in which measurements were taken."
    },
    "timeline": "\n##S{{appendix_timeline}}: Daily Data Collection  {#appendix-timeline}\n\n{{< pagebreak >}}\n\n@fig-timeline presents the New Zealand Attitudes and Values Study Data Collection {{baseline_wave}} retained cohort from {{study_years}}.\n\n```{r}\n#| label: fig-timeline\n#| fig-cap: \"Historgram of New Zealand Attitudes and Values Study Daily Data Collection for {{baseline_wave}} cohort: years 2018-2024.\"\n#| eval: true\n#| include: true\n#| echo: false\n#| fig-width: 12\n#| fig-height: 12\n#|\ntimeline_histogram\n```\n"
  },
  "bibliography": {
    "url": "https://raw.githubusercontent.com/go-bayes/templates/refs/heads/main/bib/references.bib",
    "local_path": "references2.bib",
    "validate": true,
    "last_updated": "2025-10-17 22:15:25"
  },
  "discussion": {
    "acknowlegements": {
      "nzavs_acknowledgements_2025": "\n### Acknowledgements\n\nThe New Zealand Attitudes and Values Study is supported by a grant from the Templeton Religious Trust (TRT0196; TRT0418). JB received support from the Max Plank Institute for the Science of Human History. The funders had no role in preparing the manuscript or deciding to publish it."
    },
    "authors_statement": {
      "empty": "\n### Author Statement\n\n\n"
    },
    "authors_statment_empty": "\n### Author Statement\n\n\n",
    "ethics": {
      "nzavs_2021_2027": "\n### Ethics\n\nThe University of Auckland Human Participants Ethics Committee reviews the NZAVS every three years. Our most recent ethics approval statement is as follows: The New Zealand Attitudes and Values Study was approved by the University of Auckland Human Participants Ethics Committee on 26/05/2021 for six years until 26/05/2027, Reference Number UAHPEC22576."
    },
    "future_directions": null,
    "implications": {
      "clinical": "\n### Implications Clinical\n\n\n\n",
      "policy": "\n### Implications Policy\n\n\n\n",
      "theoretical": "\n### Implications Theoretical\n\n\n\n"
    },
    "interpret_findings": "\n### Interpretation and Interest of Findings\n\n\n\n",
    "limitations": "\n### Limitations\n\n\n\n",
    "nzavs_acknowledgements_2025": "\n### Acknowledgements\n\nThe New Zealand Attitudes and Values Study is supported by a grant from the Templeton Religious Trust (TRT0196; TRT0418). JB received support from the Max Plank Institute for the Science of Human History. The funders had no role in preparing the manuscript or deciding to publish it.",
    "nzavs_data_availabily": "\n### Data Availability\n\nThe data described in the paper are part of the New Zealand Attitudes and Values Study. Members of the NZAVS management team and research group hold full copies of the NZAVS data. A de-identified dataset containing only the variables analysed in this manuscript is available upon request from the corresponding author or any member of the NZAVS advisory board for replication or checking of any published study using NZAVS data. The code for the analysis can be found at [OSF link](https://osf.io/ab7cx/).",
    "strengths": {
      "simple_general_approach_cate_long": "\n### Moderators and Treatment Policies\n\nIn simple terms, we wanted to see if a treatment works differently for different people, rather than just figuring out one overall benefit for everyone. We used a method called 'causal forests' (think of it like a special type of decision tree) to find which groups of people might benefit the most, and which groups might benefit the least.\n\nBecause some of our measures work in opposite directions ('lower is better', e.g. depression), we flipped those measures so that 'higher' always means 'better.' That way, if we talk about a 'positive effect,' it consistently means the person improved.\n\nTo avoid fooling ourselves by spotting fake patterns in the data, we split our sample in half. We used the first half to teach our causal forest model what to look for, then tested it on the second half—so we only trust what shows up in that new data, where the model wasn’t allowed to 'peek.'\n\nWe tested whether the model’s predictions were sensible in two ways:\n1.  **Do the average predictions match the overall effect?** This checks if the model's idea of an 'average effect' fits what we actually see in the second half of the data.\n2.  **Is there real variety in who benefits most?** The model estimates different effects for different people, but we need to confirm that these differences aren not just random noise.\n\nWe also used two extra tools:\n- **Qini curves**: these plots show if focusing on the people who the model says would benefit most actually leads to better outcomes than just treating (or not treating) everyone.\n- **Policy trees**: these are straightforward 'if-then' rules (e.g., 'If a person’s baseline score is above X, recommend treatment'). Qini curves give more insight than 'black box' machine learning models, and can help guide decisions in real-world practice.\n\nPutting it all together, this step-by-step approach lets us investigate whether treatments should be applied the same way for everyone, or whether we can do better by matching treatments to the people who stand to benefit the most (refer to appendix {{appendix_analytic_approach}}.",
      "strengths_grf_long": "\n### Strengths and Limitations of Our Approach\n\nWe used causal forests [@grf2024]—a statistical method designed to estimate Conditional Average Treatment Effects (CATEs)—to investigate how treatment effectiveness might vary across individuals with different characteristics. This strategy offers several advantages over simpler regression models, yet it also comes with important caveats.\n\n#### Potential Limitations\n\nFirst, our results depend heavily on having measured all key variables that affect both who receives treatment and how strongly they respond. If important factors are missing, the estimated differences in treatment effects may be biased. Selecting which characteristics to include in the model is also critical: omitting relevant factors or including inappropriate ones can yield misleading conclusions. Any further analyses that rely on these estimates—such as deciding whom to treat first—will inherit the same potential biases.\n\nSecond, interpreting subgroup effects can be challenging when many characteristics are considered simultaneously. Because these estimates are conditional on all factors in the model, a statistically significant finding for one subgroup may not necessarily hold when additional characteristics vary. Moreover, even if the model detects genuine differences, small or niche effects might not translate into meaningful real-world improvements.\n\n#### Strengths\n\nDespite these considerations, our approach provides a powerful way to uncover and potentially leverage treatment effect heterogeneity. Causal forests [@grf2024] do not assume a simple linear or additive structure, enabling them to detect complex interactions among diverse covariates. To ensure the findings are not just statistical artifacts, we used a {{sample_split}} sample split: one half of the data to build the model and the other to test its predictions on unseen data. This guards against overfitting and gives a more reliable indication of how well the model generalises.\n\nWe also explicitly assess the reliability and practical value of the predicted differences in treatment effects. We perform statistical checks—such as calibration and differential prediction tests [@grf2024]—to determine whether these variations are genuine rather than noise. Additionally, the Rank-Weighted Average Treatment Effect (RATE) [@grf2024; @wager2018] estimates how much we might improve outcomes if we treat only the individuals predicted to benefit most, instead of treating everyone equally. To visualise this, Qini curves [@grf2024] show how much extra benefit accumulates as we expand treatment from the top-ranked individuals to a larger portion of the population. Finally, policy trees [@policytree_package_2024; @athey2021; @athey_2021_policy_tree_econometrica] translate these insights into straightforward ‘if-then’ rules based on key baseline characteristics, making the findings more accessible for real-world decision-making.\n\nIn sum, this combination of flexible modelling, rigorous testing, and practical tools for targeting treatment offers a robust framework for studying and applying treatment effect heterogeneity. Nonetheless, these benefits hinge on the completeness of our data and the accuracy of our assumptions.\n",
      "strengths_grf_long_text": "\n### Strengths and Limitations of Our Approach\n\nWe use a statistical method designed to estimate Conditional Average Treatment Effects (CATEs) to investigate how treatment effectiveness might vary across individuals with different characteristics. This methods is deploys *causal forests* [@grf202]. Our strategy offers several advantages over simpler regression models, yet it also comes with important caveats. We next describe consider the promise, and perils of causal forests.\n\n#### Potential Limitations\n\nFirst, our results depend heavily on having measured the key variables that affect both who receives treatment and how strongly they respond. If important variables are missing, the estimated differences in treatment effects may be biased. Selecting which characteristics to include in the model, and which to leave out, is also critical. The dinner party of CATE estimation is only as good as the indicators we invite to it.  Noisy indicators may drown out true insights. The insights of indicators left out cannot be obtained. Any further analyses that rely on these estimates, such as deciding whom to treat first, will inherit the same potential biases of our measures.\n\nSecond, interpreting subgroup effects can be challenging when many characteristics are considered simultaneously. Because these estimates are conditional on all factors in the model, as well as on the population that is modelled, a statistically significant finding for one subgroup may not necessarily hold when additional characteristics are included in a model. Moreover, even if the model detects genuine differences, small or niche effects might not translate into meaningful real-world advice. Given that each individual carries multiple indicators --  age, and ethnicity, and education-level, body mass, anxiety-level, work and commuting regime, rural or urban status, occupational status, personality facets, religion -- and given that we can only observe, at most, one treatment condition for each individual, inferences to conditional average treatment effects from individual-level data is a **difficult statistical problem**, which forest and ensemble methods may not fully resolve. The ambition of our causal questions may reach ahead of warrented confidence.\n\n#### Strengths\n\nAlthough we should remain humbled by the challenges of causal inferences,  we should be encouraged by recent progress in machine learning for uncovering treatment effect heterogeneity. When combined with methods for cross-validation on data the model has not observed, causal forests offer a powerful method for uncovering, and potentially leveraging, treatment-effect heterogeneity in the populations of interest. Causal forests [@grf2024] do not assume a simple linear or additive structure, enabling them to detect complex interactions among diverse covariates. To ensure the findings are not mere statistical artifacts, we used a {{sample_split}} sample splitting such that part of the data is used to build the model and the other part is used test its predictions -- the tested part remaing unseen during model training. These qualities allow for feature detection and and guard against overfitting, yeilding more reliable generalisations when extrapolating beyond a given study.\n\nWe also explicitly assess the reliability and practical value of the predicted differences in treatment effects.  The Rank-Weighted Average Treatment Effect (RATE) [@grf2024; @wager2018] estimates how much we might improve outcomes if we treat individuals by their ranked predicted benefit, instead of treating everyone without regard to their covariates. Qini curves [@grf2024] show how much extra benefit accumulates as we expand treatment from the top-ranked individuals to a larger portion of the population at different budget-levels. Finally, policy trees [@policytree_package_2024; @athey2021; @athey_2021_policy_tree_econometrica] translate insights into straightforward ‘if-then’ rules for which several baseline characteristics are most predictive of treatment response. Such policy-rules make findings more accessible for real-world decision-making.\n\nThus as combinationing of flexible machine-learning with rigorous cross-validation, the application of algorithms for quantifying the hazards and benefits of CATE-based prioritisation, and and practical decision-making tools for effectively targeting treatments, offers a robust framework for investigating treatment effect heterogeneity and better informing policy. Again, such benefits rely on untestable assumptions both about the qualities of the data and of the mechanisms that generate them.\n",
      "strengths_grf_short": "\nWe used causal forests to uncover how the treatment effect changes across people who differ in age, gender, baseline scores, and other measured characteristics [@grf2024]. This flexible, non-parametric method avoids the rigid functional‐form assumptions of linear or logistic regression and can capture complex, higher-order interactions that would otherwise be missed.\n\nTo guard against over-fitting we split the data: one portion trained the forest, and the other evaluated its predictions train/test ratio: 50/50. On the evaluation set we computed three complementary metrics: (i) rate statistics: the area under the treatment–outcome curve (AUTOC) which summarise how well the model ranks individuals from 'most likely to benefit' to 'least likely to benefit' based on their baseline caracteristics; (ii) Qini curves which show the cumulative gain achieved by treating successively larger fractions of the population -- which is relevant to understanding gains from different spend levels. policy trees, which convert the forest's complex predictions into a short set of human-readable if–then rules that can guide targeting in practice [@policytree_package_2024; @athey2021; @athey_2021_policy_tree_econometrica]. Collectively, these tools help to clarify whether heterogeneous effects exist, and also how much extra benefit a data-driven targeting policy might yield over random allocation [@wager2018].\n\nAlthough causal forests improve on traditional parametric methods, every observational approach carries risks.\n\nFirst, causal inference in observational settings inevitably relies on untestable ignorability assumptions (treatments are 'as good as random' conditional on measured covariates). Whether we have measured all factors that may jointly influence treatment assignment and the outcomes cannot be evaluated by statistical tests. If strong common causes of both the exposure and outcome are unobserved or poorly measured, our estimates will be biased.  Interpreting subgroup findings can also be challenging: statistically significant differences are not always large enough to matter in real life. More basic, perhaps, methods for detecting real differences rely on measures that are, in survey research, inherently noisy, and noise often, but no always, attenuates affects. The twin dangers of mistaking noise for signal, or of obscuring singles from noise, abide. Such limitations must be kept firmly in mind when interpreting results. \n\n"
    },
    "student_authors_statement": "\n### Author Statement\n\nThe Methods and Results section were created using standard protocols from the EPIC lab (Joseph Bulbulia). These were encoded using the `boilerplate` package [@boilerplate2024] and `margot package` [@margot2024] in R. The introduction and conclusion for this research are solely the student's work.",
    "student_data": "\n### Data Availability\n\nThe data described in the paper were *simulated* from the New Zealand Attitudes and Values Study (NZAVS). For more information contact professor Joseph Bulbulia at joseph.bulbulia@vuw.ac.nz. For more information about the NZAVS, see: [OSF link](https://osf.io/ab7cx/).",
    "student_ethics": "\n### Ethics\n\nThe data were simulated for the purposes of instruction. The Ethics Approval for the dataset from which the synthetic data were generated is as follows: The University of Auckland Human Participants Ethics Committee reviews the NZAVS every three years. The most recent ethics approval statement is as follows: The New Zealand Attitudes and Values Study was approved by the University of Auckland Human Participants Ethics Committee on 26/05/2021 for six years until 26/05/2027, Reference Number UAHPEC22576."
  },
  "measures": {
    "age": {
      "description": "We asked participants' ages in an open-ended question (\"What is your age?\" or \"What is your date of birth\").",
      "waves": "1-current",
      "reference": "sibley2021",
      "name": "age",
      "items": [
        "What is your date of birth?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "agreeableness": {
      "description": "Mini-IPIP6 Agreeableness dimension: (i) I sympathize with others' feelings. (ii) I am not interested in other people's problems. (r) (iii) I feel others' emotions. (iv) I am not really interested in others. (r)",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "agreeableness",
      "items": [
        "I sympathize with others' feelings.",
        "I am not interested in other people's problems.",
        "I feel others' emotions.",
        "I am not really interested in others (reversed)."
      ],
      "keywords": "personality",
      "reversed_items": 4,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "alcohol_frequency": {
      "name": "alcohol_frequency",
      "items": [
        "\"How often do you have a drink containing alcohol?\""
      ],
      "description": "Participants could chose between the following responses: '(1 = Never - I don't drink, 2 = Monthly or less, 3 = Up to 4 times a month, 4 = Up to 3 times a week, 5 = 4 or more times a week, 6 = Don't know)'",
      "reference": "Ministry_of_Health_2013",
      "waves": "1-current",
      "keywords": "health",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "alcohol_intensity": {
      "name": "alcohol_intensity",
      "items": [
        "\"How many drinks containing alcohol do you have on a typical day when drinking alcohol? (number of drinks on a typical day when drinking)\""
      ],
      "description": "Participants responded using an open-ended box.",
      "reference": "Ministry_of_Health_2013",
      "waves": "6-current",
      "keywords": "health",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "alert_level_combined": {
      "name": "alert_level_combined",
      "items": [
        "Covid Alert Levels"
      ],
      "description": "Defined by levels of lockdown severity",
      "reference": "sibley2021",
      "waves": "10-11",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "anxiety": {
      "name": "anxiety",
      "description": "Anxiety was measured using a standard anxiety scale",
      "reference": "anxiety_reference",
      "waves": "1-3",
      "keywords": ["anxiety", "mental health"],
      "items": [
        "feeling nervous or anxious",
        "worrying too much about different things"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "ban_hate_speech": {
      "name": "ban_hate_speech",
      "items": [
        "People who hold opinions that are harmful or offensive to minority groups should be banned from expressing those views publicly."
      ],
      "waves": "11-current",
      "keywords": "institutional_trust",
      "reference": "dore2022boundaries",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "belong": {
      "description": "We assessed felt belongingness with three items adapted from the Sense of Belonging Instrument (Hagerty & Patusky, 1995): (1) \"Know that people in my life accept and value me\"; (2) \"Feel like an outsider\"; (3) \"Know that people around me share my attitudes and beliefs\". Participants responded on a scale from 1 (Very Inaccurate) to 7 (Very Accurate). The second item was reversely coded.",
      "waves": "1-current",
      "reference": "hagerty1995",
      "name": "belong",
      "items": [
        "Know that people in my life accept and value me.",
        "Feel like an outsider (reversed).",
        "Know that people around me share my attitudes and beliefs."
      ],
      "keywords": "cooperation",
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "belong_accept": {
      "reference": "hagerty1995",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Know that people in my life accept and value me."
      ],
      "name": "belong_accept",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "belong_beliefs": {
      "description": "We assessed felt belongingness with three items adapted from the Sense of Belonging Instrument (Hagerty & Patusky, 1995): (1) \"Know that people in my life accept and value me\"; (2) \"Feel like an outsider\"; (3) \"Know that people around me share my attitudes and beliefs\". Participants responded on a scale from 1 (Very Inaccurate) to 7 (Very Accurate). The second item was reversely coded.",
      "reference": "hagerty1995",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Know that people around me share my attitudes and beliefs."
      ],
      "name": "belong_beliefs",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "belong_routside_reversed": {
      "description": "We assessed felt belongingness with three items adapted from the Sense of Belonging Instrument (Hagerty & Patusky, 1995): (1) \"Know that people in my life accept and value me\"; (2) \"Feel like an outsider\"; (3) \"Know that people around me share my attitudes and beliefs\". Participants responded on a scale from 1 (Very Inaccurate) to 7 (Very Accurate). The second item was reversely coded.",
      "reference": "hagerty1995",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Feel like an outsider (reversed)."
      ],
      "name": "belong_routside_reversed",
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "bmi_cat": {
      "name": "bmi_cat",
      "description": "Responses classified by WHO codes: 1. Underweight: BMI less than 18.5 2. Normal weight: BMI 18.5 to 24.9 3. Overweight: BMI 25.0 to 29.9 4. Obese Class I: BMI 30.0 to 34.9 5. Obese Class II: BMI 35.0 to 39.9 6. Obese Class III: BMI 40.0 or higher",
      "reference": "WHO1995Anthropometry",
      "waves": "2-current",
      "keywords": "health",
      "items": [
        "'What is your height? (meters)'/'How much do you weigh? (kgs)'"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "bmi_cat_num": {
      "name": "bmi_cat_num",
      "description": "Responses classified by WHO codes: 1. Underweight: BMI less than 18.5 2. Normal weight: BMI 18.5 to 24.9 3. Overweight: BMI 25.0 to 29.9 4. Obese Class I: BMI 30.0 to 34.9 5. Obese Class II: BMI 35.0 to 39.9 6. Obese Class III: BMI 40.0 or higher (coded numeric)",
      "reference": "WHO1995Anthropometry",
      "waves": "2-current",
      "keywords": "health",
      "items": [
        "'What is your height? (meters)'/'How much do you weigh? (kgs)'"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "bodysat": {
      "name": "bodysat",
      "items": [
        "I am satisfied with the appearance, size and shape of my body."
      ],
      "description": "Ordinal response .",
      "reference": "stronge2015facebook",
      "waves": "5-current.",
      "keywords": "reflective-present",
      "scale_info": "1 = Very inaccurate to 7 = Very accurate",
      "scale_anchors": "1 = Very inaccurate to 7 = Very accurate",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "born_nz": {
      "description": "Open-ended response coded as binary.",
      "reference": "sibley2021",
      "waves": "1-2,4-current",
      "name": "born_nz",
      "items": [
        "Where were you born? (please be specific, e.g., which town/city?)"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "born_nz_binary": {
      "description": "Coded binary (1 = New Zealand; 0 = elsewhere.)",
      "waves": "1-2,4-current",
      "reference": "sibley2021",
      "name": "born_nz_binary",
      "items": [
        "Where were you born? (please be specific, e.g., which town/city?)"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "charitable_donations": {
      "description": "Using one item from Hoverd and Sibley (2010), we asked participants, \"How much money have you donated to charity in the last year?\". To stabilise this indicator, we took the natural log of the response + 1.",
      "reference": "hoverd_religious_2010",
      "name": "charitable_donations",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "charity_donate": {
      "name": "charity_donate",
      "items": [
        "How much money have you donated to charity in the last year?"
      ],
      "description": "Numerical: open-ended response",
      "reference": "hoverd_religious_2010",
      "waves": "1-current",
      "keywords": "cooperation",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "children_num": {
      "description": "We measured the number of children using one item from Bulbulia et al. (2015). We asked participants, \"How many children have you given birth to, fathered, or adopted?\" or \"How many children have you given birth to, fathered, and/or parented?\" (waves: 12-15).",
      "waves": "1-3, 4-current",
      "reference": "bulbulia_2015",
      "name": "children_num",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "community_money_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "sibley2021",
      "waves": "10-13",
      "keywords": "cooperation",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...friends...TIME (hours)."
      ],
      "name": "community_money_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "community_time_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "sibley2021",
      "waves": "10-13",
      "keywords": "cooperation",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...members of my community...TIME (hours)."
      ],
      "name": "community_time_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "conscientiousness": {
      "description": "Mini-IPIP6 Conscientiousness dimension: (i) I get chores done right away. (ii) I like order. (iii) I make a mess of things. (r) (iv) I often forget to put things back in their proper place. (r)",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "conscientiousness",
      "items": [
        "I get chores done right away.",
        "I like order.",
        "I make a mess of things.",
        "I often forget to put things back in their proper place."
      ],
      "keywords": "personality",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "conspiracy_beliefs": {
      "name": "conspiracy_beliefs",
      "items": [
        "I think that the official version of major world events given by authorities often hides the truth."
      ],
      "reference": "knowles2009malleability",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "depression": {
      "name": "depression",
      "description": "Depression was measured using a standard depression scale",
      "reference": "depression_reference",
      "waves": "1-3",
      "keywords": ["depression", "mental health"],
      "items": [
        "feeling down or depressed",
        "having little interest in doing things"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "doubts_official_version": {
      "reference": "knowles2009malleability",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I think that the official version of major world events given by authorities often hides the truth."
      ],
      "name": "doubts_official_version",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "doubts_official_version_truth": {
      "reference": "knowles2009malleability",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I think that the official version of major world events given by authorities often hides the truth."
      ],
      "name": "doubts_official_version_truth",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "education_level_coarsen": {
      "description": "We asked participants, \"What is your highest level of qualification?\". We coded participans highest finished degree according to the New Zealand Qualifications Authority. Ordinal-Rank 0-10 NZREG codes (with overseas school qualifications coded as Level 3, and all other ancillary categories coded as missing)",
      "waves": "1, 4-current",
      "reference": "sibley2021",
      "name": "education_level_coarsen",
      "items": [
        "What is your highest level of qualification?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "emp_job_sat": {
      "name": "emp_job_sat",
      "description": "Job satisfaction was measured with a single item:",
      "reference": "eisenbarth2022aspects",
      "waves": "1-present",
      "keywords": ["employment", "mental health"],
      "items": [
        "How satisfied are you with your current job?"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "emp_job_secure": {
      "description": "Participants indicated their feeling of job security by answering \"How secure do you feel in your current job?\" on a scale from 1 (not secure) to 7 (very secure).",
      "waves": "1-3,4-7,9-current",
      "reference": "sibley2021",
      "name": "emp_job_secure",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "emp_job_valued": {
      "name": "emp_job_valued",
      "description": "Perceved organizational gratitude was measured with a single item:",
      "reference": "sibley2021",
      "waves": "10-present",
      "keywords": ["employment", "mental health"],
      "items": [
        "How valued do you feel by your current organization?"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "emp_job_valued_binary": {
      "name": "emp_job_valued_binary",
      "description": "Perceved organizational gratitude was measured with a single item.",
      "reference": "sibley2021",
      "waves": "10-present",
      "keywords": ["employment", "mental health"],
      "items": [
        "How valued do you feel by your current organization?"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "employed": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "statsnz_ssga18",
      "waves": "1-current",
      "keywords": "demography",
      "items": [
        "Are you currently employed (This includes self-employed of casual work)?"
      ],
      "name": "employed",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "employed_binary": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "waves": "1-current",
      "reference": "statsnz_ssga18",
      "name": "employed_binary",
      "items": [
        "Are you currently employed (This includes self-employed of casual work)?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_1080poison": {
      "name": "env_1080poison",
      "items": [
        "Please rate how strongly you oppose or support each of the following possible policies or issues...Increased government spending on new motorways."
      ],
      "description": ".",
      "reference": "milfont_sociopolitical_2022",
      "waves": "1,4-5,10-11",
      "keywords": "environment",
      "scale_info": "1 = \"Strongly Oppose\" to 7 = \"Strongly Support\"",
      "scale_anchors": "1 = \"Strongly Oppose\" to 7 = \"Strongly Support\"",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_climate_chg_cause": {
      "name": "env_climate_chg_cause",
      "items": [
        "Climate change is caused by humans."
      ],
      "reference": "sibley2013model",
      "waves": "1-current",
      "keywords": "environment",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_climate_chg_concern": {
      "reference": "sibley2021",
      "waves": "5-current",
      "keywords": "environment",
      "items": [
        "I am deeply concerned about climate change."
      ],
      "name": "env_climate_chg_concern",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_climate_chg_real": {
      "reference": "sibley2013model",
      "waves": "1-current",
      "keywords": "environment",
      "items": [
        "Climate change is real."
      ],
      "name": "env_climate_chg_real",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_efficacy": {
      "reference": "sharma2008we",
      "waves": "1-9;12-15",
      "keywords": "environment",
      "items": [
        "By taking personal action I believe I can make a positive difference to environmental problems.",
        "I feel I can make a difference to the state of the environment."
      ],
      "name": "env_efficacy",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_efficacy_action_belief": {
      "name": "env_efficacy_action_belief",
      "items": [
        "By taking personal action I believe I can make a positive difference to environmental problems."
      ],
      "reference": "sharma2008we",
      "waves": "1-9;12-15",
      "keywords": "environment",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_efficacy_action_feeling": {
      "reference": "sharma2008we",
      "waves": "1-9;12-15",
      "keywords": "environment",
      "items": [
        "I feel I can make a difference to the state of the environment."
      ],
      "name": "env_efficacy_action_feeling",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_not_climate_chg_cause": {
      "reference": "sibley2013model",
      "waves": "1-current",
      "keywords": "environment",
      "items": [
        "1. Climate change is caused by humans (reversed)."
      ],
      "name": "env_not_climate_chg_cause",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_not_climate_chg_concern": {
      "reference": "sibley2021",
      "waves": "5-current",
      "keywords": "environment",
      "items": [
        "I am deeply concerned about climate change (reversed)."
      ],
      "name": "env_not_climate_chg_concern",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_not_climate_chg_real": {
      "reference": "sibley2013model",
      "waves": "1-current",
      "keywords": "environment",
      "items": [
        "Climate change is real (reversed)."
      ],
      "name": "env_not_climate_chg_real",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_not_env_efficacy": {
      "reference": "sharma2008we",
      "waves": "1-9;12-15",
      "keywords": "environment",
      "items": [
        "By taking personal action I believe I can make a positive difference to environmental problems (reversed)",
        "I feel I can make a difference to the state of the environment (reversed)."
      ],
      "name": "env_not_env_efficacy",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": [1, 2],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_not_sat_nz_environment": {
      "reference": "tiliouine_measuring_2006",
      "waves": "1-current",
      "keywords": "environment",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life and New Zealand...The quality of New Zealand's natural environment (reversed)."
      ],
      "name": "env_not_sat_nz_environment",
      "scale_info": "0 = Completely Dissatisfied, 10 =  Completely Datisfied",
      "scale_anchors": [
        "0 = Completely Dissatisfied",
        "10 =  Completely Datisfied"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_routine_made": {
      "name": "env_routine_made",
      "items": [
        "Have you made changes to your daily routine in order to protect the environment?"
      ],
      "waves": "1-6",
      "keywords": "environment",
      "reference": "liu2012hope",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_routine_willing": {
      "reference": "liu2012hope",
      "waves": "1-6",
      "keywords": "environment",
      "items": [
        "Are you willing to change your daily routine in order to protect the environment?"
      ],
      "name": "env_routine_willing",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_sac_made": {
      "name": "env_sac_made",
      "items": [
        "Have you made sacrifices to your standard of living (e.g., accepted higher prices, driven less, conserved energy) in order to protect the environment?"
      ],
      "waves": "1-6,9",
      "keywords": "environment",
      "reference": "liu2012hope",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_sac_willing": {
      "reference": "liu2012hope",
      "waves": "1-6,9",
      "keywords": "environment",
      "items": [
        "Are you willing to make sacrifices to your standard of living (e.g., accept higher prices, drive less, conserve energy) in order to protect the environment?"
      ],
      "name": "env_sac_willing",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "env_sat_nz_environment": {
      "name": "env_sat_nz_environment",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life and New Zealand...The quality of New Zealand’s natural environment."
      ],
      "reference": "tiliouine_measuring_2006",
      "waves": "1-current",
      "keywords": "environment",
      "scale_info": "0 = Completely Dissatisfied, 10 =  Completely Datisfied",
      "scale_anchors": [
        "0 = Completely Dissatisfied",
        "10 =  Completely Datisfied"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "envefficacy": {
      "reference": "sharma2008we",
      "waves": "1-9;12-15",
      "keywords": "environment",
      "items": [
        "By taking personal action I believe I can make a positive difference to environmental problems.",
        "I feel I can make a difference to the state of the environment."
      ],
      "name": "envefficacy",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "eth_cat": {
      "description": "Coded string: (1 = New Zealand European; 2 = Māori; 3 = Pacific; 4 = Asian)",
      "waves": "1-current",
      "reference": "statsnz_ssga18",
      "name": "eth_cat",
      "items": [
        "Which ethnic group(s) do you belong to?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "euro": {
      "description": "Code string (Binary): (0 = not European, 1 = European)",
      "waves": "1-current",
      "reference": "statsnz_ssga18",
      "name": "euro",
      "items": [
        "Which ethnic group(s) do you belong to?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "extraversion": {
      "description": "Mini-IPIP6 Extraversion dimension: (i) I am the life of the party. (ii) I don't talk a lot. (r) (iii) I keep in the background. (r) (iv) I talk to a lot of different people at parties.",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "extraversion",
      "items": [
        "I am the life of the party.",
        "I don't talk a lot (reversed).",
        "I keep in the background (reversed).",
        "I talk to a lot of different people at parties."
      ],
      "keywords": "personality",
      "reversed_items": [2, 3],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "family_money_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "waves": "10-13",
      "keywords": "cooperation",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...family...MONEY (dollars)"
      ],
      "name": "family_money_binary",
      "reference": "sibley2021",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "family_time_binary": {
      "name": "family_time_binary",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...family...TIME (hours)."
      ],
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "waves": "10-13",
      "keywords": "cooperation",
      "reference": "sibley2021",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "forgiveness": {
      "name": "forgiveness",
      "items": [
        "Sometimes I can't sleep because of thinking about past wrongs I have suffered.",
        "I can usually forgive and forget when someone does me wrong.",
        "I find myself regularly thinking about past times that I have been wronged."
      ],
      "description": "We assessed participants' forgiveness using reversed scores of a the NZAVS \"vengeful rumination scale.\" This scale contains three items, adapted from @caprara_indicators_1986 and @berry_forgivingness_2005, and developed for NZAVS, ordinal response scale 1-7 (1 = Strongly Disagree to 7 = Strongly Agree).",
      "reference": "combines @berry_forgivingness_2005 and @caprara_indicators_1986.",
      "waves": "10-current",
      "keywords": "reflective-present",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "free_speech": {
      "name": "free_speech",
      "items": [
        "Although I may disagree with the opinions that other people hold, they should be allowed to express those views publicly."
      ],
      "reference": "dore2022boundaries",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "friends_money_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "sibley2021",
      "waves": "10-13",
      "keywords": "cooperation",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...family...MONEY (dollars)"
      ],
      "name": "friends_money_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "friends_time_binary": {
      "name": "friends_time_binary",
      "items": [
        "Please estimate how much help you have received from the following sources in the last week...friends...TIME (hours)."
      ],
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "sibley2021",
      "waves": "10-13",
      "keywords": "cooperation",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "gratitude": {
      "name": "gratitude",
      "items": [
        "I have much in my life to be thankful for.",
        "When I look at the world, I don't see much to be grateful for (reversed).",
        "I am grateful to a wide variety of people."
      ],
      "description": "Ordinal response scale 1 = Strongly Disagree to 7 = Strongly Agree.",
      "reference": "mccullough_grateful_2002",
      "waves": "10-current",
      "keywords": "reflective-life",
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "has_siblings": {
      "description": "\"Do you have siblings?\"",
      "reference": "stronge2019onlychild",
      "name": "has_siblings",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hlth_bmi": {
      "name": "hlth_bmi",
      "items": [
        "What is your height? (metres)\" and \"What is your weight? (kg)."
      ],
      "description": "Based on participants indication of their height and weight we calculated the BMI by dividing the weight in kilograms by the square of the height in meters.",
      "reference": "sibley2021",
      "waves": "2-current",
      "keywords": "health",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hlth_disability_binary": {
      "description": "We assessed disability with a one-item indicator adapted from Verbrugge (1997). It asks, \"Do you have a health condition or disability that limits you and that has lasted for 6+ months?\" (1 = Yes, 0 = No).",
      "waves": "5-current",
      "reference": "verbrugge1997",
      "name": "hlth_disability_binary",
      "items": [
        "Do you have a health condition or disability that limits you and that has lasted for 6+ months?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hlth_fatigue": {
      "waves": "5-current",
      "reference": "sibley2020",
      "name": "hlth_fatigue",
      "items": [
        "During the last 30 days, how often did ... you feel exhausted?"
      ],
      "keywords": "psychological-well-being",
      "scale_info": "0 = None Of The Time; 1 = A Little Of The Time; 2= Some Of The Time; 3 = Most Of The Time; 4 = All Of The Time",
      "scale_anchors": [
        "0 = None Of The Time",
        "1 = A Little Of The Time",
        "2= Some Of The Time",
        "3 = Most Of The Time",
        "4 = All Of The Time"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hlth_sleep_hours": {
      "name": "hlth_sleep_hours",
      "items": [
        "During the past month, on average, how many hours of actual sleep did you get per night?"
      ],
      "description": "Open ended response.",
      "reference": "buysse1989pittsburgh",
      "waves": "5-current",
      "keywords": "health",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "honesty_humility": {
      "description": "Mini-IPIP6 Honesty-Humility dimension: (i) I feel entitled to more of everything. (r) (ii) I deserve more things in life. (r) (iii) I would like to be seen driving around in a very expensive car. (r) (iv) I would get a lot of pleasure from owning expensive luxury goods. (r)",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "honesty_humility",
      "items": [
        "I feel entitled to more of everything (reversed).",
        "I deserve more things in life (reversed).",
        "I deserve more things in life (reversed).",
        "I would get a lot of pleasure from owning expensive luxury goods (reversed)."
      ],
      "keywords": "personality",
      "reversed_items": [1, 2, 3, 4],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hours_charity": {
      "name": "hours_charity",
      "items": [
        "Hours spent … voluntary/charitable work."
      ],
      "description": "Numerical: open-ended response",
      "reference": "sibley2011",
      "waves": "1-current",
      "keywords": "cooperation",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hours_children": {
      "description": "Numerical: open-ended response",
      "reference": "sibley2021",
      "waves": "1, 4-current",
      "keywords": "hours",
      "items": [
        "Hours spent ... looking after children"
      ],
      "name": "hours_children",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hours_commute": {
      "description": "",
      "reference": "sibley2021",
      "waves": "1,4-current",
      "keywords": "hours",
      "items": [
        "Hours spent...travelling/commuting."
      ],
      "name": "hours_commute",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hours_comp_games": {
      "description": "Numerical: open-ended response",
      "reference": "sibley2021",
      "waves": "1, 4-current",
      "keywords": "hours",
      "items": [
        "Hours spent ... playing computer games"
      ],
      "name": "hours_comp_games",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "hours_exercise_who_cat_num": {
      "name": "hours_exercise_who_cat_num",
      "description": "Responses classified by WHO codes: 1. Inactive: 0 h/week 2. Insufficiently active: > 0 to < 2.5 h/week (< 150 min/week) 3. Meeting guidelines: ≥ 2.5 to < 5 h/week (150–300 min/week) 4. Highly active: ≥ 5 to < 7.5 h/week (300–450 min/week) 5. Very highly active: ≥ 7.5 h/week (> 450 min/week) )",
      "reference": "who_2010_exercise",
      "waves": "1,4-current",
      "keywords": ["health", "hours"],
      "items": [
        "'Hours spent...exercising/physical activity' (coded numeric 1-5)"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "household_inc": {
      "name": "household_inc",
      "items": [
        "Please estimate your total household income (before tax) for the year XXXX."
      ],
      "waves": "1-current",
      "keywords": "demography",
      "reference": "sibley2021",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "kessler_latent_anxiety": [
      "During the past 30 days, how often did...you feel nervous?",
      "During the past 30 days, how often did...you feel restless or fidgety?",
      "During the past 30 days, how often did...you feel that everything was an effort?"
    ],
    "kessler_latent_depression": {
      "name": "kessler_latent_depression",
      "items": [
        "During the past 30 days, how often did...you feel hopeless?",
        "During the past 30 days, how often did...you feel so depressed nothing could cheer you up?",
        "During the past 30 days, how often did...you feel worthless?"
      ],
      "reference": "kessler2002",
      "waves": "2-current",
      "keywords": "psychological-well-being",
      "scale_info": "0 = None Of The Time; 1 = A Little Of The Time; 2= Some Of The Time; 3 = Most Of The Time; 4 = All Of The Time",
      "scale_anchors": [
        "0 = None Of The Time",
        "1 = A Little Of The Time",
        "2= Some Of The Time",
        "3 = Most Of The Time",
        "4 = All Of The Time"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "kessler6": {
      "reference": "kessler2002",
      "waves": "2-current",
      "keywords": "psychological-well-being",
      "items": [
        "During the past 30 days, how often did...you feel hopeless?",
        "During the past 30 days, how often did...you feel so depressed nothing could cheer you up?",
        "During the past 30 days, how often did...you feel restless or fidgety?",
        "During the past 30 days, how often did...you feel that everything was an effort?",
        "During the past 30 days, how often did...you feel worthless?",
        "During the past 30 days, how often did...you feel nervous?"
      ],
      "name": "kessler6",
      "scale_info": "0 = None Of The Time; 1 = A Little Of The Time; 2= Some Of The Time; 3 = Most Of The Time; 4 = All Of The Time",
      "scale_anchors": [
        "0 = None Of The Time",
        "1 = A Little Of The Time",
        "2= Some Of The Time",
        "3 = Most Of The Time",
        "4 = All Of The Time"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "kessler6_sum": {
      "reference": "kessler2002",
      "waves": "2-current",
      "keywords": "psychological-well-being",
      "items": [
        "During the past 30 days, how often did...you feel hopeless?",
        "During the past 30 days, how often did...you feel so depressed nothing could cheer you up?",
        "During the past 30 days, how often did...you feel restless or fidgety?",
        "During the past 30 days, how often did...you feel that everything was an effort?",
        "During the past 30 days, how often did...you feel worthless?",
        "During the past 30 days, how often did...you feel nervous?"
      ],
      "name": "kessler6_sum",
      "scale_info": "0 = None Of The Time; 1 = A Little Of The Time; 2= Some Of The Time; 3 = Most Of The Time; 4 = All Of The Time",
      "scale_anchors": [
        "0 = None Of The Time",
        "1 = A Little Of The Time",
        "2= Some Of The Time",
        "3 = Most Of The Time",
        "4 = All Of The Time"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "life_satisfaction": {
      "name": "life_satisfaction",
      "description": "Life satisfaction was measured using a standard scale",
      "reference": "satisfaction_reference",
      "waves": "1-4",
      "keywords": ["wellbeing", "satisfaction"],
      "items": [
        "i am satisfied with my life",
        "the conditions of my life are excellent"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "lifesat": {
      "name": "lifesat",
      "items": [
        "I am satisfied with my life.",
        "In most ways my life is close to ideal."
      ],
      "description": ".",
      "reference": "diener1985a",
      "waves": "5-current",
      "keywords": "health",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_hours_children": {
      "description": "We took the natural log of the response + 1.",
      "waves": "1,4-current.",
      "reference": "sibley2011",
      "name": "log_hours_children",
      "items": [
        "Hours spent...looking after children."
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_hours_commute": {
      "name": "log_hours_commute",
      "items": [
        "Hours spent...travelling/commuting."
      ],
      "description": "We took the natural log of the response + 1.",
      "waves": "1,4-current",
      "reference": "sibley2021",
      "keywords": "hours",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_hours_exercise": {
      "description": "We took the natural log of the response + 1.",
      "waves": "1,4-current",
      "reference": "sibley2011",
      "name": "log_hours_exercise",
      "items": [
        "Hours spent...exercising/physical activity."
      ],
      "keywords": "hours",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_hours_housework": {
      "description": "We took the natural log of the response + 1.",
      "waves": "1,4-current.",
      "reference": "sibley2011",
      "name": "log_hours_housework",
      "items": [
        "Hours spent...housework/cooking."
      ],
      "keywords": "hours",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_hours_work": {
      "description": "We took the natural log of the response + 1.",
      "waves": "1,4-current",
      "reference": "sibley2011",
      "name": "log_hours_work",
      "items": [
        "Hours spent...working in paid employment."
      ],
      "keywords": "hours",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "log_household_inc": {
      "name": "log_household_inc",
      "items": [
        "Please estimate your total household income (before tax) for the year XXXX."
      ],
      "description": "We took the natural log of the response + 1.",
      "waves": "1-3, 4-current",
      "keywords": "demography",
      "reference": "sibley2021",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "male": {
      "description": "We asked participants' gender in an open-ended question: \"what is your gender?\" or \"Are you male or female?\" (waves: 1-5). Female was coded as 0, Male was coded as 1, and gender diverse coded as 3 (Fraser et al., 2020). (or 0.5 = neither female nor male). Here, we coded all those who responded as Male as 1, and those who did not as 0.",
      "waves": "1-current",
      "reference": "fraser_coding_2020",
      "name": "male",
      "items": [
        "What is your gender?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "male_binary": {
      "description": "Here, we coded all those who responded as Male as 1, and those who did not as 0.",
      "waves": "1-current",
      "reference": "fraser_coding_2020",
      "name": "male_binary",
      "items": [
        "We asked participants’ gender in an open-ended question: \"what is your gender?\""
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "meaning_purpose": {
      "name": "meaning_purpose",
      "items": [
        "My life has a clear sense of purpose"
      ],
      "description": ".",
      "reference": "steger_meaning_2006",
      "waves": "10-current",
      "keywords": "reflective-life",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "meaning_sense": {
      "name": "meaning_sense",
      "items": [
        "I have a good sense of what makes my life meaningful."
      ],
      "description": ".",
      "reference": "steger_meaning_2006",
      "waves": "10-current",
      "keywords": "reflective-life",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_emphasis_on_science": {
      "reference": "hartman2017",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "Our society places too much emphasis on science (reversed)."
      ],
      "name": "mistrust_emphasis_on_science",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_free_speech": {
      "reference": "dore2022boundaries",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "Although I may disagree with the opinions that other people hold, they should be allowed to express those views publicly (reversed)."
      ],
      "name": "mistrust_free_speech",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_official_version_truth": {
      "reference": "knowles2009malleability",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I think that the official version of major world events given by authorities often hides the truth."
      ],
      "name": "mistrust_official_version_truth",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_police": {
      "reference": "tyler2005",
      "waves": "7,9-current",
      "keywords": "institutional_trust",
      "items": [
        "People's basic rights are well protected by the New Zealand Police (reversed).",
        "There are many things about the New Zealand Police and its policies that need to be changed.",
        "The New Zealand Police care about the well-being of everyone they deal with (reversed)."
      ],
      "name": "mistrust_police",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": [1, 3],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_politicians": {
      "reference": "sibley2020a",
      "waves": "9-current",
      "keywords": "institutional_trust",
      "items": [
        "Politicians in New Zealand can generally be trusted (reversed)."
      ],
      "name": "mistrust_politicians",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "mistrust_scientific_community": {
      "reference": "nisbet2015",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I have a high degree of confidence in the scientific community (reversed)."
      ],
      "name": "mistrust_scientific_community",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "modesty": {
      "description": "Participants indicated the extent to which they agree with the following four statements from Campbell et al. (2004), and Sibley et al. (2011) (1 = Strongly Disagree to 7 = Strongly Agree): (i) I want people to know that I am an important person of high status, (Waves: 1, 10-14); (ii) I am an ordinary person who is no better than others. (all waves); (iii) I wouldn't want people to treat me as though I were superior to them. (all waves); (iv) I think that I am entitled to more respect than the average person is. (all waves)",
      "waves": "10-14",
      "reference": "campbell2004",
      "name": "modesty",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "neighbourhood_community": {
      "name": "neighbourhood_community",
      "items": [
        "I feel a sense of community with others in my local neighbourhood."
      ],
      "description": ".",
      "reference": "sengupta2013",
      "waves": "6-current",
      "keywords": "reflective-social",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "neuroticism": {
      "description": "Mini-IPIP6 Neuroticism dimension: (i) I have frequent mood swings. (ii) I am relaxed most of the time. (r) (iii) I get upset easily. (iv) I seldom feel blue. (r)",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "neuroticism",
      "items": [
        "I have frequent mood swings.",
        "I am relaxed most of the time (reversed).",
        "I get upset easily.",
        "I seldom feel blue (reversed)."
      ],
      "keywords": "personality",
      "reversed_items": [2, 4],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "not_heterosexual_binary": {
      "name": "not_heterosexual_binary",
      "items": [
        "How would you describe your sexual orientation? (e.g., heterosexual, homosexual, straight, gay, lesbian, bisexual, etc.)"
      ],
      "description": "Open-ended question, coded as binary (not heterosexual = 1).",
      "reference": "greaves2017diversity",
      "waves": "5-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "not_lost": {
      "name": "not_lost",
      "items": [
        "Indicator of whether participant was not lost to follow up in the following wave."
      ],
      "reference": "sibley2021",
      "waves": "1-current",
      "keywords": "coding",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "nz_dep2018": {
      "name": "nz_dep2018",
      "items": [
        "New Zealand Deprivation - Decile Index - Using 2018 Census Data"
      ],
      "description": "Numerical: (1-10)",
      "reference": "atkinson2019",
      "waves": "1-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "nzsei_13_l": {
      "description": "This index uses the income, age, and education of a reference group, in this case, the 2013 New Zealand census, to calculate a score for each occupational group. Scores range from 10 (Lowest) to 90 (Highest). This list of index scores for occupational groups was used to assign each participant a NZSEI-13 score based on their occupation.",
      "waves": "8-current",
      "reference": "fahy2017",
      "name": "nzsei_13_l",
      "items": [
        "We assessed occupational prestige and status using the New Zealand Socio-economic Index 13 (NZSEI-13)."
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "openness": {
      "description": "Mini-IPIP6 Openness to Experience dimension: (i) I have a vivid imagination. (ii) I have difficulty understanding abstract ideas. (r) (iii) I do not have a good imagination. (r) (iv) I am not interested in abstract ideas. (r)",
      "waves": "1-current",
      "reference": "sibley2011",
      "name": "openness",
      "items": [
        "I have a vivid imagination.",
        "I have difficulty understanding abstract ideas (reversed).",
        "I do not have a good imagination (reversed).",
        "I am not interested in abstract ideas (reversed)."
      ],
      "keywords": "personality",
      "reversed_items": [2, 3, 4],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "parent": {
      "name": "parent",
      "items": [
        "\"If you are a parent, in which year was your eldest child born?\" (Parents were coded as 1, while the others were coded as 0)"
      ],
      "reference": "sibley2020",
      "waves": "1-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "parent_binary": {
      "description": "Parents were coded as 1, while the others were coded as 0.",
      "waves": "5-current",
      "reference": "sibley2021",
      "name": "parent_binary",
      "items": [
        "If you are a parent, in which year was your eldest child born?"
      ],
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "partner": {
      "description": "\"What is your relationship status?\" (e.g., single, married, de-facto, civil union, widowed, living together, etc.)",
      "reference": "sibley2021",
      "name": "partner",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "partner_binary": {
      "name": "partner_binary",
      "items": [
        "What is your relationship status? (e.g., single, married, de-facto, civil union, widowed, living together, etc.)"
      ],
      "description": "Coded as binary (has partner = 1).",
      "waves": "1-current",
      "keywords": "demography",
      "reference": "sibley2021",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "perc_age_discrim": {
      "name": "perc_age_discrim",
      "items": [
        "I feel that I am often discriminated against because of my age."
      ],
      "waves": "2-current",
      "keywords": "prejudice",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "perc_discrim": {
      "name": "perc_discrim",
      "items": [
        "I feel that I am often discriminated against because of my ethnicity."
      ],
      "waves": "1-current",
      "keywords": "prejudice",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "perc_gend_discrim": {
      "name": "perc_gend_discrim",
      "items": [
        "I feel that I am often discriminated against because of my gender."
      ],
      "waves": "2-current",
      "keywords": "prejudice",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "perc_religious_discrim": {
      "name": "perc_religious_discrim",
      "items": [
        "I feel that I am often discriminated against because of my religious/spiritual beliefs."
      ],
      "waves": "7-current",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "perfectionism": {
      "name": "perfectionism",
      "items": [
        "Doing my best never seems to be enough.",
        "My performance rarely measures up to my standards.",
        "I am hardly ever satisfied with my performance."
      ],
      "description": ".",
      "reference": "rice_short_2014",
      "waves": "10-current",
      "keywords": "reflective-present",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pol_politician_trust": {
      "name": "pol_politician_trust",
      "items": [
        "Politicians in New Zealand can generally be trusted."
      ],
      "waves": "9-current",
      "keywords": "institutional_trust",
      "reference": "sibley2020a",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pol_wing": {
      "description": "We measured participants' political right-wing orientation using a single item adapted from Jost (2006): \"Please rate how politically left-wing versus right-wing you see yourself as being.\" (1 = Extremely left-wing to 7 = Extremely right-wing)",
      "reference": "jost_end_2006-1",
      "name": "pol_wing",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "police_trust": {
      "name": "police_trust",
      "items": [
        "People's basic rights are well protected by the New Zealand Police.",
        "There are many things about the New Zealand Police and its policies that need to be changed (reversed).",
        "The New Zealand Police care about the well-being of everyone they deal with."
      ],
      "reference": "tyler2005",
      "waves": "7,9-current",
      "keywords": "institutional_trust",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "political_conservative": {
      "waves": "1-current",
      "reference": "jost_end_2006-1",
      "name": "political_conservative",
      "items": [
        "Please rate how politically liberal versus conservative you see yourself as being."
      ],
      "keywords": "demography",
      "scale_info": "1 = Extremely Liberal, 7 = Extremely Conservative",
      "scale_anchors": [
        "1 = Extremely Liberal",
        "7 = Extremely Conservative"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "power_no_control_composite": {
      "reference": "overall2016power",
      "waves": "10-13,16",
      "keywords": "present",
      "items": [
        "I do not have enough power or control over important parts of my life.",
        "Other people have too much power or control over important parts of my life."
      ],
      "name": "power_no_control_composite",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "power_others_control": {
      "name": "power_others_control",
      "items": [
        "Other people have too much power or control over important parts of my life."
      ],
      "waves": "10-13,16",
      "keywords": "present",
      "reference": "overall2016power",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "power_self_nocontrol": {
      "reference": "overall2016power",
      "waves": "10-13,16",
      "keywords": "present",
      "items": [
        "Other people have too much power or control over important parts of my life."
      ],
      "name": "power_self_nocontrol",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pwb_standard_living": {
      "name": "pwb_standard_living",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life...Your standard of living."
      ],
      "description": ".",
      "waves": "1-current",
      "keywords": "reflective-present",
      "reference": "cummins_developing_2003",
      "scale_info": "0 = completely dissatisfied to 10 = completely satisfied",
      "scale_anchors": "0 = completely dissatisfied to 10 = completely satisfied",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pwb_your_future_security": {
      "name": "pwb_your_future_security",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life...Your future security."
      ],
      "description": ".",
      "reference": "cummins_developing_2003",
      "waves": "1-current",
      "keywords": "reflective-present",
      "scale_info": "0 = completely dissatisfied to 10 = completely satisfied",
      "scale_anchors": "0 = completely dissatisfied to 10 = completely satisfied",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pwb_your_health": {
      "name": "pwb_your_health",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life...Your health."
      ],
      "description": ".",
      "waves": "1-current",
      "keywords": "reflective-present",
      "reference": "cummins_developing_2003",
      "scale_info": "0 = completely dissatisfied to 10 = completely satisfied",
      "scale_anchors": "0 = completely dissatisfied to 10 = completely satisfied",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "pwb_your_relationships": {
      "name": "pwb_your_relationships",
      "items": [
        "Please rate your level of satisfaction with the following aspects of your life...Your personal relationships."
      ],
      "description": ".",
      "waves": "1-current",
      "keywords": "reflective-present",
      "reference": "cummins_developing_2003",
      "scale_info": "0 = completely dissatisfied to 10 = completely satisfied",
      "scale_anchors": "0 = completely dissatisfied to 10 = completely satisfied",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_believe_god": {
      "name": "religion_believe_god",
      "items": [
        "Do you believe in a God?"
      ],
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "eurobarometer2005b",
      "waves": "2-current",
      "keywords": "religion",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_believe_god_binary": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "eurobarometer2005b",
      "waves": "2-current",
      "keywords": "religion",
      "items": [
        "Do you believe in a God?"
      ],
      "name": "religion_believe_god_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_believe_spirit": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "eurobarometer2005b",
      "waves": "2-current",
      "keywords": "religion",
      "items": [
        "Do you believe in some form of spirit or life force?"
      ],
      "name": "religion_believe_spirit",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_believe_spirit_binary": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "eurobarometer2005b",
      "waves": "2-current",
      "keywords": "religion",
      "items": [
        "Do you believe in some form of spirit or life force?"
      ],
      "name": "religion_believe_spirit_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_bigger_denominations": {
      "name": "religion_bigger_denominations",
      "items": [
        "Do you identify with a religion and/or spiritual group? --> (If yes...)--> What religion or spiritual group?"
      ],
      "reference": "sibley2021",
      "waves": "1-current",
      "keywords": "religion",
      "description": "Open-ended (string). Coded from New Zealand Census Categories. Levels are: \"Not Religious\",\"Anglican\",\"Buddhist\", \"Catholic\", \"Christian (Non-Denominational)\", \"Christian (Other Denominations)\",\"Hindu\", \"Jewish\", \"Muslim\",\"Presbyterian, Congregational, Reformed\", \"Other Religions\".",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_church": {
      "name": "religion_church",
      "items": [
        "How many times did you attend a church or place of worship in the last month?"
      ],
      "description": "Numerical: open-ended response",
      "reference": "sibley2012",
      "waves": "2-11; 12(imputed); 13(partial)- current.",
      "keywords": "religion",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_church_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "sibley2012",
      "waves": "2-11; 14-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group? -> How many times did you attend a church or place of worship in the last month?"
      ],
      "name": "religion_church_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_identification_level": {
      "name": "religion_identification_level",
      "items": [
        "How important is your religion to how you see yourself?"
      ],
      "waves": "1-current",
      "keywords": "religion",
      "reference": "sibley2021",
      "scale_info": "1 = Not Important, 7 = Very Important",
      "scale_anchors": [
        "1 = Not Important",
        "7 = Very Important"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_prayer": {
      "description": "Numerical: open-ended response",
      "reference": "bulbulia_2015",
      "waves": "6-12, 14-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group? -> How many times did you pray in the last week?"
      ],
      "name": "religion_prayer",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_prayer_binary": {
      "description": "Numerical: open-ended response",
      "reference": "bulbulia_2015",
      "waves": "6-12, 14-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group? -> How many times did you pray in the last week?"
      ],
      "name": "religion_prayer_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_religious": {
      "name": "religion_religious",
      "items": [
        "Do you identify with a religion and/or spiritual group?"
      ],
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "statsnz_ssga18",
      "waves": "1-current",
      "keywords": "religion",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_religious_binary": {
      "description": "Binary response: (0 = No, 1 = Yes)",
      "reference": "statsnz_ssga18",
      "waves": "1-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group?"
      ],
      "name": "religion_religious_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_scripture": {
      "description": "Numerical: open-ended response",
      "reference": "bulbulia2016",
      "waves": "6-12, 14-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group? -> How many times did you read religious scripture in the last week?"
      ],
      "name": "religion_scripture",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_scripture_binary": {
      "description": "Code string (Binary): (0 = 0, 1 = greater than 0)",
      "reference": "bulbulia2016",
      "waves": "6-12, 14-current",
      "keywords": "religion",
      "items": [
        "Do you identify with a religion and/or spiritual group? -> How many times did you read religious scripture in the last week?"
      ],
      "name": "religion_scripture_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_spiritual_identification": {
      "reference": "postmes2013single",
      "waves": "8,10,12-current",
      "keywords": "religion",
      "items": [
        "I identify as a spiritual person"
      ],
      "name": "religion_spiritual_identification",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "religion_spiritual_identification_level": {
      "reference": "postmes2013single",
      "waves": "8,10,12-current",
      "keywords": "religion",
      "items": [
        "I identify as a spiritual person"
      ],
      "name": "religion_spiritual_identification_level",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "rumination": {
      "name": "rumination",
      "items": [
        "During the last 30 days, how often did...you have negative thoughts that repeated over and over?"
      ],
      "description": "Ordinal responses: 0 = None of The Time, 1 = A little of The Time, 2 = Some of The Time, 3 = Most of The Time, 4 = All of The Time.",
      "reference": "nolen-hoeksema_effects_1993",
      "waves": "2-current",
      "keywords": "psychological-wellbeing",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "rural_gch_2018_l": {
      "name": "rural_gch_2018_l",
      "items": [
        "High Urban Accessibility = 1, Medium Urban Accessibility = 2, Low Urban Accessibility  = 3, Remote = 4, Very Remote = 5."
      ],
      "description": "\"Participants residence locations were coded according to a five-level ordinal categorisation ranging from Urban to Rural.\"",
      "reference": "whitehead2023unmasking",
      "waves": "1-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "rwa": {
      "name": "rwa",
      "items": [
        "It is always better to trust the judgment of the proper authorities in government and religion than to listen to the noisy rabble-rousers in our society who are trying to create doubt in people's minds.",
        "It would be best for everyone if the proper authorities censored magazines so that people could not get their hands on trashy and disgusting material.",
        "Our country will be destroyed some day if we do not smash the perversions eating away at our moral fibre and traditional beliefs.",
        "People should pay less attention to The Bible and other old traditional forms of religious guidance, and instead develop their own personal standards of what is moral and immoral.",
        "Atheists and others who have rebelled against established religions are no doubt every bit as good and virtuous as those who attend church regularly.",
        "Some of the best people in our country are those who are challenging our government, criticizing religion, and ignoring the \"normal way\" things are supposed to be done (reversed)."
      ],
      "reference": "altemeyer1996authoritarian",
      "waves": "1-current",
      "keywords": "demography",
      "description": "Right Wing Authoritarianism was measured using the following items:",
      "reversed_items": 6,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "sample_frame_opt_in_binary": {
      "name": "sample_frame_opt_in_binary",
      "items": [
        "Participant was not randomly sampled from the New Zealand Electoral Roll."
      ],
      "description": "Code string (Binary): (0 = No, 1 = Yes)",
      "reference": "sibley2021",
      "waves": "1-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "sdo": {
      "name": "sdo",
      "items": [
        "It is OK if some groups have more of a chance in life than others.",
        "Inferior groups should stay in their place.",
        "To get ahead in life, it is sometimes okay to step on other groups.",
        "We should have increased social equality (reversed).",
        "It would be good if groups could be equal (reversed).",
        "We should do what we can to equalise conditions for different groups (reversed)."
      ],
      "reference": "sidanius1999social",
      "waves": "1-current",
      "keywords": "demography",
      "description": "Social Dominance Orientation was measured using the following items:",
      "reversed_items": [4, 5, 6],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "self_control": {
      "name": "self_control",
      "items": [
        "In general, I have a lot of self-control",
        "I wish I had more self-discipline (reversed)"
      ],
      "reference": "tangney_high_2004",
      "waves": "5-current",
      "keywords": "present",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "self_control_have_lots": {
      "name": "self_control_have_lots",
      "items": [
        "In general, I have a lot of self-control."
      ],
      "description": ".",
      "waves": "5-current",
      "keywords": "reflective-present",
      "reference": "tangney_high_2004",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "self_control_wish_more_reversed": {
      "name": "self_control_wish_more_reversed",
      "items": [
        "I wish I had more self-discipline."
      ],
      "description": ".",
      "reference": "tangney_high_2004",
      "waves": "5-current",
      "keywords": "reflective-present",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "self_esteem": {
      "name": "self_esteem",
      "items": [
        "On the whole am satisfied with myself.",
        "Take a positive attitude toward myself.",
        "Am inclined to feel that I am a failure (reversed)."
      ],
      "description": ".",
      "reference": "rosenberg1965",
      "waves": "1-current",
      "keywords": "reflective-present",
      "scale_info": "1 = Very inaccurate to 7 = Very accurate",
      "scale_anchors": "1 = Very inaccurate to 7 = Very accurate",
      "reversed_items": 3,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "sexual_satisfaction": {
      "name": "sexual_satisfaction",
      "items": [
        "How satisfied are you with your sex life?"
      ],
      "description": "Participants were asked to report their sexual orientation; ordinal response: 1 = Not satisfied to 7 = Very satisfied.",
      "reference": "sibley2021",
      "waves": "10-current",
      "keywords": "reflective-present",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "sfhealth": {
      "reference": "instrument1992mos",
      "waves": "5-current",
      "keywords": "health",
      "items": [
        "\"In general, would you say your health is...\"",
        "\"I seem to get sick a little easier than other people\" (reversed).",
        "\"I expect my health to get worse\" (reversed)."
      ],
      "name": "sfhealth",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": [2, 3],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "short_form_health": {
      "name": "short_form_health",
      "items": [
        "In general, would you say your health is..."
      ],
      "reference": "instrument1992mos",
      "waves": "5-current",
      "keywords": "health",
      "scale_info": "1 = Poor, 7 = Excellent",
      "scale_anchors": [
        "1 = Poor",
        "7 = Excellent"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "smoker_binary": {
      "name": "smoker_binary",
      "items": [
        "Do you currently smoke tobacco cigarettes?"
      ],
      "description": "Binary smoking indicator (0 = No, 1 = Yes).",
      "reference": "sibley2021",
      "waves": "4-current",
      "keywords": "health",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "support": {
      "waves": "1-current",
      "reference": "cutrona1987",
      "name": "support",
      "items": [
        "There are people I can depend on to help me if I really need it.",
        "There is no one I can turn to for guidance in times of stress (reversed).",
        "I know there are people I can turn to when I need help."
      ],
      "keywords": "social",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "support_help": {
      "reference": "cutrona1987",
      "waves": "1-current",
      "keywords": "social",
      "items": [
        "There are people I can depend on to help me if I really need it."
      ],
      "name": "support_help",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "support_noguidance_reversed": {
      "reference": "cutrona1987",
      "waves": "1-current",
      "keywords": "social",
      "items": [
        "There is no one I can turn to for guidance in times of stress (reversed)."
      ],
      "name": "support_noguidance_reversed",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "support_turnto": {
      "reference": "cutrona1987",
      "waves": "1-current",
      "keywords": "social",
      "items": [
        "I know there are people I can turn to when I need help."
      ],
      "name": "support_turnto",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_free_speech": {
      "reference": "dore2022boundaries",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "Although I may disagree with the opinions that other people hold, they should be allowed to express those views publicly."
      ],
      "name": "trust_free_speech",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_not_official_version_truth": {
      "reference": "knowles2009malleability",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I think that the official version of major world events given by authorities often hides the truth."
      ],
      "name": "trust_not_official_version_truth",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_science": {
      "reference": "hartman2017",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "Our society places too much emphasis on science (reversed)."
      ],
      "name": "trust_science",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_science_high_confidence_scientific_community": {
      "name": "trust_science_high_confidence_scientific_community",
      "items": [
        "I have a high degree of confidence in the scientific community."
      ],
      "reference": "nisbet2015",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_science_high_confidence_scientific_community_cat": {
      "description": "Quantiles of",
      "reference": "nisbet2015",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I have a high degree of confidence in the scientific community."
      ],
      "name": "trust_science_high_confidence_scientific_community_cat",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_science_low_confidence_scientific_community": {
      "reference": "nisbet2015",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I have a high degree of confidence in the scientific community (reversed)."
      ],
      "name": "trust_science_low_confidence_scientific_community",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "reversed_items": 1,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_science_our_society_places_too_much_emphasis_reversed": {
      "name": "trust_science_our_society_places_too_much_emphasis_reversed",
      "items": [
        "Our society places too much emphasis on science."
      ],
      "reference": "hartman2017",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "trust_scientists": {
      "reference": "nisbet2015",
      "waves": "11-current",
      "keywords": "institutional_trust",
      "items": [
        "I have a high degree of confidence in the scientific community."
      ],
      "name": "trust_scientists",
      "scale_info": "1 = Strongly Disagree, 7 = Strongly Agree",
      "scale_anchors": [
        "1 = Strongly Disagree",
        "7 = Strongly Agree"
      ],
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "urban_binary": {
      "description": "We coded whether they are living in an urban or rural area (1 = Urban, 0 = Rural) based on the addresses provided.",
      "waves": "1-current",
      "reference": "sibley2021",
      "name": "urban_binary",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "vengeful_rumin": {
      "name": "vengeful_rumin",
      "items": [
        "Sometimes I can't sleep because of thinking about past wrongs I have suffered.",
        "I can usually forgive and forget when someone does me wrong (reversed scored).",
        "I find myself regularly thinking about past times that I have been wronged."
      ],
      "description": "This scale contains three items, adapted from @caprara_indicators_1986 and @berry_forgivingness_2005, and developed for NZAVS; .",
      "reference": "sibley2021",
      "waves": "10-current",
      "keywords": "reflective-present",
      "scale_info": "1 = Strongly Disagree to 7 = Strongly Agree",
      "scale_anchors": "1 = Strongly Disagree to 7 = Strongly Agree",
      "reversed_items": 2,
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "volunteers": {
      "description": "We measured hours of volunteering using one item from Sibley et al. (2011): \"Hours spent … voluntary/charitable work.\" To stabilise this indicator, we took the natural log of the response + 1.",
      "reference": "sibley2011",
      "name": "volunteers",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "w_gend_age_ethnic": {
      "name": "w_gend_age_ethnic",
      "items": [
        "weight(age,gender,ethnicity) = prop_census(age,gender,ethnicity)/prop_sample(age,gender,ethnicity)"
      ],
      "description": "Sample weights for NZ population (NZ Census)",
      "reference": "sibley2021",
      "waves": "1-current",
      "keywords": "demography",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "w_gend_age_euro": {
      "description": "Sample weights for NZ population (NZ Census)",
      "reference": "sibley2021",
      "waves": "1-current",
      "keywords": "demography",
      "items": [
        "weight(age,gender,european) = prop_census(age,gender,ethnicity)/prop_sample(age,gender,european)"
      ],
      "name": "w_gend_age_euro",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_asians": {
      "name": "warm_asians",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Asians in general."
      ],
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_chinese": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Chinese."
      ],
      "name": "warm_chinese",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_disabled": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "12-15",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...People with disability."
      ],
      "name": "warm_disabled",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_elderly": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "9-16",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Elderly people."
      ],
      "name": "warm_elderly",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_immigrants": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...toward Immigrants in general."
      ],
      "name": "warm_immigrants",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_indians": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "2-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...toward Indians."
      ],
      "name": "warm_indians",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_lgbtq": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "12-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...LGBTQ+ people."
      ],
      "name": "warm_lgbtq",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_maori": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Māori."
      ],
      "name": "warm_maori",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_mental_illness": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "9-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...People with mental illness."
      ],
      "name": "warm_mental_illness",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_muslims": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "4-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Muslims."
      ],
      "name": "warm_muslims",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_nz_euro": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...NZ Europeans."
      ],
      "name": "warm_nz_euro",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_overweight": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Overweight people."
      ],
      "name": "warm_overweight",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_pacific": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "1-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Pacific Islanders."
      ],
      "name": "warm_pacific",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    },
    "warm_refugees": {
      "reference": "Modelled on United States National Election Study.",
      "waves": "9-current",
      "keywords": "cooperation",
      "items": [
        "Please rate your feelings of WARMTH toward the following groups using the 'feeling thermometer scale' for each group...Refugees."
      ],
      "name": "warm_refugees",
      "scale_info": "Feel LEAST WARM Toward This Group = 1,… 4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "scale_anchors": "4 = Neutral… 7 = Feel MOST WARM Toward This Group",
      "standardised": true,
      "standardised_date": "2025-10-17"
    }
  },
  "methods": {
    "analytic_approach": {
      "general_approach_cate_long": "\n### Moderators and treatment policies\n\nWe asked whether individualised targeting, guided by conditional average treatment effects $\\hat{\\tau}(x)$, can out-perform a one-size-fits-all strategy, and how any gains might be converted into rules that practitioners trust.\n\n#### Pre-processing and honest model training\n\nDirection was standardised by sign-flipping outcomes whose valence opposed that of the exposure; the affected measures were {{flipped_list}}. Each analysis used an honest {{sample_ratio_policy}} split: the training fold built a causal forest with grf [@grf2024], while the held-out fold supplied every diagnostic and served as the data set for learning policy trees.  This partition keeps each estimate out-of-sample and protects against over-fitting.\n\n#### Stage 1: Omnibus and Rank Average Treatment Effect Analysis (RATE)\n\nOn the evaluation data, we first ran an omnibus test for differential prediction and calibration to detect any systematic prediction error. Concurrently, we computed RATE-AUTOC (Area Under the Targeting Operating Characteristic) and RATE-Qini (weighted area emphasising broader improvements) statistics. All RATE tests employed five-fold cross-validation following [@wager2024_sequential_validation_hte]. Detailed results are reported in S{{appendix_rate}}.\n\n#### Stage 2: Budget-specific exploration\n\nFor outcomes passing Stage 1 (i.e., at least one non-negative RATE result), we conducted exploratory analysis using Qini curves. Assuming a unit treatment cost per participant, we examined potential gains at the top 10 % and 40% of the population (highly restricted/restricted resources). This analysis quantifies the expected uplift from targeted treatment under realistic budget scenarios, with 95% confidence intervals indicating precision. Results are exploratory and intended to inform resource allocation decisions.\n\n#### Stage 3: Transparent decision rules\n\nFor outcomes showing promise in Stage 2, we developed interpretable 'if–then' rules using depth-2 policy trees [@policytree_package_2024; @athey_2021_policy_tree_econometrica]. To ensure robustness, we employed `margot::margot_policy_tree_stability()` with {{n_iterations}} iterations of varying train/test splits. Variables appearing consistently (>{{stability_threshold}} % frequency) indicate reliable treatment effect modifiers, while high variability suggests the decision boundaries may be unstable.\n\nThis staged approach -- forest $\\rightarrow$ omnibus and rate diagnostics $\\rightarrow$ Qini-screening $\\rightarrow$ stability-based rule extraction -- ensures we only develop targeting strategies for outcomes with solid evidence of heterogeneity, quantifies their practical value under resource constraints, and delivers decision rules that practitioners can implement with confidence. Algorithmic details appear in S{{appendix_explain_grf}}.\n",
      "general_approach_cate_long_no_flip": "\n### Moderators and treatment policies\n\nWe pursued two complementary objectives: (i) to test whether personalised targeting, based on individual conditional average treatment effects $\\hat\\tau(x)$, yields welfare gains, and (ii) to convert any such gains into transparent, practitioner‐ready decision rules.\n\n#### Pre-processing and honest model training\n\nEach model estimate used an honest {{sample_ratio_policy}} split: the training fold built the causal forest with grf [@grf2024], while the held-out fold powered all diagnostic checks and provided data for fitting policy trees.  This separation curbs over-fitting yet keeps the workflow simple.\n\n#### Budget-based screening with Qini curves.\n\nBefore constructing rules we asked a budget question: If resources allow treatment of only the top 20% or 50% of individuals ranked by $\\hat\\tau(x)$, what uplift is purchased relative to treating everyone?\nQini curves quantified the incremental gain; outcomes whose 95% confidence intervals excluded zero at either spend level were labelled actionable, signalling meaningful heterogeneity in benefit.\n\n#### Deriving transparent decision rules.\n\nFor each actionable outcome we trained depth-2 policy trees with policytree [@policytree_package_2024; @athey_2021_policy_tree_econometrica] on the validation data.  The resulting if–then statements maximise expected welfare under the same budget cap and remain auditable by domain experts.\n\n####  Global heterogeneity tests (supplementary).\n\nS{{appendix_rate}} reports RATE-AUTOC and RATE-Qini statistics, asking whether any covariate information can beat a uniform policy.  These tests, controlled for false discovery at q={{cate_alpha}} via {{cate_adjustment}}, are informative but not required for the budget-first pipeline.\n\nOverall, combining Qini curves to screen and shallow policy trees to act isolates budget-relevant treatment heterogeneity and distils it into actionable rules, avoiding the chase for spurious complexity. Full technical details appear in Appendix {{appendix_explain_grf}}.\n",
      "general_approach_cate_short": "\n### Heterogeneous Treatment Effects: moderators and treatment policies\n\nWe asked whether individualised targeting, guided by conditional average treatment effects $\\hat\\tau(x)$, can out-perform a one-size-fits-all strategy, and how any gains might be converted into rules that practitioners trust.\n\n#### Pre-processing and honest forests\n\nEach analysis used an honest {{sample_ratio_policy}} split: the training fold built a causal forest with grf [@grf2024], while the held-out fold supplied every diagnostic and served as the data set for learning policy trees.  This partition keeps each estimate out-of-sample and protects against over-fitting.\n\n#### Diagnostics\n\nOn the evaluation fold we first verified forest calibration, then computed RATE-AUTOC and RATE-Qini statistics, formal tests of whether any covariate information can beat uniform treatment [@wager2018].  p-values were adjusted by the Benjamini–Hochberg procedure at q={{cate_alpha}} using {{cate_adjustment}} [@benjamini1995controlling]. S{{appendix_rate}} reports RATE-AUTOC and RATE-Qini statistics.\n\n#### Budget-focused evidence\n\nBecause programme budgets are finite, we next asked: If resources permit treating only the top 10% ranked by $\\hat\\tau(x)$, what uplift should planners expect?  Qini curves answer this question and flag an outcome as actionable when the 95% confidence interval for incremental gain excluded zero at either spending level.\n\nNote that RATE and Qini provide complementary lenses—global versus budget-specific evidence -- and either can justify the move to rule learning.\n\n#### Transparent decision rules\n\nFor each actionable outcome we fitted a depth-2 policy tree with policytree on the validation data [@policytree_package_2024; @athey_2021_policy_tree_econometrica].  The tree yields an if–then allocation rule that maximises expected welfare under the chosen budget cap and remains fully auditable.\n\nThe workflow—forest $\\rightarrow$ diagnostics $\\rightarrow$ tree—identifies meaningful heterogeneity, quantifies the payoff to targeting, and delivers concise decision rules that practitioners can implement.\n\n#### Challenges in estimating heterogeneous treatment effects\n\nEstimating individualised treatment effects poses several fundamental challenges. First, inferring $\\hat\\tau(x)$ requires modelling how treatment effects vary with high-dimensional covariates, which risks severe overfitting when sample sizes are modest or predictors are numerous. Second, treatment assignment must satisfy overlap (positivity) across all covariate strata: sparse or empty regions in $X$ undermine the credibility of any estimated heterogeneity, inflating variance or introducing bias.\n\nThird, standard machine-learning algorithms optimise predictive accuracy, not causal effect estimation; naively applying them can produce systematically mis-calibrated CATEs. Honest splitting (or cross-fitting) mitigates this, but at the cost of reduced effective sample size in each fold. Fourth, unmeasured confounding or model‐misspecification can masquerade as heterogeneity, so rigorous diagnostic tests (e.g. omnibus, RATE-AUTOC, RATE-Qini) are essential to distinguish genuine treatment effect variation from artefacts of imbalance or noise.\n\nFinally, the trade-off between flexibility and interpretability looms large: highly flexible methods (causal forests, deep nets) can uncover subtle patterns but yield complex CATE surfaces, whereas simpler parametric models may miss non-linear interactions. Our staged pipeline—forest $\\rightarrow$ diagnostics $\\rightarrow$ Qini-screening $\\rightarrow$ policy-tree—navigates these trade-offs by first safeguarding against overfitting and false positives, then focusing on budget‐relevant gains, and finally distilling results into transparent, low-depth decision rules. Furhter details on our approach and algorithms appear in S{{appendix_explain_grf}}.\n",
      "general_approach_cate_short_no_flip": "\n### Heterogeneous Treatment Effects: moderators and treatment policies\n\nWe asked whether individualised targeting, guided by conditional average treatment effects $\\hat\\tau(x)$, can out-perform a one-size-fits-all strategy, and how any gains might be converted into rules that practitioners trust.\n\n#### Pre-processing and honest forests\n\nEach analysis used an honest {{sample_ratio_policy}} split: the training fold built a causal forest with grf [@grf2024], while the held-out fold supplied every diagnostic and served as the data set for learning policy trees.  This partition keeps each estimate out-of-sample and protects against over-fitting.\n\n#### Diagnostics\n\nOn the evaluation fold we first verified forest calibration, then computed RATE-AUTOC and RATE-Qini statistics, formal tests of whether any covariate information can beat uniform treatment [@wager2018].  p-values were adjusted by the Benjamini–Hochberg procedure at q={{cate_alpha}} using {{cate_adjustment}} [@benjamini1995controlling]. S{{appendix_rate}} reports RATE-AUTOC and RATE-Qini statistics.\n\n#### Budget-focused evidence\n\nBecause programme budgets are finite, we next asked: If resources permit treating only the top 10% ranked by $\\hat\\tau(x)$, what uplift should planners expect?  Qini curves answer this question and flag an outcome as actionable when the 95% confidence interval for incremental gain excluded zero at either spending level.\n\nNote that RATE and Qini provide complementary lenses—global versus budget-specific evidence -- and either can justify the move to rule learning.\n\n#### Transparent decision rules\n\nFor each actionable outcome we fitted a depth-2 policy tree with policytree on the validation data [@policytree_package_2024; @athey_2021_policy_tree_econometrica].  The tree yields an if–then allocation rule that maximises expected welfare under the chosen budget cap and remains fully auditable.\n\nThe workflow—forest $\\rightarrow$ diagnostics $\\rightarrow$ tree—identifies meaningful heterogeneity, quantifies the payoff to targeting, and delivers concise decision rules that practitioners can implement. \n\n#### Challenges in estimating heterogeneous treatment effects\n\nEstimating individualised treatment effects poses several fundamental challenges. First, inferring $\\hat\\tau(x)$ requires modelling how treatment effects vary with high-dimensional covariates, which risks severe overfitting when sample sizes are modest or predictors are numerous. Second, treatment assignment must satisfy overlap (positivity) across all covariate strata: sparse or empty regions in $X$ undermine the credibility of any estimated heterogeneity, inflating variance or introducing bias.  \n\nThird, standard machine-learning algorithms optimise predictive accuracy, not causal effect estimation; naively applying them can produce systematically mis-calibrated CATEs. Honest splitting (or cross-fitting) mitigates this, but at the cost of reduced effective sample size in each fold. Fourth, unmeasured confounding or model‐misspecification can masquerade as heterogeneity, so rigorous diagnostic tests (e.g. omnibus, RATE-AUTOC, RATE-Qini) are essential to distinguish genuine treatment effect variation from artefacts of imbalance or noise.  \n\nFinally, the trade-off between flexibility and interpretability looms large: highly flexible methods (causal forests, deep nets) can uncover subtle patterns but yield complex CATE surfaces, whereas simpler parametric models may miss non-linear interactions. Our staged pipeline—forest $\\rightarrow$ diagnostics $\\rightarrow$ Qini-screening $\\rightarrow$ policy-tree—navigates these trade-offs by first safeguarding against overfitting and false positives, then focusing on budget‐relevant gains, and finally distilling results into transparent, low-depth decision rules. Furhter details on our approach and algorithms appear in S{{appendix_explain_grf}}.\n\n",
      "simple_general_approach_cate_long": "\n### Learning Moderators and Deriving Practical Treatment Rules\n\nAfter estimating the average treatment effect, we asked *for whom* the exposure helps and *how* to act on that knowledge.  The workflow:\n\n1. **Orient outcomes.** All scales were re-coded so that higher scores had the same valence as the exposure (flipped: {{flipped_list}}).\n2. **Honest causal forest.** A {{sample_ratio_policy}} split trained the forest and produced out-of-sample CATEs $\\hat\\tau(x)$ on the validation fold [@grf2024].\n3. **Global heterogeneity test.** On the validation fold we computed **RATE-AUTOC** and **RATE-Qini**; FDR was controlled with {{cate_adjustment}} at q = {{cate_alpha}} [@benjamini1995controlling] (see S{{appendix_rate}}).\n4. **Budget lens.** **Qini curves** compared “treat top–ranked” to “treat all”, revealing expected uplift at budget caps (S{{appendix_qini_curve}}).\n5. **Transparent policy.** When heterogeneity looked actionable, we fitted depth-2 **policy trees** on the validation fold, turning the black-box forest into concise *if–then* rules (details in S{{appendix_explain_grf}}).\n\nThis pipeline converts complex CATE estimates into interpretable, out-of-sample decision policies while controlling both over-fitting and multiple testing.",
      "simple_general_approach_cate_long_no_flip": "\n### Learning Moderators and Deriving Practical Treatment Rules\n\nAfter estimating the average treatment effect, we asked *for whom* the exposure helps and *how* to act on that knowledge.  The workflow:\n\n1. **Orient outcomes.** All scales were re-coded so that higher scores had the same valence as the exposure (flipped: {{flipped_list}}).\n2. **Honest causal forest.** A {{sample_ratio_policy}} split trained the forest and produced out-of-sample CATEs $\\hat\\tau(x)$ on the validation fold [@grf2024].\n3. **Global heterogeneity test.** On the validation fold we computed **RATE-AUTOC** and **RATE-Qini**; FDR was controlled with {{cate_adjustment}} at q = {{cate_alpha}} [@benjamini1995controlling] (see S{{appendix_rate}}).\n4. **Budget lens.** **Qini curves** compared “treat top–ranked” to “treat all”, revealing expected uplift at budget caps (Appendix {{appendix_qini_curve}}).\n5. **Transparent policy.** When heterogeneity looked actionable, we fitted depth-2 **policy trees** on the validation fold, turning the black-box forest into concise *if–then* rules (details in Appendix {{appendix_explain_grf}}).\n\nThis pipeline converts complex CATE estimates into interpretable, out-of-sample decision policies while controlling both over-fitting and multiple testing.",
      "simple_general_approach_cate_short": "\n### Learning Moderators and Deriving Practical Treatment Rules\n\nAfter estimating the average treatment effect, we asked *for whom* the exposure helps and *how* to act on that knowledge.  The workflow:\n\n1. **Orient outcomes.** All scales were re-coded so that higher scores had the same valence as the exposure (flipped: {{flipped_list}}).\n2. **Honest causal forest.** A {{sample_ratio_policy}} split trained the forest and produced out-of-sample CATEs $\\hat\\tau(x)$ on the validation fold [@grf2024].\n3. **Global heterogeneity test.** On the validation fold we computed **RATE-AUTOC** and **RATE-Qini**; FDR was controlled with {{cate_adjustment}} at q = {{cate_alpha}} [@benjamini1995controlling] (see S{{appendix_rate}}).\n4. **Budget lens.** **Qini curves** compared “treat top–ranked” to “treat all”, revealing expected uplift at budget caps (S{{appendix_qini_curve}}).\n5. **Transparent policy.** When heterogeneity looked actionable, we fitted depth-2 **policy trees** on the validation fold, turning the black-box forest into concise *if–then* rules (details in S{{appendix_explain_grf}}).\n\nThis pipeline converts complex CATE estimates into interpretable, out-of-sample decision policies while controlling both over-fitting and multiple testing.",
      "simple_general_approach_cate_short_no_flip": "\n### Moderators and Treatment Policies\n\nWe used a method called 'causal forests' to check if a treatment helped some people more than others. We trained the model on half the data and tested it on the other half. This helped us understand whether the differences we found were real rather than accidental. We then compared outcomes when we targeted treatment to those predicted to benefit the most (using Qini curves) against simply giving the treatment to everyone. Finally, we used policy trees to boil down these results into simple, if-then rules for deciding who's likely to benefit most from the treatment (refer to[S{{appendix_explain_grf}}](#appendix-explain-grf))."
    },
    "causal_assumptions": {
      "identification": "This study relies on the following identification assumptions for estimating the causal effect of {{exposure_var}}:\n\n1. **Consistency**: the observed outcome under the observed {{exposure_var}} is equal to the potential outcome under that exposure level.\n\n2. **Positivity**: there is a non-zero probability of receiving each level of {{exposure_var}} for every combination of values of {{exposure_var}} and confounders in the population.\n\n3. **No unmeasured confounding**: all variables that affect both {{exposure_var}} and the outcome have been measured and accounted for in the analysis.",
      "confounding_control": "To manage confounding in our analysis, we implement [@vanderweele2019]'s *modified disjunctive cause criterion* by following these steps:\n\n1. **Identified all common causes** of both the treatment and outcomes.\n2. **Excluded instrumental variables** that affect the exposure but not the outcome.\n3. **Included proxies for unmeasured confounders** affecting both exposure and outcome.\n4. **Controlled for baseline exposure** and **baseline outcome**."
    },
    "causal_identification_criteria": "\n### Causal Identification Assumptions\n\nThis study relies on the following identification assumptions for estimating the causal effect of {{name_exposure_variable}}:\n\n1. **Consistency**: the observed outcome under the observed {{name_exposure_variable}} is equal to the potential outcome under that exposure level. As part of consistency, we assume no interference: the potential outcomes for one individual are not affected by the {{name_exposure_variable}} status of other individuals.\n\n2. **No unmeasured confounding**: all variables that affect both {{name_exposure_variable}} and the outcome have been measured and accounted for in the analysis.\n\n3. **Positivity**: there is a non-zero probability of receiving each level of {{name_exposure_variable}} for every combination of values of {{name_exposure_variable}} and confounders in the population. Positivity is the only fundamental casual assumption that can be evaluated with data (refer to [S{{appendix_positivity}}](#appendix-positivity)).",
    "causal_intervention": {
      "basic": "#### Interventions\nThis study considers the following causal interventions on the exposure variable '{{exposure_var}}':\n\n{{interventions_list}}\n\n#### Contrasts\n\n{{contrasts_text}}\n\nThis approach to defining interventions and contrasts allows us to systematically evaluate the causal effects of interest in our study.",
      "grf": "\n### Causal Inference\n\nWhen researchers analyse data, they often seek to understand causal relationships: what would happen if we could intervene on certain variables? To investigate such questions with observational data, we must clearly define our causal question and design our analysis to emulate a hypothetical randomised controlled trial—often called a **target trial** [@hernan2016]. A target trial asks, setting aside practicalities and ethics, *what experiment are we attempting to emulate with our data?* Without explicitly stating this hypothetical experiment, it can be unclear which causal effect we are actually estimating.\n\nHere, we ask:\n\n> 'What is the effect on an outcome if we set a binary exposure variable to a specific level for everyone, compared to setting it to an alternative level, considering individual characteristics?'\n\nTo answer this, we compare two hypothetical exposures:\n\n1.  **{{name_exposure_threshold}}**: We hypothetically assign everyone to have the exposure set to `{{value_exposure}}`.\n2.  **{{name_control_threshold}}**: We hypothetically assign everyone to have the exposure set to `{{value_control}}`.\n\nOur goal is to estimate how the effect of the {{name_exposure_threshold}} exposure compared to the {{name_control_threshold}} exposure varies across individuals based on their baseline characteristics. We aim to compute the **Conditional Average Treatment Effect (CATE)**, defined as:\n\n$$ \\tau(x) = E[Y({{value_exposure}}) - Y({{value_control}})|X = x] $$\n\nHere, $Y({{value_exposure}})$ is the potential outcome if an individual received the {{name_exposure_threshold}} exposure, $Y({{value_control}})$ is the potential outcome if they received the {{name_control_threshold}} exposure, and $X$ represents the full set of baseline covariates measured before the exposure. The CATE, $\\tau(x)$, estimates the average difference in outcomes between the two exposures for individuals with specific characteristics $x$.\n\n(Refer to [S{{appendix_assumptions_grf}}](#appendix-assumptions_grf) and [{{appendix_explain_grf}}](#appendix-explain-grf), w further details). The target population is {{name_target_population}}.",
      "grf_simple_text": "\n### Average treatment effect\n\nTo learn how the outcome would shift if everyone received a different exposure, we emulate a **target trial** [@hernan2016c]. Making the hypothetical experiment explicit fixes the estimand, the data requirements, and the assumptions.\n\nOur guiding question is:\n\n> *How would the outcomes change if, for every individual, we set the exposure to **{{value_exposure}}** rather than **{{value_control}}**, conditional on their baseline characteristics?*\n\nWe compare two interventions:\n\n1. **{{name_exposure_threshold}}** — every participant is set to {{value_exposure}}.\n2. **{{name_control_threshold}}** — every participant is set to {{value_control}}.\n\nThe difference in population means defines the **average treatment effect (ATE)**. Figure @fig-exposure plots the exposure distribution and its dichotomisation; the centre dashed line marks the mean, flanked by one standard deviation.\n\n```{r}\n#| label: fig-exposure\n#| fig-cap: \"Histogram of exposure with binary groupin\"\n#| eval: true\n#| echo: false\n#| fig-height: 12   # tweak if needed\n#| fig-width: 12    # tweak if needed\n\ngraph_cut\n\n```\n\nBecause we test several outcomes, we adjust the ATE confidence intervals for multiplicity with {{ate_adjustment}} at $\\alpha = {{ate_alpha}}$.\n\nThe longitudinal design and rich baseline covariates allow us -- under the standard identification assumptions of consistency, positivity, and no unmeasured confounding -- to attribute the differences between the two exposure means as a causal effect. Conditioning on demographics, personality traits, and other pretreatment factors renders exposure assignment ignorable [@rosenbaum1983central].",
      "lmtp_multi_wave": "\n### Causal Inference\n\nWhen psychologists analyse time-series data, they often use growth models to describe how variables evolve over time. However, many questions are causal: we want to know what would happen if we could intervene on certain variables (such as {{name_exposure_variable}}). To investigate these questions with observational time-series data, we must clearly define our causal question and design our analysis to emulate a hypothetical randomised controlled trial—often called a **target trial** [@hernan2016]. A target trial asks, setting aside practicalities and ethics, *what experiment are we attempting to emulate with our data?* Without explicitly stating this hypothetical experiment, it can be unclear which causal effect we are actually estimating.\n\nHere, we ask:\n\n  > 'What if, at each wave, we intervened to set {{name_exposure_variable}} to a certain level, and then measured everyone's outcomes at the final wave?'\n\nTo answer this, we compare two hypothetical interventions. Each intervention shifts {{name_exposure_variable}} across {{number_exposure_waves}} waves, with outcomes measured after the year following the final exposure wave.  A rich set of indicators covariates in the baseline wave -- the wave before the first exposure wave -- as well measurements of time-varying confounders at each exposure wave obtained there after are necessary to control for common causes of the exposures and outcomes measured at the end of study (refer to @tbl-plan).\n\nFollowing a modified treatment policies approach, we define **shift functions** describing each intervention:\n\n1. **{{name_exposure_regime}}**\n\n{{value_exposure_regime}}\n\n2. **{{name_control_regime}}**\n\n{{value_control_regime}}\n\n::: {#tbl-plan}\n```{=latex}\n\\vizfive\n```\nWe contrast outcomes from two treatment regimes: (1) {{name_exposure_regime}} (2) {{name_control_regime}}. $a^{+}$ denotes {{value_exposure_regime}}; $a^{-}$ denotes {{value_control_regime}}. Our statistical models control for baseline-wave confounders, and subsequent time-varying confounders for all exposure waves. We include baseline measurments of {{name_exposure_variable}} and baseline measurements of all outcomes as confounders. We assume that conditional on these confounders, treatment assignment is 'as good as random.' Outcomes, here denoted $Y_\\tau$, are measured in the wave following the final treatment.\n:::\n\nWe then organise our data to resemble a randomised sequential experiment that assigns each person to one of two longitudinal treatment strategies *{{name_exposure_regime}}* and *{{name_control_regime}}*. We define a 'confounder' as a variable that, once included in the model, along with other included variables, removes any non-causal association between the treatment and outcome. Here, as mentioned, we adjust for a rich set of demographic and personality variables, as well as baseline {{name_exposure_variable}} and baseline measures of all outcomes. We also adjust for time-varying confounders at each wave {{time_varying_confounders}}. We assume these time-varying confounders can influence {{name_exposure_variable}} and outcomes, potentially biasing our estimates. We ensure there is no reverse causation by measuring the outcomes at the end of the study, one year after the final treatment wave.\n\n::: {#tbl-feedback}\n```{=latex}\n\\feedbackB\n```\nCommon cause of Treatment 1 and downstream confounder of Treatment 2 is a collider.\n:::\n\n### Causal Contrasts\n\nWe compute the average expected outcome under and {{name_exposure_regime}} and {{name_control_regime}}, and then contrast these expected averages on the difference scale (i.e., subtracting the expected outcome under {{name_exposure_regime}} from that under {{name_control_regime}}. We obtain confidence intervals using the cross-fitted influence-function approach in the `lmtp` package [@williams2021]. This approach employs sequentially doubly robust (SDR) estimator, as developed by @diaz2021_non_parametric_lmtp, which remains valid if either the outcome model or the propensity model is correctly specified, thereby requiring weaker assumptions than standard approaches. By setting up our data as if it came from a hypothetical experiment, we gain clarity about which causal effects we are estimating and as well as confidence about our causal effect estimates (refer to @hernan2024WHATIF, @bulbulia2022; @bulbulia2023).\n\nOur estimation relies on standard causal assumptions:\n\n1.  **No unmeasured confounding**: all relevant common causes of the exposure and outcome are included in $X$.\n2.  **Consistency**: an individual's observed outcome corresponds to their potential outcome under the exposure they actually received.\n3.  **Positivity**: within strata defined by $X$, there is a non-zero probability of receiving either exposure level (`{{value_exposure}}` or `{{value_control}}`).\n\n(Refer to [S{{appendix_assumptions}}](#appendix-assumptions) for further details). The target population is {{name_target_population}}.",
      "lmtp_multi_wave_long": "\n### Causal Inference\n\nWhen psychologists analyse time-series data, they often use growth models to describe how variables evolve over time. However, many questions are causal: we want to know what would happen if we could intervene on certain variables (such as {{name_exposure_variable}}). To investigate these questions with observational time-series data, we must clearly define our causal question and design our analysis to emulate a hypothetical randomised controlled trial—often called a **target trial** [@hernan2016]. A target trial asks, setting aside practicalities and ethics, *what experiment are we attempting to emulate with our data?* Without explicitly stating this hypothetical experiment, it can be unclear which causal effect we are actually estimating.\n\nHere, we ask:\n\n  > 'What if, at each wave, we intervened to set {{name_exposure_variable}} to a certain level, and then measured everyone's outcomes at the final wave?'\n\nTo answer this, we compare two hypothetical interventions. Each intervention shifts {{name_exposure_variable}} across {{number_exposure_waves}} waves, with outcomes measured after the year following the final exposure wave.  A rich set of indicators covariates in the baseline wave -- the wave before the first exposure wave -- as well measurements of time-varying confounders at each exposure wave obtained there after are necessary to control for common causes of the exposures and outcomes measured at the end of study (refer to @tbl-plan).\n\nFollowing a modified treatment policies approach, we define **shift functions** describing each intervention:\n\n1. **{{name_exposure_regime}}**\n\n{{value_exposure_regime}}\n\n2. **{{name_control_regime}}**\n\n{{value_control_regime}}\n\n::: {#tbl-plan}\n```{=latex}\n\\vizfive\n```\nWe contrast outcomes from two treatment regimes: (1) {{name_exposure_regime}} (2) {{name_control_regime}}. $a^{+}$ denotes {{value_exposure_regime}}; $a^{-}$ denotes {{value_control_regime}}. Our statistical models control for baseline-wave confounders, and subsequent time-varying confounders for all exposure waves. We include baseline measurments of {{name_exposure_variable}} and baseline measurements of all outcomes as confounders. We assume that conditional on these confounders, treatment assignment is 'as good as random.' Outcomes, here denoted $Y_\\tau$, are measured in the wave following the final treatment.\n:::\n\nWe then organise our data to resemble a randomised sequential experiment that assigns each person to one of two longitudinal treatment strategies *{{name_exposure_regime}}* and *{{name_control_regime}}*. We define a 'confounder' as a variable that, once included in the model, along with other included variables, removes any non-causal association between the treatment and outcome. Here, as mentioned, we adjust for a rich set of demographic and personality variables, as well as baseline {{name_exposure_variable}} and baseline measures of all outcomes. We also adjust for time-varying confounders at each wave {{time_varying_confounders}}. We assume these time-varying confounders can influence {{name_exposure_variable}} and outcomes, potentially biasing our estimates. We ensure there is no reverse causation by measuring the outcomes at the end of the study, one year after the final treatment wave.\n\n::: {#tbl-feedback}\n```{=latex}\n\\feedbackB\n```\nCommon cause of Treatment 1 and downstream confounder of Treatment 2 is a collider.\n:::\n\n### Causal Contrasts\n\nWe compute the average expected outcome under and {{name_exposure_regime}} and {{name_control_regime}}, and then contrast these expected averages on the difference scale (i.e., subtracting the expected outcome under {{name_exposure_regime}} from that under {{name_control_regime}}. We obtain confidence intervals using the cross-fitted influence-function approach in the `lmtp` package [@williams2021]. This approach employs sequentially doubly robust (SDR) estimator, as developed by @diaz2021_non_parametric_lmtp, which remains valid if either the outcome model or the propensity model is correctly specified, thereby requiring weaker assumptions than standard approaches. By setting up our data as if it came from a hypothetical experiment, we gain clarity about which causal effects we are estimating and as well as confidence about our causal effect estimates (refer to @hernan2024WHATIF, @bulbulia2022; @bulbulia2023).\n\nOur estimation relies on standard causal assumptions:\n\n1.  **No unmeasured confounding**: all relevant common causes of the exposure and outcome are included in $X$.\n2.  **Consistency**: an individual's observed outcome corresponds to their potential outcome under the exposure they actually received.\n3.  **Positivity**: within strata defined by $X$, there is a non-zero probability of receiving either exposure level (`{{value_exposure}}` or `{{value_control}}`).\n\n(Refer to [S{{appendix_assumptions}}](#appendix-assumptions) for further details). The target population is {{name_target_population}}."
    },
    "confounding_control": {
      "vanderweele": "\n### Confounding Control\n\nTo manage confounding in our analysis, we implement @vanderweele2019's *modified disjunctive cause criterion* by following these steps:\n\n1. **Identified all common causes** of both the treatment and outcomes.\n2. **Excluded instrumental variables** that affect the exposure but not the outcome. Instrumental variables do not contribute to controlling confounding and can reduce the efficiency of the estimates.\n3. **Included proxies for unmeasured confounders** affecting both exposure and outcome. According to the principles of d-separation @pearl2009a, using proxies allows us to control for their associated unmeasured confounders indirectly.\n4. **Controlled for baseline exposure** and **baseline outcome**. Both are used as proxies for unmeasured common causes, enhancing the robustness of our causal estimates, refer to @vanderweele2020.\n"
    },
    "eligibility": {
      "special": "\n### Eligibility Criteria\n\nTo be included in the analysis of this study, participants needed to participate in the {{baseline_wave}} of the study and respond to the baseline measure of {{name_exposure_variable}}. Additionally, participants needed to meet the following eligibility criteria: {{eligibility_criteria}}.\n\nWe allowed participants to have been lost to follow-up at the end of the study if they met eligibility criteria at {{baseline_wave}}. We adjusted for attrition and non-response using censoring weights, described below.\n\nA total of {{n_participants}} individuals met these criteria and were included in the study.\n",
      "standard": "\n### Eligibility Criteria\n\nTo be included in the analysis of this study, participants needed to participate in the {{baseline_wave}} of the study and respond to the baseline measure of {{name_exposure_variable}}.\n\nParticipants may have been lost to follow-up at the end of the study if they met eligibility criteria at {{baseline_wave}}. We adjusted for attrition and non-response using censoring weights, described below.\n\nA total of {{n_participants}} individuals met these criteria and were included in the study.\n"
    },
    "exposure_indicator": "\n### Exposure Indicator\n\n\nThe New Zealand Attitudes and Values Study assesses {{name_exposure_variable}} using the following question:\n\n\n{{measures_exposure}}(Refer to [S{{appendix_measures}}](#appendix-measures)).",
    "grf": {
      "why_cate_hard": "\n## Why Estimating Heterogeneous Treatment Effects Is Hard\n\nModern policy and intervention science increasingly asks **“for whom does it work?”** rather than the classical average‐treatment‐effect question. Yet uncovering effect heterogeneity is intrinsically difficult, for both statistical and conceptual reasons.  Below we outline six obstacles that arise when analysts rely on conventional moderation analyses. This discussion motivates the move to non‑parametric machine‐learning tools such as causal forests.\n\n### 1. Rigid Functional‑Form Assumptions\n\nTraditional moderation tests add interaction terms e.g., *Treatment $\\times$ Age*, inside a linear or logistic regression.  This forces the conditional average treatment effect (CATE) to vary in a very specific, low‑order polynomial way.  If the true effect surface is non‑linear, discontinuous, or involves higher‑order interactions (e.g., *Treatment $\\times$ Age $\\times$  Income*), the fitted model cannot capture this surface, leading to attenuation or even suppression of real heterogeneity.\n\n### 2. Thin Data in High‑Dimensional Space\n\nEvery additional moderator partitions the sample into finer strata.  A model that is linear in each covariate 'borrows strength' across strata, but once the true pattern bends or breaks, there may be only a handful of treated and untreated observations in any local neighbourhood.  Standard errors balloon, power collapses, and estimates become highly unstable to small perturbations.\n\n### 3. Arbitrary Categorisation of Continuous Variables\n\nTo make interaction plots digestible, researchers often dichotomise or trichotomise continuous moderators at arbitrary splits -- such as one standard deviation above or below the mean for a covariate.  Apart from discarding measurement precision and distorting scales, such decisions can both mask and manufacture interaction effects. As modelled interactions increase, uncertainty propogates.\n\n### 4. Scarcity of Support (Positivity/Overlap Violations)\n\nInteraction coefficients are identified only where treated and untreated cases coexist for each moderator value.  If, say, all highly economically deprived participants receive the control while wealthier participants receive the treatment, the model must extrapolate across a data void. Here again, the resulting estimates are driven by modelling assumptions rather than empirical support.\n\n### 5. Interpretation Overload\n\nA regression with several interaction terms yields a forest of coefficients and *p*‑values.  Analysts typically resort to inspecting conditional effects at arbitrarily chosen 'representative' covariate values, again assuming linearity and suppressing complex structure in the data. The world need not, and typically does not, unfold at the pre-determined joints of an analysts imagination. \n\n### 6. Lack of Individual‑Level Ranking\n\nClassical moderation answers explanatory questions (*Is the effect larger for group **A** than group **B**?*) but decision‑makers often need actionable scoring rules (*Who should we treat first?*).  Linear interaction models rarely produce well‑calibrated CATE estimates for every individual, limiting their utility for personalised intervention. Providing such estimates is a difficult statisitcal problem.\n\n#### Implication\n\nBecause of these obstacles, traditional moderation analyses frequently miss or misstate true underlying heterogeneity in a population, and struggle to convert statistical findings into actionable guidance.  Causal forests, and related ensemble methods, address these weaknesses by (i) allowing non‑parametric effect surfaces, (ii) adaptively pooling information across similar units, (iii) safeguarding against over‑fitting via sample splitting, and (iv) outputting an estimated CATE for every participant, complete with honest variance estimates.\n"
    },
    "grf_flow_chart": "\n#### Heterogeneity Treatment Effect Decision Flow\n\n\n```text\nThis following flowchart shows the decision logic:\n\n    START: For each model\n             |\n             v\n    STEP 1: EXCLUSION CHECK\n    Is RATE QINI < 0 (stat sig) OR RATE AUTOC < 0 (stat sig)?\n             |\n        +----+----+\n        |         |\n       YES       NO\n        |         |\n        v         v\n    EXCLUDED    STEP 2: RATE SELECTION CHECK\n    (Stop)      Is RATE QINI > 0 (stat sig) OR RATE AUTOC > 0 (stat sig)?\n                         |\n                    +----+----+\n                    |         |\n                   YES       NO\n                    |         |\n                    v         v\n                SELECTED   UNCLEAR\n                    |         |\n                    v         v\n                STEP 3: QINI CURVE ANALYSIS\n                (Applied to all non-excluded models)\n                    |         |\n                    v         v\n                Already     Check: Is QINI curve positive\n                selected     at any spend level?\n                            |\n                       +----+----+\n                       |         |\n                      YES       NO\n                       |         |\n                       v         v\n                   SELECTED   UNCLEAR\n                             (final)\n\n```\n\nNote: Models can be SELECTED as merting consideration for CATE allocation based on either:\n- Statistically significant positive RATE tests (QINI or AUTOC)\n- Positive QINI curves at specific budget levels\n\n",
    "missing_data": {
      "missing_grf_simple": "\n### Missing Data\n\nThe GRF package accepts missing values at baseline. To obtain valid inference for missing responses we computed inverse probability of censoring weights for censoring of the exposure, given that systematic censoring following the baseline wave may lead to selection bias that limit generalistion to the baseline target population [@bulbulia2024wierd]. See [S{{appendix_explain_grf}}](#appendix-explain-grf).",
      "missing_lmtp_simple": "\n### Missing Responses and Attrition\n\nTo mitigate bias from missing data, we used the following strategies:\n\n#### Baseline missingness\n\nWe employed the `ppm` algorithm from the `mice` package in R [@vanbuuren2018] to impute missing baseline data (wave {{baseline_wave}}). This method allowed us to reconstruct incomplete datasets by estimating a plausible value for missing observation. Because we could only pass one data set to the lmtp, we employed single imputation. Approximately {{baseline_missing_data_proportion}}% of covariate values were missing at {{baseline_wave}}. We only used baseline data to impute baseline wave missingness (refer to @zhang2023shouldMultipleImputation).\n\n#### Outcome missingness\n\nTo address confounding and selection bias arising from missing responses and panel attrition at the end of study {{outcome_wave}}, we applied censoring weights obtained using nonparametric machine learning ensembles afforded by the `lmtp` package (and its dependencies) in R [@williams2021].",
      "missing_lmtp_time_varying": "\n### Missing Data\n\nTo mitigate bias from missing data, we implement the following strategies:\n\n#### Baseline missingness\n\nWe used predictive mean matching from the `mice` package [@vanbuuren2018] to impute missing baseline values (comprising `r percent_missing_baseline` of the baseline data). Following [@zhang2023shouldMultipleImputation], we performed single imputation using only baseline data. For each column with missing values, we created a binary indicator of missingness so that the machine learning algorithms we employed could condition on missingness information during estimation (see `lmtp` documentation [@williams2021]).\n\n#### Missingness in Time-Varying Variables\n\nWhen a time-varying value was missing in any wave but a future value was observed, we carried forward the previous response and included a missingness indicator. Again, this approach let the patterns of missingness inform nonparametric machine learning. If no future value was observed, we considered the participant censored and used inverse probability of treatment weights to address attrition.\n\n#### Outcome missingness\n\nTo address confounding and selection bias arising from missing responses and panel attrition at the end of study {{outcome_wave}}, we applied censoring weights obtained using nonparametric machine learning ensembles afforded by the `lmtp` package (and its dependencies) in R [@williams2021]."
    },
    "outcomes": {
      "outcomewide_flourishing": "\n### Wellbeing Outcomes\n\nWe adopt an outcome-wide approach, modelling every outcome in a domain. This strategy reduces cherry-picking and selectivity biases, and offers a meta-analytic perspective on the concepts of interest [@vanderweele2017a; @vanderweele2020]. We categorised outcomes into five domains—health, psychological well-being, present-reflective outcomes, life-reflective outcomes, and social outcomes—based on validated scales and measures. Outcomes were based on those modelled in an earlier outcome-wide flourispaper @pedro_2024effects. @tbl-outcomes summarises each domain and its associated measures. For instance, health outcomes included BMI and hours of sleep, whereas psychological well-being included anxiety and depression. Outcomes were converted to z-scores (standardised), and the causal effect estimates may be therefore be interpreted as effect sizes.\n\n|       Domain        |                 Dimension                |\n  |---------------------|------------------------------------------------|\n  |       Health        | BMI, Hours of Sleep, Hours of Exercise, Short Form Health |\n  | Psychological Well-Being | Anxiety, Depression, Fatigue, Rumination      |\n  | Present-Reflective  | Body Satisfaction, Forgiveness, Perfectionism, Self-Control, Self-Esteem, Sexual Satisfaction |\n  | Life-Reflective     | Gratitude, Life Satisfaction, Meaning (Sense & Purpose), Personal Wellbeing Index |\n  |       Social        | Social Belonging, Social Support, Neighbourhood Community |\n\n: Outcome domains and example dimensions. Data summaries for all measures used in this study are provided in [S{{appendix_outcomes}}](#appendix-outcomes). {#tbl-outcomes}",
      "outcomewide_personality": "### Personality Outcomes\n\nWe adopt an outcome-wide approach, modelling every outcome in a domain. This strategy reduces cherry-picking and selectivity biases, and offers a meta-analytic perspective on the concepts of interest [@vanderweele2017a; @vanderweele2020]. We categorised personality outcomes into six domains based on the Mini-IPIP6 [@sibley2011]. @tbl-outcomes summarises each domain and its associated measures. For instance, extraversion includes being the life of the party and talking to different people at parties, whereas agreeableness includes sympathising with others' feelings and feeling others' emotions. Outcomes were converted to z-scores (standardised), and the causal effect estimates may therefore be interpreted as effect sizes.\n\n| Domain | Items |\n|--------|-------|\n| Extraversion | Am the life of the party.  |\n|  | Don't talk a lot. (R) |\n|  | Keep in the background. (R) |\n|  | Talk to a lot of different people at parties. |\n| Agreeableness | Sympathize with others' feelings. |\n|  | Am not interested in other people's problems. (R) |\n|  | Feel others' emotions. |\n|  | Am not really interested in others. (R) |\n| Conscientiousness | Get chores done right away. |\n|  | Like order. |\n|  | Make a mess of things. (R) |\n|  | Often forget to put things back in their proper place. (R) |\n| Neuroticism/Emotional Stability | Have frequent mood swings. |\n|  | Am relaxed most of the time. (R) |\n|  | Get upset easily. |\n|  | Seldom feel blue. (R) |\n| Openness to Experience | Have a vivid imagination. |\n|  | Have difficulty understanding abstract ideas. (R) |\n|  | Do not have a good imagination. (R) |\n|  | Am not interested in abstract ideas. (R) |\n| Honesty-Humility | Feel entitled to more of everything. (R) |\n|  | Deserve more things in life. (R) |\n|  | Would like to be seen driving around in a very expensive car. (R) |\n|  | Would get a lot of pleasure from owning expensive luxury goods. (R) |\n\n: Personality domains and associated items from the Mini-IPIP6. (R) indicates reverse-scored items. Data summaries for all measures used in this study are provided in [S{{appendix_outcomes}}](#appendix-outcomes). {#tbl-outcomes}"
    },
    "overlap": "\n### Overlap\n\n```{r, results = 'asis'}\noverlap$text_summary\n```\n\n@fig-overlap graphs the propensity score distribution, where values closer to zero indicate a lower probability of treatment, and values closer to one indicate a higher probability of treatment. The dashed lines indicate regions of common support.\n\n```{r}\n#| label: fig-overlap\n#| fig-cap: \"Histogram of exposure with binary groupin\"\n#| eval: true\n#| echo: false\n#| fig-height: 12   # tweak if needed\n#| fig-width: 12    # tweak if needed\n\noverlap$propensity_plots$exposure\n```\n\n\n",
    "sample": {
      "nzavs": "\n### Sample\n\nData were collected as part of the New Zealand Attitudes and Values Study (NZAVS), an annual longitudinal national probability panel assessing New Zealand residents’ social attitudes, personality, ideology, and health outcomes. The panel began in 2009 and has since expanded to include over fifty researchers, with responses from {{n_total}} participants to date. The study operates independently of political or corporate funding and is based at a university. It employs prize draws to incentivise participation. The NZAVS tends to slightly under-sample males and individuals of Asian descent and to over-sample females and Māori (the Indigenous people of New Zealand). To enhance the representativeness of our sample population estimates for the target population of New Zealand, we apply census-based survey weights that adjust for age, gender, and ethnicity (New Zealand European, Asian, Māori, Pacific) [@sibley2021]. For more information about the NZAVS, visit: [OSF.IO/75SNB](https://doi.org/10.17605/OSF.IO/75SNB).\n",
      "nzavs_timline": "\n### Sample\n\nData were collected as part of the New Zealand Attitudes and Values Study (NZAVS), an annual longitudinal national probability panel assessing New Zealand residents’ social attitudes, personality, ideology, and health outcomes. The panel began in 2009 and has since expanded to include over fifty researchers, with responses from {{n_total}} participants to date. The study operates independently of political or corporate funding and is based at a university. It employs prize draws to incentivise participation. The NZAVS tends to slightly under-sample males and individuals of Asian descent and to over-sample females and Māori (the Indigenous people of New Zealand). To enhance the representativeness of our sample population estimates for the target population of New Zealand, we apply census-based survey weights that adjust for age, gender, and ethnicity (New Zealand European, Asian, Māori, Pacific) [@sibley2021]. For more information about the NZAVS, visit: [OSF.IO/75SNB](https://doi.org/10.17605/OSF.IO/75SNB). Refer to [ S{{appendix_timeline}}](#appendix-timeline) for a histogram of daily responses for this cohort.\n"
    },
    "sensitivity_analysis": {
      "short_evalue": "\n### Sensitivity Analysis\nWe perform sensitivity analyses using the E-value metric [@vanderweele2017; @linden2020EVALUE]. The E-value represents the minimum association strength (on the risk-ratio scale) that an unmeasured confounder would need with both exposure and outcome—after adjusting for measured covariates—to explain away the observed association [@vanderweele2020; @linden2020EVALUE]. Confidence intervals for each E-value were derived from the multiplicity-adjusted confidence intervals of the corresponding coefficient estimates ({{ate_adjustment}}, $\\alpha$ = {{ate_alpha}}), so the sensitivity analysis obeys the same error-control framework as the main results."
    },
    "statistical": {
      "default": "We used appropriate statistical methods for causal inference.",
      "longitudinal": {
        "default": "We estimate causal effects using the Longitudinal Modified Treatment Policy (LMTP) estimator within a Targeted Minimum Loss-based Estimation (TMLE) framework [@van2014targeted; @van2012targeted].",
        "lmtp": "We perform statistical estimation using a Targeted Minimum Loss-based Estimation (TMLE) approach, specifically the Longitudinal Modified Treatment Policy (LMTP) estimator [@van2014targeted; @van2012targeted]. TMLE is a flexible framework for causal inference that provides valid uncertainty estimates. LMTP extends TMLE to handle time-varying treatments and confounders.",
        "sdr": "We employed a semi-parametric estimator known as Sequentially Doubly Robust (SDR) estimation [@díaz2021]."
      },
      "heterogeneity": {
        "default": "Treatment effect heterogeneity was assessed using appropriate methods.",
        "grf": {
          "default": "We estimate heterogeneous treatment effects with Generalized Random Forests (GRF) [@grf2024].",
          "standard": "We used the standard GRF implementation for heterogeneity detection.",
          "custom": "We implemented a custom GRF approach with modified splitting criteria."
        },
        "causal_forest": "Causal forests were used to estimate conditional average treatment effects."
      }
    },
    "statistical_models": {
      "grf_short_explanation": "\n### Statistical Estimation\n\nWe estimate heterogeneous treatment effects with Generalized Random Forests (GRF) [@grf2024]. GRF extends random forests for causal inference by focusing on conditional average treatment effects (CATE). It handles complex interactions and non-linearities without explicit model specification, and it provides 'honest' estimates by splitting data between model-fitting and inference. GRF is doubly robust because it remains consistent if either the outcome model or the propensity model is correct. We evaluate policies with the `policytree` package [@policytree_package_2024; @athey_2021_policy_tree_econometrica] and visualise results with `margot` [@margot2024]. (Refer to [S{{appendix_explain_grf}}](#appendix-explain-grf) for a detailed explanation of our approach.)",
      "lmtp_long_explanation": "\nWe estimated the effect of {{name_exposure_variable}} on {{name_outcome_variable}} using observational data and a modified treatment policy (MTP) framework to address time-varying confounding and censoring. Our target answers a pragmatic ‘what if?’: How would the average {{name_outcome_variable}} change if we implemented a specified modification to {{name_exposure_variable}} in the population, compared with leaving exposure as observed?\n\nLet $\\dd(A)$ define the policy (e.g., {{shift_intervention}}). We report the contrast between the expected outcome under $\\dd$ and under the natural course (identity policy), with all quantities defined under no loss to follow-up:\n\n$$\n\\Delta_{\\dd}\n;=;\nE\bigl( Y^{\\dd, R=1} \bigr)\n; - ;\nE\bigl( Y^{\\mathbf{d_0}, R=1} \bigr),\n$$\n\nwhere $\\mathbf{d_0}$ leaves exposure unchanged at each wave (the identity policy), and $R=1$ denotes remaining under observation at each wave (including baseline pre-exposure censoring). Note that $E\\bigl[ Y^{\\mathbf{d_0}, R=1} \\bigr] = E\\bigl[ Y^{R=1} \\bigr]$.\n\nWe include the natural course for two reasons: (i) it yields a directly interpretable baseline reflecting the observed exposure process, and (ii) compared with static counterfactual rules (e.g., ‘always/never’), it avoids additional exposure-positivity requirements for the reference arm, which can be restrictive in practice.\n\nIdentification assumptions. We interpret $\\Delta_{\\dd}$ causally under:\n1.  Sequential exchangeability (no unmeasured confounding): Given observed history, there is no unmeasured confounding for the exposure–outcome and censoring–outcome relations.\n2.  Positivity: For each time and covariate history, the policy $\\dd$ maps into exposure values with positive probability in the observed data, and the probability of remaining uncensored satisfies $\\Pr(R=1 \\mid \\text{history}) > 0$.\n3.  Consistency: If an individual’s exposure path equals the policy-imposed path and they remain uncensored, their observed outcome equals the corresponding potential outcome.\n\nEstimation. We used a cross-fitted ($k = {{n_folds}}$) doubly robust TMLE (as implemented in lmtp) to estimate both $E(Y^{\\dd, R=1})$ and $E(Y^{\\mathbf{d_0}, R=1})$ [@diaz2023lmtp; @williams2023lmtp]. The procedure estimates:\n\n* the outcome mechanism,\n* the exposure mechanism (relative to the policy $\\dd$), and\n* the censoring mechanism $\\Pr(R=1 \\mid \\text{history})$ (including baseline pre-exposure censoring).\n\nWe used the Super Learner ensemble [@polley2023; @vanderlaan2007super] with SL.glmnet, SL.ranger, and SL.xgboost [@friedman2010regularization; @wright2017ranger; @chen2016xgboost] and employed cross-fitting to preserve valid inference with flexible learners.\n\nAll results, tables, and figures were generated with the margot R package [@margot2024]. For mathematical and computational specifics, see S{{appendix_technical_lmtp}}.\n",
      "lmtp_short_explanation": "\nWe estimated the causal effect of {{name_exposure_variable}} on {{name_outcome_variable}} using a modified treatment policy (MTP) estimand [@haneuse2013estimation; @diaz2012population; @young2014identification; @diaz2023lmtp].\n\nThis estimand compares the expected outcome under a hypothetical policy that modifies exposure to the expected outcome under the natural course (identity policy), all defined under no loss to follow-up (R = 1):\n\n1.  Natural course (identity policy): $E\\bigl[Y^{\\mathbf{d_0}, R=1}\\bigr]$, which equals $E\\bigl[Y^{R=1}\\bigr]$.\n2.  Hypothetical policy: $E\\bigl[Y^{\\dd, R=1}\\bigr]$, where $\\dd(A)$ specifies how {{name_exposure_variable}} ($A$) is modified (e.g., {{shift_intervention}}).\n\nOur primary effect is the policy contrast:\n\n\\Delta_{\\dd}\n;=;\nE\bigl(Y^{\\dd, R=1}\bigr)\n; - ;\nE\bigl(Y^{\\mathbf{d_0}, R=1}\bigr),\n$$\n\nwith $\\mathbf{d_0}$ the identity (natural-course) policy. Here, $R=1$ denotes remaining under observation at each wave (i.e., no censoring, including baseline).\n\nWe interpret $\\Delta_{\\dd}$ causally under three identifying conditions:\n\n1.  Conditional exchangeability (sequential): Given measured covariates, there is no unmeasured confounding for the exposure–outcome and censoring–outcome relations.\n2.  Positivity: Within covariate strata, individuals have non-zero probability of the policy-relevant exposure support and of remaining uncensored ($R=1$) at each time. The natural course itself imposes no additional exposure-positivity requirements beyond the observed process.\n3.  Consistency: Each individual’s observed outcome equals the potential outcome under their realised exposure and censoring history.\n\nWe estimated $\\Delta_{\\dd}$ with a cross-fitted ($k = {{n_folds}}$) doubly robust TMLE for MTPs implemented in lmtp [@diaz2023lmtp; @williams2023lmtp]. Nuisance components included the outcome, exposure, and censoring mechanisms. We used Super Learner [@polley2023; @vanderlaan2007super] with SL.glmnet, SL.ranger, and SL.xgboost [@friedman2010regularization; @wright2017ranger; @chen2016xgboost]. Results, tables, and figures were produced with the margot R package [@margot2024]. See S{{appendix_technical_lmtp}} for technical details.\n",
      "lmtp_short_explanation_2": "\nWe used a modified treatment policy (MTP) estimand [@haneuse2013estimation; @diaz2012population; @young2014identification; @diaz2023lmtp] to quantify the effect of {{name_exposure_variable}} on {{name_outcome_variable}}.\n\nAll estimands are defined under no loss to follow-up ($R=1$; i.e., remaining under observation at each wave, including baseline). We contrast:\n1.  Natural course (identity policy): the expected outcome under the observed exposure process, $E\\bigl[Y^{\\mathbf{d_0}, R=1}\\bigr] = E\\bigl[Y^{R=1}\\bigr]$.\n2.  Hypothetical policy (intervention): the expected outcome under a modified exposure distribution, $E\\bigl[Y^{\\dd, R=1}\\bigr]$, where $\\dd(A)$ specifies how {{name_exposure_variable}} is changed ({{shift_intervention}}).\n\nThe MTP contrast is\n$$\nE\bigl(Y^{\\dd, R=1}\bigr) ;-; E\bigl(Y^{\\mathbf{d_0}, R=1}\bigr).\n$$\n\nUnder the following conditions we interpret this difference causally:\n1.  Conditional exchangeability (sequential): Given the measured covariates (including time-varying history), exposure assignment and censoring are independent of the potential outcomes.\n2.  Positivity: Within covariate strata, there is non-zero probability of exposure levels required by $\\dd$ and of remaining uncensored ($R=1$) at each time; the natural course imposes no extra exposure-positivity burden.\n3.  Consistency: The observed outcome equals the potential outcome under the realised exposure and censoring.\n\nWe estimated these functionals using a cross-fitted ($k = {{n_folds}}$) TMLE for MTPs [@diaz2023lmtp; @williams2023lmtp], with Super Learner [@polley2023; @vanderlaan2007super] combining regularised regression (SL.glmnet), random forests (SL.ranger), and gradient boosting (SL.xgboost) [@friedman2010regularization; @wright2017ranger; @chen2016xgboost]. We generated all outputs with the margot R package [@margot2024]. See S{{appendix_technical_lmtp}} for full details.\n",
      "sdr_long_explanation": "\n### Sequentially Doubly Robust (SDR) Estimator\n\nWe employ a Sequentially Doubly Robust (SDR) estimator to assess the causal effects of time-varying treatment policies [@díaz2021]. SDR belongs to the broader class of doubly robust targeted learning estimators [@vanderlaan2011; @vanderlaan2018].\n\n**Process:**\n1. **Initial Modeling:** SDR uses machine learning to flexibly model relationships among treatments, covariates, and outcomes at each time point, capturing complex dependencies without strict parametric assumptions.\n2. **Sequential Updating:** SDR works backwards in time, combining outcome regression and propensity models to construct unbiased estimating equations for each time interval.\n\n**Advantages:**\n- **Sequential double robustness:** The estimator remains consistent at each time point if either the outcome or treatment mechanism model is correct (but not necessarily both).\n- **Time-varying confounders:** SDR naturally incorporates time-dependent structures.\n- **Flexible estimation:** It accommodates non-linearities and interactions through machine learning.\n- **Missingness:** The method handles attrition or loss-to-follow-up with inverse-probability weighting.\n\nWe use cross-validation to reduce overfitting and improve finite-sample performance. We implement SDR through the `lmtp` package [@williams2021; @hoffman2024studying; @diaz2023lmtp], relying on `SuperLearner` with base learners such as `SL.ranger`, `SL.glmnet`, and `SL.xgboost` [@polley2023; @xgboost2023; @Ranger2017; @SuperLearner2023]. For more details, see [@hoffman2022; @hoffman2024studying; @díaz2021]. We use the `margot` package [@margot2024] for reporting and visualisation.\n",
      "sdr_short_explanation": "\n### Sequentially Doubly Robust (SDR) Estimator\n\nWe estimate causal effects of time-varying treatment policies using a Sequential Doubly Robust (SDR) estimator with the `lmtp` package [@williams2021; @díaz2021; @hoffman2024studying]. SDR involves two main steps. First, flexible machine learning models capture complex relationships among treatments, covariates, and outcomes [@díaz2021]. Second, SDR targets these initial fits to refine causal effect estimates. This design is multiply robust if treatments repeat over multiple waves [@diaz2023lmtp; @hoffman2024studying], ensuring consistency when either the outcome or treatment model is correct. We use `SuperLearner` [@SuperLearner2023] with `SL.ranger`, `SL.glmnet`, and `SL.xgboost` [@polley2023; @xgboost2023; @Ranger2017]. We use cross-validation to reduce overfitting and improve finite-sample performance. We create graphs, tables, and output with the `margot` package [@margot2024]."
    },
    "student_target_population": "\n### Target Population\n\nThe data are simulated from the New Zealand Attitudes and Values Study. For the purposes of this assessment, the target population for this study comprises New Zealand residents as represented in the {{baseline_wave}} of the New Zealand Attitudes and Values Study (NZAVS) during the years {{baseline_wave}} weighted by New Zealand Census weights for age, gender, and ethnicity (refer to @sibley2021). The NZAVS is a national probability study designed to reflect the broader New Zealand population accurately. Despite its comprehensive scope, the NZAVS has some limitations in its demographic representation. Notably, it tends to under-sample males and individuals of Asian descent while over-sampling females and Māori (the indigenous peoples of New Zealand). To address these disparities and enhance the accuracy of our findings, we apply New Zealand Census survey weights to the sample data.",
    "sudent_sample": {
      "nzavs": "\n### Sample\n\nThe data in this study are simulated for the purposes of instruction from data collected as part of the New Zealand Attitudes and Values Study (NZAVS). The NZAVS is an annual longitudinal national probability panel assessing New Zealand residents’ social attitudes, personality, ideology, and health outcomes. The panel began in 2009 and has since expanded to include over fifty researchers, with responses from {{n_total}} participants to date. The study operates independently of political or corporate funding and is based at a university. It employs prize draws to incentivise participation. The NZAVS tends to slightly under-sample males and individuals of Asian descent and to over-sample females and Māori (the Indigenous people of New Zealand). To enhance the representativeness of our sample population estimates for the target population of New Zealand, we apply census-based survey weights that adjust for age, gender, and ethnicity (New Zealand European, Asian, Māori, Pacific) [@sibley2021]. For more information about the NZAVS, visit: [OSF.IO/75SNB](https://doi.org/10.17605/OSF.IO/75SNB).\n"
    },
    "target_population": "\n### Target Population\n\nThe target population for this study comprises New Zealand residents as represented in the {{baseline_wave}} of the New Zealand Attitudes and Values Study (NZAVS) during the years {{baseline_wave}} weighted by New Zealand Census weights for age, gender, and ethnicity (refer to @sibley2021). The NZAVS is a national probability study designed to reflect the broader New Zealand population accurately. Despite its comprehensive scope, the NZAVS has some limitations in its demographic representation. Notably, it tends to under-sample males and individuals of Asian descent while over-sampling females and Māori (the indigenous peoples of New Zealand). To address these disparities and enhance the accuracy of our findings, we apply New Zealand Census survey weights to the sample data."
  },
  "results": {
    "domain": {
      "default": "Results varied by outcome domain.",
      "health": "In the health domain, we found {{health_finding}}.",
      "psychological": "In the psychological domain, we found {{psych_finding}}.",
      "present_reflective": "In the present-reflective domain, we found {{present_reflective_finding}}.",
      "life_reflective": "In the present-reflective domain, we found {{life_reflective_finding}}.",
      "social": "In the social domain, we found {{social_finding}}."
    },
    "grf": {
      "interpretation_ominibus_test_negative": "\n#### Omnibus Test\n\nThe omnibus test did not provide statistically reliable evidence for overall treatment effect heterogeneity beyond chance. However, omnibus tests can lack power for detecting subtle or localised heterogeneity. Therefore, we examined more specific indicators of potential targeting benefits and subgroup differences. Refer to [S{{appendix_cate_validation_grf}}](#appendix-cate-validation).",
      "interpretation_ominibus_test_positive": "\n#### Omnibus Test\n\nThe omnibus test (@tbl-omnibus) indicates that the model found differences in how individuals respond to {{omnibus_confirmed_heterogeneity_outcome}}.  Notably, omnibus tests can lack power for detecting subtle or localised heterogeneity. However, even with its anti-conservativism, the test confirmed heterogeneity for {{omnibus_confirmed_heterogeneity_outcome}}. Refer to [S{{appendix_cate_validation_grf}}](#appendix-cate-validation).",
      "interpretation_policy_tree": "\n#### Policy Trees\n\nWe used policy trees [@policytree_package_2024; @athey2021; @athey_2021_policy_tree_econometrica] to find straightforward ‘if-then’ rules for who benefits most from treatment, based on participant characteristics. Because we flipped some measures, a higher predicted effect always means greater improvement. Policy trees can uncover small but important subgroups whose treatment responses stand out, even when the overall differences might be modest.",
      "interpretation_qini": "\n#### Qini Curves\n\nThe Qini curve shows the cumulative **gain** as we expand a targeting rule down the CATE ranking.\n\n* **Beneficial exposure:** we add individuals from the top positive CATEs downward; the baseline is 'expose everyone.'\n* **Detrimental exposure:** we first flip outcome direction (so higher values represent **more harm**; see {{flipped_list}}), then *add* the exposure starting with individuals whose CATEs show the **greated harm**, gradually including those predicted to be more resistant to harm; the baseline is 'expose everyone.'  The curve therefore quantifies the harm by when those most suceptible to harm are exposed.\n\nIf the Qini curve stays above its baseline, a targeted policy increases the outcome more than a one-size-fits-all alternative.",
      "interpretation_rate": "\n#### Rate Test\n\nThe RATE metric shows how much extra gain (or avoided loss) we achieve by **targeting** instead of treating everyone identically.\n\n**Technical note**: In code we always set `policy = \"treat_best\"`; for harmful exposures this is interpreted as *'treat-those-most-sensitive'* (i.e., prioritise protection or withholding).\n\n* **Beneficial exposure:** we rank by positive CATEs and deliver the exposure to those predicted to **benefit most**.\n* **Detrimental exposure:** we rank by increasingly **positive** CATEs (more predicted harm) and identify those who should be protected or withheld from the exposure.\n\nEither way, a larger **absolute** RATE shows that a CATE-based targeting rule 'outperforms' a one-size-fits-all policy—by boosting outcomes for beneficial exposures or -- in the case where we are explore sensitivity to harm -- evaluating increasing harms for detrimental ones.\n\nRecall we flipped {{flipped_list}} so **'higher' always tracks the analysis goal: higher = more benefit for beneficial exposures, higher = more harm for detrimental exposures.**\n\nBecause we test several outcomes, RATE *p*-values are adjusted with {{cate_adjustment}} (q = {{cate_alpha}}) before we decide whether heterogeneity is actionable.",
      "interpretation_rate_no_flip": "\n#### Rate Test\n\nThe RATE metric shows how much extra gain in the outcome we achieve by **targeting** instead of treating everyone identically.\n\n* **Beneficial exposure:** we rank by positive CATEs and deliver the exposure to those predicted to **benefit most**.\n* **Detrimental exposure:** we rank by increasingly **positive** CATEs (more predicted harm) and identify those who should be protected or withheld from the exposure.\n\n(Note the valence of the outcomes match the valence of the exposures.)\n\nEither way, a larger **absolute** RATE shows that a CATE-based targeting rule 'outperforms' a one-size-fits-all policy—by boosting outcomes for beneficial exposures or -- in the case where we are explore sensitivity to harm -- evaluating increasing harms for detrimental ones.\n\nBecause we test several outcomes, RATE *p*-values are adjusted with {{cate_adjustment}} (q = {{cate_alpha}}) before we decide whether heterogeneity is actionable."
    },
    "long": {
      "outcomewide_flourishing_2025": "\n\n## Results\n\n### Health\n\n```{r}\n#| label: fig-health\n#| fig-cap: \"Health effects\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 16\n\nhealth_religious_vs_secular$plot\n```\n\n```{r}\n#| label: tbl-health\n#| tbl-cap: \"Health effects\"\n#| eval: true\n#| echo: false\n\nhealth_religious_vs_secular$transformed_table|>\n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n```\n\n\n```{r, results = 'asis'}\ncat(health_religious_vs_secular$interpretation)\n```\n\n{{< pagebreak >}}\n\n### Psychological Well-Being\n\n```{r}\n#| label: fig-psych\n#| fig-cap: \"Effects on Psychological Well-Being\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 16\n\npsych_religious_vs_secular$plot\n```\n\n```{r}\n#| label: tbl-psych\n#| tbl-cap: \"Effects on Psychological Well-Being\"\n#| eval: true\n#| echo: false\n\npsych_religious_vs_secular$transformed_table|>\n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n```\n\n\n```{r, results = 'asis'}\ncat(psych_religious_vs_secular$interpretation)\n```\n\n{{< pagebreak >}}\n\n### Present-Focussed Well-Being\n\n```{r}\n#| label: fig-present\n#| fig-cap: \"Effects on Person-Focussed Well-Being\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 16\n\npresent_religious_vs_secular$plot\n```\n\n```{r}\n#| label: tbl-present\n#| tbl-cap: \"Effects on Person-Focussed Well-Being\"\n#| eval: true\n#| echo: false\n\npresent_religious_vs_secular$transformed_table|>\n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n```\n\n\n```{r, results = 'asis'}\ncat(present_religious_vs_secular$interpretation)\n```\n\n\n{{< pagebreak >}}\n\n### Life-Focussed Well-Being\n\n```{r}\n#| label: fig-life\n#| fig-cap: \"Effects on Life-Focussed Well-Being\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 16\n\nlife_religious_vs_secular$plot\n```\n\n```{r}\n#| label: tbl-life\n#| tbl-cap: \"Effects on Life-Focussed Well-Being\"\n#| eval: true\n#| echo: false\n\nlife_religious_vs_secular$transformed_table|>\n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n```\n\n\n```{r, results = 'asis'}\ncat(life_religious_vs_secular$interpretation)\n```\n\n\n{{< pagebreak >}}\n\n### Social-Focussed Well-Being\n\n```{r}\n#| label: fig-social\n#| fig-cap: \"Effects on Life-Focussed Well-Being\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 16\n\nsocial_religious_vs_secular$plot\n```\n\n```{r}\n#| label: tbl-social\n#| tbl-cap: \"Effects on Social Well-Being\"\n#| eval: true\n#| echo: false\n\nsocial_religious_vs_secular$transformed_table|>\n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n```\n\n\n```{r, results = 'asis'}\ncat(social_religious_vs_secular$interpretation)\n```\n"
    },
    "main_effect": "The estimated causal effect was {{effect_size}} ({{confidence_interval}}), indicating {{interpretation}}.",
    "null_results": "We did not find evidence of an effect ({{effect_size}}, {{confidence_interval}})."
  },
  "template": {
    "conference_presentation": "---\ntitle: \"{{title}}\"\nauthor: \"{{authors}}\"\ndate: \"{{date}}\"\nformat:\n  revealjs:\n    theme: default\n    logo: institution_logo.png\nbibliography: references.bib\n---\n\n## Research Question\n\n{{research_question}}\n\n## Methods\n{{methods_brief}}\n\n## Key Findings\n{{results_highlights}}\n\n## Implications\n{{implications}}\n\n## Thank You\n{{acknowledgments}}\n",
    "grant_proposal": "---\ntitle: \"{{title}}\"\nauthor: \"{{authors}}\"\ndate: \"{{date}}\"\nformat: pdf\n---\n\n# Project Summary\n{{project_summary}}\n\n# Specific Aims\n{{specific_aims}}\n\n# Background and Significance\n{{background}}\n\n# Preliminary Studies\n{{preliminary_studies}}\n\n# Research Strategy\n\n## Methods\n{{methods_planned}}\n\n## Timeline\n{{timeline}}\n\n# Budget Justification\n{{budget_justification}}\n\n# References\n",
    "grf": {
      "simple": "## Introduction\n\nUnderstanding the factors that shape {{name_outcomes_lower}} is a fundamental goal in psychological science. Previous research has linked{{name_exposure_capfirst}} to {{name_outcomes_lower}}, yet establishing a reliable *causal* relationship remains challenging. Moving beyond mere correlation to identify causal effects is crucial for accurately predicting how interventions, such as encouraging {{name_exposure_lower}}, might influence individual development.\n\nFurthermore, individuals are not uniform; they respond differently to the same experiences. Relying solely on average treatment effects can mask significant heterogeneity, where effects vary substantially across different subgroups. Identifying who benefits most, least, or even differently from an intervention is vital for developing targeted and effective strategies.\n\nTraditional parametric approaches, such as standard linear regression, often struggle to meet these needs. They typically impose restrictive assumptions about the functional form of relationships and the uniformity of effects, potentially leading to biased causal estimates and overlooking crucial individual differences [@HainmuellerMummoloXu2019].\n\nThis study addresses these limitations by combining large-scale, longitudinal national panel data (the New Zealand Attitudes and Values Study) with robust methodological approaches. We aim to estimate the causal effect of {{name_exposure_lower}} on {{name_outcomes_lower}} while carefully investigating heterogeneity in these effects using non-parametric machine learning [@grf2024]. By employing methods designed to handle complex confounding and detect variations across individuals, we seek more subtle insights than conventional techniques typically provide, offering clarity into how targeted interventions affect individuals across the population over time."
    },
    "journal_article": "---\ntitle: \"{{title}}\"\nauthor: \"{{authors}}\"\ndate: \"{{date}}\"\nformat:\n  docx:\n    reference-doc: journal_template.docx\nbibliography: references.bib\n---\n\n# Abstract\n\n{{abstract}}\n\n# Introduction\n\n{{introduction}}\n\n# Methods\n\n## Sample\n{{methods_sample}}\n\n## Measures\n{{methods_measures}}\n\n## Statistical Approach\n{{methods_statistical}}\n\n# Results\n\n{{results}}\n\n# Discussion\n\n{{discussion}}\n\n# References\n"
  }
}
